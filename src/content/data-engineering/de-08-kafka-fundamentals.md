---
public: true
title: "ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì‹œë¦¬ì¦ˆ #8: Kafka í•µì‹¬ - ë©”ì‹œì§€ íë¥¼ ë„˜ì–´ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ"
date: '2026-01-02'
category: Data Engineering
series: data-engineering
tags: [Data Engineering, Kafka, Partitioning, Streaming]
excerpt: "Kafkaì˜ í•µì‹¬ ê°œë…ì„ ë°°ì›ë‹ˆë‹¤. Redis Streamsì™€ ë¹„êµí•˜ë©° Topic, Partition, Consumer Group, Exactly-Once Semanticsë¥¼ ì´í•´í•©ë‹ˆë‹¤."
---

# ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì‹œë¦¬ì¦ˆ #8: Kafka í•µì‹¬ - ë©”ì‹œì§€ íë¥¼ ë„˜ì–´ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ

> **ëŒ€ìƒ ë…ì**: ì¶©ë¶„í•œ ê²½í—˜ì„ ê°€ì§„ ë°±ì—”ë“œ/í’€ìŠ¤íƒ ì—”ì§€ë‹ˆì–´ë¡œ, Redis Streamsë‚˜ RabbitMQì— ìµìˆ™í•˜ì§€ë§Œ KafkaëŠ” ì²˜ìŒì¸ ë¶„

## ì´ í¸ì—ì„œ ë‹¤ë£¨ëŠ” ê²ƒ

Redis Streamsë¥¼ ì¨ë´¤ë‹¤ë©´ "Kafkaê°€ ë­ê°€ ë‹¤ë¥´ì§€?"ë¼ëŠ” ì˜ë¬¸ì´ ìˆì„ ê²ë‹ˆë‹¤. **ì™œ ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì—ì„œ Kafkaë¥¼ ì„ íƒí•˜ëŠ”ì§€**, í•µì‹¬ ê°œë…ì„ ë°°ì›ë‹ˆë‹¤.

---

## Redis Streams vs Kafka

### ì¹œìˆ™í•œ Redis Streamsì™€ ë¹„êµ

```mermaid
flowchart TB
    subgraph Redis ["Redis Streams"]
        RS_Stream["Stream: orders"]
        RS_Group1["Consumer Group A"]
        RS_Group2["Consumer Group B"]
        RS_C1["Consumer 1"]
        RS_C2["Consumer 2"]
        
        RS_Stream --> RS_Group1 --> RS_C1
        RS_Stream --> RS_Group2 --> RS_C2
    end
    
    subgraph Kafka ["Apache Kafka"]
        K_Topic["Topic: orders<br/>(Partitioned)"]
        K_Group1["Consumer Group A"]
        K_Group2["Consumer Group B"]
        K_C1["Consumer 1"]
        K_C2["Consumer 2"]
        
        K_Topic --> K_Group1 --> K_C1
        K_Topic --> K_Group2 --> K_C2
    end
    
    Similar["ìœ ì‚¬í•œ ê°œë…!"]
```

### ì£¼ìš” ì°¨ì´ì 

| íŠ¹ì„± | Redis Streams | Kafka |
|------|--------------|-------|
| **ì„¤ê³„ ëª©ì ** | ìºì‹œ + ê°€ë²¼ìš´ ìŠ¤íŠ¸ë¦¬ë° | ëŒ€ìš©ëŸ‰ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì „ìš© |
| **ë°ì´í„° ì €ì¥** | ë©”ëª¨ë¦¬ (ì œí•œì  ë³´ì¡´) | ë””ìŠ¤í¬ (ì¥ê¸° ë³´ì¡´ ê°€ëŠ¥) |
| **ìŠ¤ì¼€ì¼ë§** | ìˆ˜ì§ í™•ì¥ ìœ„ì£¼ | ìˆ˜í‰ í™•ì¥ (Partition) |
| **ì²˜ë¦¬ëŸ‰** | ìˆ˜ë§Œ TPS | **ìˆ˜ë°±ë§Œ TPS** |
| **ë³µì œ** | Master-Replica | Multi-broker ë³µì œ |
| **ìˆœì„œ ë³´ì¥** | Stream ë‚´ ë³´ì¥ | Partition ë‚´ ë³´ì¥ |
| **Consumer ê´€ë¦¬** | ìì²´ ê´€ë¦¬ í•„ìš” | Coordinator ìë™ ê´€ë¦¬ |

### ìŠ¤ì¼€ì¼ ë¹„êµ

```mermaid
flowchart TB
    subgraph RedisScale ["Redis Streams ìŠ¤ì¼€ì¼ë§"]
        RS1["ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤<br/>100K TPS"]
        RS2["Cluster Sharding<br/>ë³µì¡í•œ ê´€ë¦¬"]
    end
    
    subgraph KafkaScale ["Kafka ìŠ¤ì¼€ì¼ë§"]
        K1["Partition ì¶”ê°€"]
        K2["Broker ì¶”ê°€"]
        K3["Consumer ì¶”ê°€"]
        
        K1 --> K2 --> K3
        Result["ì„ í˜• í™•ì¥ ê°€ëŠ¥<br/>ìˆ˜ë°±ë§Œ TPS"]
    end
```

---

## Kafka í•µì‹¬ ê°œë…

### ì „ì²´ êµ¬ì¡°

```mermaid
flowchart TB
    subgraph Producers ["Producers"]
        P1["Producer 1"]
        P2["Producer 2"]
    end
    
    subgraph Kafka ["Kafka Cluster"]
        subgraph Broker1 ["Broker 1"]
            T1P0["Topic A<br/>Partition 0"]
            T1P1["Topic A<br/>Partition 1"]
        end
        
        subgraph Broker2 ["Broker 2"]
            T1P2["Topic A<br/>Partition 2"]
            T2P0["Topic B<br/>Partition 0"]
        end
        
        subgraph Broker3 ["Broker 3"]
            T2P1["Topic B<br/>Partition 1"]
        end
    end
    
    subgraph Consumers ["Consumer Groups"]
        subgraph CG1 ["Consumer Group 1"]
            C1["Consumer 1"]
            C2["Consumer 2"]
        end
        
        subgraph CG2 ["Consumer Group 2"]
            C3["Consumer 3"]
        end
    end
    
    Producers --> Kafka --> Consumers
```

### Topic

```mermaid
flowchart LR
    subgraph Topic ["Topic: user_events"]
        direction TB
        Desc["â€¢ ì´ë²¤íŠ¸ì˜ ì¹´í…Œê³ ë¦¬/ì±„ë„<br/>â€¢ Nê°œì˜ Partitionìœ¼ë¡œ êµ¬ì„±<br/>â€¢ ì„¤ì •ëœ ê¸°ê°„ë§Œí¼ ë³´ì¡´"]
    end
    
    Examples["ì˜ˆì‹œ:<br/>â€¢ orders<br/>â€¢ user_signups<br/>â€¢ page_views"]
    
    Topic --- Examples
```

### Partition

```mermaid
flowchart TB
    subgraph Topic ["Topic: orders"]
        subgraph P0 ["Partition 0"]
            M0_0["offset 0"] --> M0_1["offset 1"] --> M0_2["offset 2"]
        end
        
        subgraph P1 ["Partition 1"]
            M1_0["offset 0"] --> M1_1["offset 1"] --> M1_2["offset 2"]
        end
        
        subgraph P2 ["Partition 2"]
            M2_0["offset 0"] --> M2_1["offset 1"]
        end
    end
    
    Features["â€¢ ìˆœì„œ ë³´ì¥ ë‹¨ìœ„<br/>â€¢ ë³‘ë ¬ ì²˜ë¦¬ ë‹¨ìœ„<br/>â€¢ íŒŒí‹°ì…˜ í‚¤ë¡œ ë¶„ë°°"]
```

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸**:

- **ìˆœì„œ ë³´ì¥ì€ Partition ë‚´ì—ì„œë§Œ!**
- Partition ìˆ˜ = ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜ì¤€
- ê°™ì€ í‚¤ëŠ” ê°™ì€ Partitionìœ¼ë¡œ

### Offset

```mermaid
flowchart LR
    subgraph Partition ["Partition 0"]
        O0["offset 0<br/>msg_a"]
        O1["offset 1<br/>msg_b"]
        O2["offset 2<br/>msg_c"]
        O3["offset 3<br/>msg_d"]
        O4["offset 4<br/>msg_e"]
        
        O0 --> O1 --> O2 --> O3 --> O4
    end
    
    subgraph Consumers ["Consumer ìœ„ì¹˜"]
        C1["Group A<br/>offset: 3"]
        C2["Group B<br/>offset: 1"]
    end
    
    O3 -.->|"ì½ëŠ” ì¤‘"| C1
    O1 -.->|"ì½ëŠ” ì¤‘"| C2
```

**Offsetì˜ ì—­í• **:

- ê° Consumer Groupì´ ì–´ë””ê¹Œì§€ ì½ì—ˆëŠ”ì§€ ì¶”ì 
- ì¬ì‹œì‘ ì‹œ ì´ì–´ì„œ ì½ê¸° ê°€ëŠ¥
- ê³¼ê±° ë°ì´í„° ë‹¤ì‹œ ì½ê¸° ê°€ëŠ¥ (rewind)

### Consumer Group

```mermaid
flowchart TB
    subgraph Topic ["Topic: orders (3 partitions)"]
        P0["Partition 0"]
        P1["Partition 1"]
        P2["Partition 2"]
    end
    
    subgraph Group1 ["Consumer Group A (3 consumers)"]
        C1["Consumer 1"]
        C2["Consumer 2"]
        C3["Consumer 3"]
    end
    
    subgraph Group2 ["Consumer Group B (1 consumer)"]
        C4["Consumer 4"]
    end
    
    P0 --> C1
    P1 --> C2
    P2 --> C3
    
    P0 --> C4
    P1 --> C4
    P2 --> C4
    
    Note1["Group A: ê° Consumerê°€<br/>1ê°œ Partition ë‹´ë‹¹"]
    Note2["Group B: 1 Consumerê°€<br/>ëª¨ë“  Partition ë‹´ë‹¹"]
```

**í•µì‹¬ ê·œì¹™**:

- í•œ Partitionì€ Group ë‚´ **í•˜ë‚˜ì˜ Consumer**ë§Œ ì½ì„ ìˆ˜ ìˆìŒ
- Consumer ìˆ˜ > Partition ìˆ˜ â†’ ì¼ë¶€ Consumer ìœ íœ´
- Consumer ìˆ˜ < Partition ìˆ˜ â†’ ì¼ë¶€ Consumerê°€ ì—¬ëŸ¬ Partition ë‹´ë‹¹

---

## Producer: ë©”ì‹œì§€ ë³´ë‚´ê¸°

### íŒŒí‹°ì…˜ ê²°ì • ì „ëµ

```mermaid
flowchart TB
    Message["ë©”ì‹œì§€ ì „ì†¡"]
    
    HasKey{"í‚¤ê°€<br/>ìˆëŠ”ê°€?"}
    
    Hash["hash(key) % partition_count<br/>â†’ ê°™ì€ í‚¤ = ê°™ì€ Partition"]
    RoundRobin["ë¼ìš´ë“œ ë¡œë¹ˆ<br/>â†’ ê³ ë¥´ê²Œ ë¶„ë°°"]
    Sticky["Sticky Partitioner<br/>â†’ ë°°ì¹˜ ìµœì í™”"]
    
    Message --> HasKey
    HasKey -->|"ì˜ˆ"| Hash
    HasKey -->|"ì•„ë‹ˆì˜¤ (2.4+)"| Sticky
    HasKey -->|"ì•„ë‹ˆì˜¤ (êµ¬ë²„ì „)"| RoundRobin
```

### Python Producer ì˜ˆì‹œ

```python
from confluent_kafka import Producer

def delivery_callback(err, msg):
    if err:
        print(f"Delivery failed: {err}")
    else:
        print(f"Delivered to {msg.topic()} [{msg.partition()}] @ {msg.offset()}")

# Producer ì„¤ì •
producer = Producer({
    'bootstrap.servers': 'localhost:9092',
    'acks': 'all',  # ëª¨ë“  replica í™•ì¸
    'enable.idempotence': True,  # ì¤‘ë³µ ë°©ì§€
})

# í‚¤ê°€ ìˆëŠ” ë©”ì‹œì§€ (ê°™ì€ user_id = ê°™ì€ Partition)
producer.produce(
    topic='user_events',
    key='user_123',
    value='{"event": "purchase", "amount": 100}',
    callback=delivery_callback
)

# í‚¤ê°€ ì—†ëŠ” ë©”ì‹œì§€ (ìë™ ë¶„ë°°)
producer.produce(
    topic='logs',
    value='{"level": "info", "message": "hello"}',
    callback=delivery_callback
)

producer.flush()
```

---

## Consumer: ë©”ì‹œì§€ ì½ê¸°

### Consumer ë¼ì´í”„ì‚¬ì´í´

```mermaid
flowchart TB
    subgraph Lifecycle ["Consumer ë¼ì´í”„ì‚¬ì´í´"]
        Subscribe["Subscribe<br/>Topic êµ¬ë…"]
        Poll["Poll<br/>ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°"]
        Process["Process<br/>ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§"]
        Commit["Commit<br/>Offset ì €ì¥"]
        
        Subscribe --> Poll --> Process --> Commit --> Poll
    end
```

### Python Consumer ì˜ˆì‹œ

```python
from confluent_kafka import Consumer, KafkaError

# Consumer ì„¤ì •
consumer = Consumer({
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'my-consumer-group',
    'auto.offset.reset': 'earliest',  # ì²˜ìŒë¶€í„° ì½ê¸°
    'enable.auto.commit': False,  # ìˆ˜ë™ ì»¤ë°‹
})

consumer.subscribe(['user_events'])

try:
    while True:
        msg = consumer.poll(timeout=1.0)
        
        if msg is None:
            continue
        if msg.error():
            if msg.error().code() == KafkaError._PARTITION_EOF:
                continue
            raise KafkaException(msg.error())
        
        # ë©”ì‹œì§€ ì²˜ë¦¬
        key = msg.key().decode('utf-8') if msg.key() else None
        value = msg.value().decode('utf-8')
        
        print(f"Received: key={key}, value={value}")
        
        # ì²˜ë¦¬ ì™„ë£Œ í›„ ì»¤ë°‹
        consumer.commit(asynchronous=False)
        
finally:
    consumer.close()
```

---

## Exactly-Once Semantics

> âš ï¸ **ì£¼ì˜**: Kafkaì˜ Exactly-OnceëŠ” **"Kafka ë‚´ë¶€"**ì—ì„œì˜ ë³´ì¥ì…ë‹ˆë‹¤. ì™¸ë¶€ DB/APIë¡œì˜ End-to-End Exactly-OnceëŠ” **ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ ì¶”ê°€ ì²˜ë¦¬**ê°€ í•„ìš”í•©ë‹ˆë‹¤.

### ë©”ì‹œì§€ ì „ë‹¬ ë³´ì¥ ìˆ˜ì¤€

```mermaid
flowchart TB
    subgraph Levels ["ì „ë‹¬ ë³´ì¥ ìˆ˜ì¤€"]
        AtMost["At-Most-Once<br/>ìµœëŒ€ 1ë²ˆ"]
        AtLeast["At-Least-Once<br/>ìµœì†Œ 1ë²ˆ"]
        Exactly["Exactly-Once<br/>ì •í™•íˆ 1ë²ˆ"]
    end
    
    AtMost -->|"ë©”ì‹œì§€ ìœ ì‹¤ ê°€ëŠ¥"| L1["âŒ ë°ì´í„° ì†ì‹¤"]
    AtLeast -->|"ì¤‘ë³µ ê°€ëŠ¥"| L2["âš ï¸ ì¤‘ë³µ ì²˜ë¦¬"]
    Exactly -->|"ì •í™•í•¨"| L3["âœ… ì™„ë²½"]
    
    Difficulty["êµ¬í˜„ ë‚œì´ë„: At-Most < At-Least < Exactly"]
```

### Idempotent Producer

```mermaid
flowchart LR
    subgraph Problem ["ë¬¸ì œ ìƒí™©"]
        P1["Producer ì „ì†¡"]
        P2["Broker ì €ì¥"]
        P3["ACK ìœ ì‹¤"]
        P4["Producer ì¬ì „ì†¡"]
        P5["ì¤‘ë³µ ì €ì¥!"]
        
        P1 --> P2 --> P3 --> P4 --> P5
    end
    
    subgraph Solution ["Idempotent Producer"]
        S1["Producer ì „ì†¡<br/>(PID + SeqNum)"]
        S2["Broker ì €ì¥<br/>(SeqNum ê¸°ë¡)"]
        S3["ACK ìœ ì‹¤"]
        S4["ì¬ì „ì†¡ ì‹œ<br/>ì¤‘ë³µ ê°ì§€"]
        S5["ë¬´ì‹œë¨ âœ…"]
        
        S1 --> S2 --> S3 --> S4 --> S5
    end
```

```python
# Idempotent Producer ì„¤ì •
producer = Producer({
    'bootstrap.servers': 'localhost:9092',
    'enable.idempotence': True,  # í•µì‹¬ ì„¤ì •!
    'acks': 'all',
    'retries': 5,
})
```

### Transactional Producer

```mermaid
flowchart TB
    subgraph Transaction ["íŠ¸ëœì­ì…˜"]
        Begin["begin_transaction()"]
        Send1["produce(topic_a)"]
        Send2["produce(topic_b)"]
        Commit["commit_transaction()"]
        
        Begin --> Send1 --> Send2 --> Commit
    end
    
    Result["ëª¨ë‘ ì„±ê³µ ë˜ëŠ” ëª¨ë‘ ì‹¤íŒ¨<br/>â†’ Atomic"]
```

```python
from confluent_kafka import Producer

producer = Producer({
    'bootstrap.servers': 'localhost:9092',
    'enable.idempotence': True,
    'transactional.id': 'my-transactional-producer',
})

# íŠ¸ëœì­ì…˜ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
producer.init_transactions()

try:
    producer.begin_transaction()
    
    producer.produce('orders', key='order_1', value='...')
    producer.produce('payments', key='order_1', value='...')
    
    producer.commit_transaction()
except Exception as e:
    producer.abort_transaction()
    raise
```

### Consumer ì¸¡ Exactly-Once

```python
consumer = Consumer({
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'exactly-once-group',
    'isolation.level': 'read_committed',  # ì»¤ë°‹ëœ ë©”ì‹œì§€ë§Œ ì½ê¸°
    'enable.auto.commit': False,
})
```

---

## KRaft: Zookeeper ì—†ëŠ” Kafka

### ê¸°ì¡´ ì•„í‚¤í…ì²˜ì˜ ë¬¸ì œ

```mermaid
flowchart TB
    subgraph Old ["ê¸°ì¡´ (Zookeeper ê¸°ë°˜)"]
        ZK["Zookeeper Cluster"]
        B1["Broker 1"]
        B2["Broker 2"]
        B3["Broker 3"]
        
        ZK <-->|"ë©”íƒ€ë°ì´í„°"| B1
        ZK <-->|"ë©”íƒ€ë°ì´í„°"| B2
        ZK <-->|"ë©”íƒ€ë°ì´í„°"| B3
        
        Problems["ë¬¸ì œì :<br/>â€¢ ë³„ë„ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬<br/>â€¢ ë©”íƒ€ë°ì´í„° ë™ê¸°í™” ì§€ì—°<br/>â€¢ ìš´ì˜ ë³µì¡ë„"]
    end
```

### KRaft ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph New ["KRaft (Kafka 3.0+)"]
        subgraph Controllers ["Controller ì—­í• "]
            C1["Controller 1"]
            C2["Controller 2"]
            C3["Controller 3"]
        end
        
        subgraph Brokers ["Broker ì—­í• "]
            B1["Broker 1"]
            B2["Broker 2"]
            B3["Broker 3"]
        end
        
        Controllers <-->|"Raft í•©ì˜"| Controllers
        Controllers -->|"ë©”íƒ€ë°ì´í„°"| Brokers
        
        Benefits["ì¥ì :<br/>â€¢ ë‹¨ì¼ ì‹œìŠ¤í…œ<br/>â€¢ ë¹ ë¥¸ ë©”íƒ€ë°ì´í„° ì „íŒŒ<br/>â€¢ ì‰¬ìš´ ìš´ì˜"]
    end
```

---

## Schema Registry: ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬

í”„ë¡œë•ì…˜ Kafkaì—ì„œ **ìŠ¤í‚¤ë§ˆ ì§„í™”(Schema Evolution)**ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.

> **ì¶œì²˜**: [Confluent Schema Registry Documentation](https://docs.confluent.io/platform/current/schema-registry/), Kleppmann, "Designing Data-Intensive Applications" Chapter 4

### ì™œ í•„ìš”í•œê°€?

```mermaid
flowchart TB
    subgraph Problem ["ìŠ¤í‚¤ë§ˆ ì—†ì´ ìš´ì˜"]
        P1["Producer: {name, age}"]
        P2["Consumer: {name, age, email} ê¸°ëŒ€"]
        P3["ğŸ’¥ íŒŒì‹± ì‹¤íŒ¨"]
        
        P1 --> P3
        P2 --> P3
    end
    
    subgraph Solution ["Schema Registry ì‚¬ìš©"]
        S1["ìŠ¤í‚¤ë§ˆ ì¤‘ì•™ ì €ì¥"]
        S2["ë²„ì „ ê´€ë¦¬"]
        S3["í˜¸í™˜ì„± ê²€ì¦"]
        S4["âœ… ì•ˆì „í•œ ì§„í™”"]
        
        S1 --> S2 --> S3 --> S4
    end
```

### ì§€ì› í¬ë§·

| í¬ë§· | íŠ¹ì§• | ì‚¬ìš© ì‚¬ë¡€ |
|------|------|----------|
| **Avro** | ìŠ¤í‚¤ë§ˆ ì§„í™” ìš°ìˆ˜, ì••ì¶• íš¨ìœ¨ | ê°€ì¥ ë„ë¦¬ ì‚¬ìš© |
| **Protobuf** | gRPC í˜¸í™˜, ê°•íƒ€ì… | ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ |
| **JSON Schema** | ì½ê¸° ì‰¬ì›€ | ë””ë²„ê¹…, í˜¸í™˜ì„± |

### í˜¸í™˜ì„± ëª¨ë“œ

```mermaid
flowchart TB
    subgraph Modes ["í˜¸í™˜ì„± ëª¨ë“œ"]
        BACKWARD["BACKWARD<br/>ìƒˆ ìŠ¤í‚¤ë§ˆê°€ ì´ì „ ë°ì´í„° ì½ê¸° ê°€ëŠ¥"]
        FORWARD["FORWARD<br/>ì´ì „ ìŠ¤í‚¤ë§ˆê°€ ìƒˆ ë°ì´í„° ì½ê¸° ê°€ëŠ¥"]
        FULL["FULL<br/>ì–‘ë°©í–¥ í˜¸í™˜"]
        NONE["NONE<br/>ê²€ì¦ ì—†ìŒ (ë¹„ê¶Œì¥)"]
    end
    
    Recommend["ê¶Œì¥: BACKWARD ë˜ëŠ” FULL"]
```

| ëª¨ë“œ | í—ˆìš© ë³€ê²½ | ì˜ˆì‹œ |
|------|----------|------|
| **BACKWARD** | í•„ë“œ ì‚­ì œ, ê¸°ë³¸ê°’ ìˆëŠ” í•„ë“œ ì¶”ê°€ | ìƒˆ Consumerê°€ ì´ì „ ë°ì´í„° ì½ìŒ |
| **FORWARD** | í•„ë“œ ì¶”ê°€, ê¸°ë³¸ê°’ ìˆëŠ” í•„ë“œ ì‚­ì œ | ì´ì „ Consumerê°€ ìƒˆ ë°ì´í„° ì½ìŒ |
| **FULL** | ê¸°ë³¸ê°’ ìˆëŠ” í•„ë“œë§Œ ì¶”ê°€/ì‚­ì œ | ê°€ì¥ ì•ˆì „ |

### Python ì‚¬ìš© ì˜ˆì‹œ

```python
from confluent_kafka import SerializingProducer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.schema_registry.avro import AvroSerializer

# Schema Registry ì—°ê²°
schema_registry = SchemaRegistryClient({
    'url': 'http://schema-registry:8081'
})

# Avro ìŠ¤í‚¤ë§ˆ ì •ì˜
user_schema = """
{
    "type": "record",
    "name": "User",
    "fields": [
        {"name": "name", "type": "string"},
        {"name": "age", "type": "int"},
        {"name": "email", "type": ["null", "string"], "default": null}
    ]
}
"""

# Serializer ìƒì„± (ìŠ¤í‚¤ë§ˆ ìë™ ë“±ë¡)
avro_serializer = AvroSerializer(
    schema_registry,
    user_schema,
    to_dict=lambda user, ctx: user
)

# Producer ì„¤ì •
producer = SerializingProducer({
    'bootstrap.servers': 'localhost:9092',
    'value.serializer': avro_serializer
})

# ë©”ì‹œì§€ ì „ì†¡
producer.produce(
    topic='users',
    value={'name': 'Kim', 'age': 30, 'email': 'kim@example.com'}
)
producer.flush()
```

---

## ì‚¬ìš© ì‚¬ë¡€

```mermaid
flowchart TB
    subgraph UseCases ["Kafka ì‚¬ìš© ì‚¬ë¡€"]
        subgraph Logging ["ë¡œê·¸ ìˆ˜ì§‘"]
            L1["App Logs"]
            L2["Kafka"]
            L3["Elasticsearch"]
            L1 --> L2 --> L3
        end
        
        subgraph Events ["ì´ë²¤íŠ¸ ì†Œì‹±"]
            E1["User Actions"]
            E2["Kafka<br/>(Event Store)"]
            E3["State ì¬êµ¬ì„±"]
            E1 --> E2 --> E3
        end
        
        subgraph CDC ["Change Data Capture"]
            D1[(DB)]
            D2["Debezium"]
            D3["Kafka"]
            D4["Data Lake"]
            D1 --> D2 --> D3 --> D4
        end
        
        subgraph Stream ["ì‹¤ì‹œê°„ ë¶„ì„"]
            S1["Click Stream"]
            S2["Kafka"]
            S3["Flink/Spark"]
            S4["Dashboard"]
            S1 --> S2 --> S3 --> S4
        end
    end
```

---

## ì •ë¦¬

```mermaid
mindmap
  root((Kafka<br/>í•µì‹¬))
    vs Redis Streams
      ë” í° ìŠ¤ì¼€ì¼
      ë” ê¸´ ë³´ì¡´
      ë” ë‚˜ì€ ë³µì œ
    êµ¬ì„± ìš”ì†Œ
      Topic
      Partition
      Offset
      Consumer Group
    Producer
      íŒŒí‹°ì…˜ ê²°ì •
      í‚¤ ê¸°ë°˜ ë¶„ë°°
      Idempotent
    Consumer
      Group ê´€ë¦¬
      Offset ì»¤ë°‹
      Rebalancing
    Exactly-Once
      Idempotent Producer
      Transactional
      read_committed
    KRaft
      Zookeeper ì œê±°
      ë‹¨ìˆœí•œ ìš´ì˜
      ë¹ ë¥¸ ë©”íƒ€ë°ì´í„°
    Schema Registry
      ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬
      í˜¸í™˜ì„± ê²€ì¦
      Avro/Protobuf
```

---

## ë‹¤ìŒ í¸ ì˜ˆê³ 

**9í¸: Spark Structured Streaming**ì—ì„œëŠ” ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤:

- Kafka + Spark ì—°ë™
- Watermarkì™€ Late Data
- Window ì—°ì‚°
- ì²´í¬í¬ì¸íŒ…

---

## ì°¸ê³  ìë£Œ

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Confluent Schema Registry](https://docs.confluent.io/platform/current/schema-registry/)
- [Confluent Developer](https://developer.confluent.io/)
- "Kafka: The Definitive Guide" (O'Reilly)
- Martin Kleppmann, "Designing Data-Intensive Applications" - Chapter 4
- [KRaft Overview](https://kafka.apache.org/documentation/#kraft)
