[
  {
    "id": "turf-polygon-operations",
    "slug": "turf-polygon-operations",
    "path": "frontend/maps",
    "fullPath": "frontend/maps/turf-polygon-operations",
    "title": "Turf.js로 폴리곤 공간 연산 수행하기",
    "excerpt": "Turf.js를 사용하여 멀티폴리곤의 합집합, 차집합, 교집합 연산을 수행하는 방법을 알아봅니다.",
    "content": "# Turf.js로 폴리곤 공간 연산 수행하기\n\n## 개요\n\n**Turf.js**는 브라우저와 Node.js에서 실행되는 GeoJSON 기반 공간 분석 라이브러리입니다. v7부터 `polygon-clipping` 엔진으로 성능과 정확도가 크게 개선되었습니다.\n\n![Union, Difference, Intersect 연산 결과 시각화](/images/turf-operations-demo-image.png)\n\n## 설치\n\n```bash\n# 전체 라이브러리\nnpm install @turf/turf\n\n# 또는 개별 모듈\nnpm install @turf/union @turf/difference @turf/intersect @turf/helpers\n```\n\n## 기본 데이터 생성\n\n### 폴리곤 생성\n\n```javascript\nimport { polygon, multiPolygon, featureCollection } from '@turf/helpers';\n\n// 단일 폴리곤\nconst poly1 = polygon([\n    [[0, 0], [2, 0], [2, 2], [0, 2], [0, 0]]\n]);\n\nconst poly2 = polygon([\n    [[1, 1], [3, 1], [3, 3], [1, 3], [1, 1]]\n]);\n\n// 멀티폴리곤\nconst multiPoly = multiPolygon([\n    [[[0, 0], [1, 0], [1, 1], [0, 1], [0, 0]]],\n    [[[2, 2], [3, 2], [3, 3], [2, 3], [2, 2]]]\n]);\n```\n\n## 합집합 (Union)\n\n여러 폴리곤을 하나로 병합합니다.\n\n```javascript\nimport { union } from '@turf/union';\nimport { featureCollection } from '@turf/helpers';\n\n// v7: FeatureCollection 입력\nconst merged = union(featureCollection([poly1, poly2]));\n// 결과: Polygon 또는 MultiPolygon (연결되지 않으면)\n```\n\n### 여러 폴리곤 병합\n\n```javascript\nimport { union } from '@turf/union';\nimport { featureCollection } from '@turf/helpers';\n\nconst polygons = [poly1, poly2, poly3, poly4];\nconst merged = union(featureCollection(polygons));\n```\n\n### 실용 예: 행정구역 병합\n\n```javascript\n// 경기도 시군구 → 경기도 전체 영역\nconst gyeonggiCities = featureCollection([\n    suwonPolygon,\n    seongnamPolygon,\n    yonginPolygon,\n    // ...\n]);\n\nconst gyeonggiProvince = union(gyeonggiCities);\n```\n\n## 차집합 (Difference)\n\n기준 폴리곤에서 다른 폴리곤 영역을 제거합니다.\n\n```javascript\nimport { difference } from '@turf/difference';\nimport { featureCollection } from '@turf/helpers';\n\n// poly1에서 poly2 영역 제거\nconst subtracted = difference(featureCollection([poly1, poly2]));\n// 결과: Polygon, MultiPolygon, 또는 null (완전히 덮이면)\n```\n\n### 여러 영역 제거\n\n```javascript\n// base에서 exclude1, exclude2 영역 모두 제거\nconst result = difference(featureCollection([base, exclude1, exclude2]));\n```\n\n### 실용 예: 특정 구역 제외\n\n```javascript\n// 서울시 전체에서 한강 영역 제외\nconst seoulLandOnly = difference(featureCollection([\n    seoulBoundary,\n    hanRiverPolygon\n]));\n```\n\n## 교집합 (Intersect)\n\n폴리곤들의 겹치는 영역만 추출합니다.\n\n```javascript\nimport { intersect } from '@turf/intersect';\nimport { featureCollection } from '@turf/helpers';\n\nconst intersection = intersect(featureCollection([poly1, poly2]));\n// 결과: Polygon, MultiPolygon, 또는 null (겹치지 않으면)\n```\n\n### 실용 예: 서비스 가능 영역\n\n```javascript\n// 배달 가능 영역과 사용자 위치 주변 영역의 교집합\nconst deliverableArea = intersect(featureCollection([\n    restaurantDeliveryZone,\n    userRadiusCircle\n]));\n\nif (deliverableArea) {\n    console.log('배달 가능한 영역 존재');\n} else {\n    console.log('배달 불가');\n}\n```\n\n## 연산 결과 검증\n\n### Null 처리\n\n교집합이나 차집합 결과가 없을 수 있습니다:\n\n```javascript\nconst result = intersect(featureCollection([polyA, polyB]));\n\nif (result === null) {\n    console.log('겹치는 영역 없음');\n    return;\n}\n\n// 결과 사용\nconsole.log(result.geometry.type); // 'Polygon' or 'MultiPolygon'\n```\n\n### 면적 검증\n\n```javascript\nimport { area } from '@turf/area';\n\nconst merged = union(featureCollection(polygons));\nconst areaM2 = area(merged);\nconsole.log(`면적: ${(areaM2 / 1000000).toFixed(2)} km²`);\n```\n\n## 복합 연산 예시\n\n### 도넛 폴리곤 생성\n\n```javascript\nimport { difference } from '@turf/difference';\nimport { circle } from '@turf/circle';\nimport { featureCollection } from '@turf/helpers';\n\n// 외부 원 (반경 5km)\nconst outer = circle([127.0, 37.5], 5, { units: 'kilometers' });\n\n// 내부 원 (반경 2km)\nconst inner = circle([127.0, 37.5], 2, { units: 'kilometers' });\n\n// 도넛 형태\nconst donut = difference(featureCollection([outer, inner]));\n```\n\n### 여러 조건 조합\n\n```javascript\nimport { union, difference, intersect } from '@turf/turf';\nimport { featureCollection } from '@turf/helpers';\n\n// 1. 모든 서비스 지역 병합\nconst allServiceAreas = union(featureCollection(servicePolygons));\n\n// 2. 금지 구역 제거\nconst allowedAreas = difference(featureCollection([\n    allServiceAreas,\n    ...restrictedZones\n]));\n\n// 3. 사용자 반경과 교차\nconst finalServiceable = intersect(featureCollection([\n    allowedAreas,\n    userRadiusPolygon\n]));\n```\n\n## 성능 고려사항\n\n### 복잡한 폴리곤\n\n```javascript\nimport { simplify } from '@turf/simplify';\n\n// 연산 전 폴리곤 단순화 (정점 수 감소)\nconst simplified = simplify(complexPolygon, { tolerance: 0.001 });\nconst result = union(featureCollection([simplified, otherPolygon]));\n```\n\n### 유효성 검사\n\n```javascript\nimport { kinks } from '@turf/kinks';\n\n// 자기 교차 검사\nconst selfIntersections = kinks(polygon);\nif (selfIntersections.features.length > 0) {\n    console.warn('자기 교차하는 폴리곤');\n}\n```\n\n## API 정리\n\n| 함수 | 입력 | 출력 | 설명 |\n|------|------|------|------|\n| `union` | FeatureCollection | Polygon/MultiPolygon | 모든 폴리곤 병합 |\n| `difference` | FeatureCollection | Polygon/MultiPolygon/null | 첫 번째에서 나머지 제거 |\n| `intersect` | FeatureCollection | Polygon/MultiPolygon/null | 공통 영역 추출 |\n\n## 모범 사례\n\n1. **FeatureCollection 사용**: v7부터 여러 폴리곤은 FeatureCollection으로 전달\n2. **Null 체크 필수**: 교집합/차집합 결과가 없을 수 있음\n3. **단순화 먼저**: 복잡한 폴리곤은 `simplify` 후 연산\n4. **좌표계 통일**: 모든 입력은 동일한 SRID (보통 4326)\n\n## 참고 자료\n\n- [Turf.js Documentation](https://turfjs.org/)\n- [Turf.js v7 Release Notes](https://github.com/Turfjs/turf/releases/tag/v7.0.0)",
    "docType": "original",
    "category": "Frontend",
    "tags": [
      "Turf.js",
      "GeoJSON",
      "JavaScript",
      "Spatial",
      "GIS"
    ],
    "readingTime": 4,
    "wordCount": 714,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "mapbox-gl-guide",
    "slug": "mapbox-gl-guide",
    "path": "frontend/maps",
    "fullPath": "frontend/maps/mapbox-gl-guide",
    "title": "Mapbox GL JS로 인터랙티브 지도 구현하기",
    "excerpt": "Mapbox GL JS v3로 Earth2 스타일 격자 그리드와 네이버부동산 스타일 영역 레이어를 구현하는 방법을 알아봅니다.",
    "content": "# Mapbox GL JS로 인터랙티브 지도 구현하기\n\n## 개요\n\n**Mapbox GL JS**는 WebGL 기반 벡터 타일 지도 라이브러리입니다. 이 글에서는 두 가지 실용적인 패턴을 다룹니다:\n\n1. **격자 그리드 레이어**: Earth2 스타일의 바둑판 오버레이\n2. **영역 폴리곤 레이어**: 네이버부동산 스타일의 지역 표시\n\n## 설치 및 초기화\n\n```bash\nnpm install mapbox-gl @turf/turf\n```\n\n```javascript\nimport mapboxgl from 'mapbox-gl';\nimport 'mapbox-gl/dist/mapbox-gl.css';\n\nmapboxgl.accessToken = 'YOUR_ACCESS_TOKEN';\n\nconst map = new mapboxgl.Map({\n    container: 'map',\n    style: 'mapbox://styles/mapbox/dark-v11',  // 격자가 잘 보이는 다크 테마\n    center: [127.0, 37.5],\n    zoom: 12\n});\n```\n\n---\n\n## 예시 1: Earth2 스타일 격자 그리드\n\n전 세계를 일정한 크기의 셀로 나누어 바둑판처럼 표시합니다.\n\n![격자 그리드 데모 - 클릭으로 셀 선택 가능](/images/mapbox-grid-demo-image.png)\n\n### 격자 생성 (Turf.js)\n\n```javascript\nimport { squareGrid, bboxPolygon } from '@turf/turf';\n\n// 현재 뷰포트 기준 격자 생성\nfunction createGrid(bounds, cellSize = 0.01) {\n    const bbox = [bounds.getWest(), bounds.getSouth(), bounds.getEast(), bounds.getNorth()];\n    \n    // cellSize: 도 단위 (0.01도 ≈ 약 1km)\n    const grid = squareGrid(bbox, cellSize, { units: 'degrees' });\n    \n    // 각 셀에 고유 ID 부여\n    grid.features.forEach((cell, i) => {\n        cell.id = i;\n        cell.properties.cellId = `cell_${i}`;\n    });\n    \n    return grid;\n}\n```\n\n### 격자 레이어 추가\n\n```javascript\nmap.on('load', () => {\n    const grid = createGrid(map.getBounds(), 0.005);\n    \n    // 소스 추가\n    map.addSource('grid', {\n        type: 'geojson',\n        data: grid,\n        generateId: true\n    });\n    \n    // 격자 면 (Fill)\n    map.addLayer({\n        id: 'grid-fill',\n        type: 'fill',\n        source: 'grid',\n        paint: {\n            'fill-color': [\n                'case',\n                ['boolean', ['feature-state', 'selected'], false], '#00ff88',\n                ['boolean', ['feature-state', 'hover'], false], '#ffffff',\n                'transparent'\n            ],\n            'fill-opacity': [\n                'case',\n                ['boolean', ['feature-state', 'selected'], false], 0.6,\n                ['boolean', ['feature-state', 'hover'], false], 0.2,\n                0\n            ]\n        }\n    });\n    \n    // 격자 선 (Line)\n    map.addLayer({\n        id: 'grid-line',\n        type: 'line',\n        source: 'grid',\n        paint: {\n            'line-color': '#00ff88',\n            'line-width': 0.5,\n            'line-opacity': 0.5\n        }\n    });\n});\n```\n\n### 격자 인터랙션\n\n```javascript\nlet hoveredCellId = null;\nconst selectedCells = new Set();\n\n// 호버\nmap.on('mousemove', 'grid-fill', (e) => {\n    if (e.features.length > 0) {\n        if (hoveredCellId !== null) {\n            map.setFeatureState({ source: 'grid', id: hoveredCellId }, { hover: false });\n        }\n        hoveredCellId = e.features[0].id;\n        map.setFeatureState({ source: 'grid', id: hoveredCellId }, { hover: true });\n    }\n});\n\nmap.on('mouseleave', 'grid-fill', () => {\n    if (hoveredCellId !== null) {\n        map.setFeatureState({ source: 'grid', id: hoveredCellId }, { hover: false });\n    }\n    hoveredCellId = null;\n});\n\n// 클릭으로 셀 선택/해제\nmap.on('click', 'grid-fill', (e) => {\n    const cellId = e.features[0].id;\n    const isSelected = selectedCells.has(cellId);\n    \n    if (isSelected) {\n        selectedCells.delete(cellId);\n        map.setFeatureState({ source: 'grid', id: cellId }, { selected: false });\n    } else {\n        selectedCells.add(cellId);\n        map.setFeatureState({ source: 'grid', id: cellId }, { selected: true });\n    }\n    \n    console.log('선택된 셀:', [...selectedCells]);\n});\n```\n\n### 뷰포트 변경 시 격자 갱신\n\n```javascript\nmap.on('moveend', () => {\n    const newGrid = createGrid(map.getBounds(), 0.005);\n    map.getSource('grid').setData(newGrid);\n});\n```\n\n---\n\n## 예시 2: 네이버부동산 스타일 영역 레이어\n\n행정구역별로 색상과 라벨을 표시하고, 클릭 시 상세 정보를 보여줍니다.\n\n![부동산 스타일 영역 레이어 - 가격별 색상과 라벨](/images/mapbox-district-demo-image.png)\n\n### GeoJSON 데이터 구조\n\n```javascript\nconst districtsData = {\n    type: 'FeatureCollection',\n    features: [\n        {\n            type: 'Feature',\n            id: 1,\n            properties: {\n                name: '강남구',\n                avgPrice: 15000000,  // 평당 가격\n                changeRate: 2.5      // 변동률 %\n            },\n            geometry: {\n                type: 'Polygon',\n                coordinates: [[[127.0, 37.5], [127.1, 37.5], [127.1, 37.52], [127.0, 37.52], [127.0, 37.5]]]\n            }\n        },\n        // ...\n    ]\n};\n```\n\n### 영역 레이어 추가\n\n```javascript\nmap.on('load', () => {\n    map.addSource('districts', {\n        type: 'geojson',\n        data: districtsData,\n        generateId: true\n    });\n    \n    // 영역 면 - 가격에 따른 색상\n    map.addLayer({\n        id: 'districts-fill',\n        type: 'fill',\n        source: 'districts',\n        paint: {\n            'fill-color': [\n                'interpolate',\n                ['linear'],\n                ['get', 'avgPrice'],\n                5000000, '#fef0d9',    // 낮은 가격: 연한 색\n                10000000, '#fdbb84',\n                15000000, '#fc8d59',\n                20000000, '#d7301f'    // 높은 가격: 진한 색\n            ],\n            'fill-opacity': [\n                'case',\n                ['boolean', ['feature-state', 'hover'], false], 0.9,\n                0.6\n            ]\n        }\n    });\n    \n    // 영역 경계선\n    map.addLayer({\n        id: 'districts-outline',\n        type: 'line',\n        source: 'districts',\n        paint: {\n            'line-color': '#ffffff',\n            'line-width': [\n                'case',\n                ['boolean', ['feature-state', 'hover'], false], 3,\n                1\n            ]\n        }\n    });\n    \n    // 라벨 (구 이름 + 가격)\n    map.addLayer({\n        id: 'districts-label',\n        type: 'symbol',\n        source: 'districts',\n        layout: {\n            'text-field': [\n                'format',\n                ['get', 'name'], { 'font-scale': 1.2 },\n                '\\n', {},\n                ['concat', ['to-string', ['/', ['get', 'avgPrice'], 10000]], '만원'], { 'font-scale': 0.9 }\n            ],\n            'text-font': ['DIN Pro Medium', 'Arial Unicode MS Bold'],\n            'text-size': 12,\n            'text-anchor': 'center'\n        },\n        paint: {\n            'text-color': '#ffffff',\n            'text-halo-color': '#000000',\n            'text-halo-width': 1\n        }\n    });\n});\n```\n\n### 호버 및 팝업\n\n```javascript\nlet hoveredDistrictId = null;\n\nmap.on('mousemove', 'districts-fill', (e) => {\n    map.getCanvas().style.cursor = 'pointer';\n    \n    if (e.features.length > 0) {\n        if (hoveredDistrictId !== null) {\n            map.setFeatureState({ source: 'districts', id: hoveredDistrictId }, { hover: false });\n        }\n        hoveredDistrictId = e.features[0].id;\n        map.setFeatureState({ source: 'districts', id: hoveredDistrictId }, { hover: true });\n    }\n});\n\nmap.on('mouseleave', 'districts-fill', () => {\n    map.getCanvas().style.cursor = '';\n    if (hoveredDistrictId !== null) {\n        map.setFeatureState({ source: 'districts', id: hoveredDistrictId }, { hover: false });\n    }\n    hoveredDistrictId = null;\n});\n\n// 클릭 시 상세 팝업\nmap.on('click', 'districts-fill', (e) => {\n    const props = e.features[0].properties;\n    const changeColor = props.changeRate >= 0 ? '#ff4444' : '#4444ff';\n    const changeSign = props.changeRate >= 0 ? '+' : '';\n    \n    new mapboxgl.Popup()\n        .setLngLat(e.lngLat)\n        .setHTML(`\n            <div style=\"padding: 8px;\">\n                <h3 style=\"margin: 0 0 8px 0;\">${props.name}</h3>\n                <p style=\"margin: 4px 0;\">평당 가격: <b>${(props.avgPrice / 10000).toFixed(0)}만원</b></p>\n                <p style=\"margin: 4px 0; color: ${changeColor};\">\n                    변동률: ${changeSign}${props.changeRate}%\n                </p>\n            </div>\n        `)\n        .addTo(map);\n});\n```\n\n### 범례 추가\n\n```html\n<div id=\"legend\" style=\"position: absolute; bottom: 20px; left: 20px; background: white; padding: 10px; border-radius: 4px;\">\n    <h4>평당 가격</h4>\n    <div><span style=\"background: #fef0d9; width: 20px; height: 10px; display: inline-block;\"></span> 500만 이하</div>\n    <div><span style=\"background: #fdbb84; width: 20px; height: 10px; display: inline-block;\"></span> 500-1000만</div>\n    <div><span style=\"background: #fc8d59; width: 20px; height: 10px; display: inline-block;\"></span> 1000-1500만</div>\n    <div><span style=\"background: #d7301f; width: 20px; height: 10px; display: inline-block;\"></span> 1500만 이상</div>\n</div>\n```\n\n---\n\n## 공통: 동적 데이터 로드\n\n### API에서 GeoJSON 로드\n\n```javascript\nasync function loadDistricts() {\n    const response = await fetch('/api/districts?city=seoul');\n    const geojson = await response.json();\n    \n    if (map.getSource('districts')) {\n        map.getSource('districts').setData(geojson);\n    } else {\n        map.addSource('districts', { type: 'geojson', data: geojson, generateId: true });\n        // 레이어 추가...\n    }\n}\n```\n\n### 필터링\n\n```javascript\n// 특정 조건만 표시\nmap.setFilter('districts-fill', ['>', ['get', 'avgPrice'], 10000000]);\n\n// 필터 해제\nmap.setFilter('districts-fill', null);\n```\n\n## 모범 사례\n\n1. **generateId 필수**: Feature State 활용 시 필요\n2. **load 이벤트 후 작업**: 소스/레이어는 반드시 `map.on('load', ...)` 내에서\n3. **호버 상태 정리**: `mouseleave`에서 상태 초기화 필수\n4. **성능**: 격자는 뷰포트 범위로 제한, 전체 로드 금지\n5. **메모리**: 컴포넌트 언마운트 시 `map.remove()` 호출\n\n## 참고 자료\n\n- [Mapbox GL JS v3 Documentation](https://docs.mapbox.com/mapbox-gl-js/)\n- [Turf.js squareGrid](https://turfjs.org/docs/#squareGrid)",
    "docType": "original",
    "category": "Frontend",
    "tags": [
      "Mapbox",
      "JavaScript",
      "GeoJSON",
      "Visualization",
      "Maps"
    ],
    "readingTime": 5,
    "wordCount": 998,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "streams-audit-pipeline",
    "slug": "streams-audit-pipeline",
    "path": "database/redis",
    "fullPath": "database/redis/streams-audit-pipeline",
    "title": "Redis Streams 기반 비동기 감사 파이프라인 구축",
    "excerpt": "Redis Streams와 Consumer Group을 활용하여 At-least-once 전달과 Dead Letter 처리를 지원하는 비동기 감사 파이프라인을 구축하는 방법을 알아봅니다.",
    "content": "# Redis Streams 기반 비동기 감사 파이프라인 구축\n\n## 개요\n\n데이터 변경 이벤트를 안정적으로 처리해야 하는 감사(Audit) 시스템에서 **Redis Streams**는 강력한 선택입니다. 이 글에서는 메시지 유실 없는 감사 파이프라인을 설계하고, 특히 처리 실패 시의 복구 메커니즘을 포함한 구현 방법을 다룹니다.\n\n## 왜 Redis Streams인가?\n\n### 장점\n\n| 특성 | 설명 |\n|------|------|\n| **At-least-once 전달** | ACK 메커니즘과 PEL을 통한 메시지 유실 방지 |\n| **순서 보장** | 스트림 내 메시지 인입 순서 유지 |\n| **고성능** | 인메모리 기반 높은 처리량 |\n| **영속성** | AOF/RDB 설정으로 데이터 지속성 보장 |\n| **Consumer Group** | 여러 워커 간 수평 확장 및 부하 분산 |\n\n### 단점\n\n| 특성 | 설명 |\n|------|------|\n| **메모리 압박** | 데이터가 누적되므로 `XTRIM` 등을 통한 관리가 필수적임 |\n| **상태 관리 복잡성** | Pending 메시지(PEL) 및 재시도 로직을 직접 제어해야 함 |\n\n## 아키텍처 설계\n\n### 파이프라인 흐름\n\n```mermaid\ngraph TD\n    %% Nodes\n    API[\"API Server\"]\n    RS[\"Redis Stream<br/>(audit-events)\"]\n    AW[\"Audit Worker<br/>(Consumer)\"]\n    DLS[\"Dead Letter Stream\"]\n    DLW[\"Dead Letter Worker\"]\n\n    %% Flow\n    API --> RS\n    RS --> AW\n    \n    %% Error Flow\n    AW -- \"실패 시\" --> DLS\n    RS -. \"파싱 실패 시\" .-> DLS\n    \n    DLS --> DLW\n\n    %% Styling\n    style API fill:#f9f9f9,stroke:#333\n    style RS fill:#e1f5fe,stroke:#01579b\n    style AW fill:#e1f5fe,stroke:#01579b\n    style DLS fill:#fff3e0,stroke:#e65100\n    style DLW fill:#fff3e0,stroke:#e65100\n```\n\n### 메시지 구조\n\nRedis Streams의 메시지는 불변(Immutable)입니다. 따라서 재시도 횟수 같은 상태값은 메시지 내부에 담기보다 Redis가 제공하는 metadata(delivery count)를 활용하는 것이 효율적입니다.\n\n```go\npackage audit\n\nimport \"time\"\n\n// EventMessage는 감사 이벤트 메시지입니다.\ntype EventMessage struct {\n    ID            string                 `json:\"id\"`\n    Collection    string                 `json:\"collection\"`\n    DocumentURI   string                 `json:\"document_uri\"`\n    Action        string                 `json:\"action\"` // CREATE, UPDATE, DELETE\n    Version       int32                  `json:\"version\"`\n    Payload       map[string]interface{} `json:\"payload\"`\n    Timestamp     time.Time              `json:\"timestamp\"`\n}\n\n```\n\n## 핵심 구현\n\n### 메시지 발행자 (Producer)\n\n```go\npackage audit\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \n    \"[github.com/redis/go-redis/v9](https://github.com/redis/go-redis/v9)\"\n)\n\nconst (\n    AuditStreamKey = \"audit-events-stream\"\n)\n\ntype EventProducer struct {\n    client redis.UniversalClient\n}\n\nfunc NewEventProducer(client redis.UniversalClient) *EventProducer {\n    return &EventProducer{client: client}\n}\n\n// Publish는 이벤트를 스트림에 발행합니다.\nfunc (p *EventProducer) Publish(ctx context.Context, event *EventMessage) (string, error) {\n    payload, err := json.Marshal(event)\n    if err != nil {\n        return \"\", fmt.Errorf(\"marshal event: %w\", err)\n    }\n    \n    messageID, err := p.client.XAdd(ctx, &redis.XAddArgs{\n        Stream: AuditStreamKey,\n        Values: map[string]interface{}{\n            \"payload\": payload,\n        },\n    }).Result()\n    \n    if err != nil {\n        return \"\", fmt.Errorf(\"xadd: %w\", err)\n    }\n    \n    return messageID, nil\n}\n\n```\n\n### 워커 (Consumer)\n\nRedis Streams에서 `>` ID는 새 메시지만을 의미합니다. 프로세스 재시작 시 처리되지 못한 메시지를 복구하려면 `0` ID를 통해 PEL(Pending Entries List)을 먼저 확인해야 합니다.\n\n```go\n// processMessages는 새 메시지와 Pending 메시지를 함께 처리합니다.\nfunc (w *StreamWorker) processMessages(ctx context.Context) {\n    // 전략: PEL(Pending Entries List)이 비워질 때까지 우선 처리한 후 새 메시지로 이동\n    \n    for {\n        // 1. 본인의 Pending 메시지(\"0\") 확인\n        msgs, err := w.readBatch(ctx, \"0\")\n        if err != nil || len(msgs) == 0 {\n            break // 더 이상 처리할 Pending 메시지가 없으면 탈출\n        }\n        \n        for _, m := range msgs {\n            w.handleMessage(ctx, m)\n        }\n        \n        // BatchSize보다 적게 가져왔다면 PEL이 거의 비어있다는 뜻이므로 다음으로 진행\n        if int64(len(msgs)) < w.config.BatchSize {\n            break\n        }\n    }\n\n    // 2. 이제 새 메시지(\">\") 처리\n    msgs, _ := w.readBatch(ctx, \">\")\n    for _, m := range msgs {\n        w.handleMessage(ctx, m)\n    }\n}\n\n// 공통 읽기 로직 분리\nfunc (w *StreamWorker) readBatch(ctx context.Context, id string) ([]redis.XMessage, error) {\n    streams, err := w.client.XReadGroup(ctx, &redis.XReadGroupArgs{\n        Group:    w.config.Group,\n        Consumer: w.config.Consumer,\n        Streams:  []string{w.config.Stream, id},\n        Count:    w.config.BatchSize,\n        Block:    w.config.PollInterval,\n    }).Result()\n    \n    if err != nil || len(streams) == 0 {\n        return nil, err\n    }\n    return streams[0].Messages, nil\n}\n\nfunc (w *StreamWorker) handleMessage(ctx context.Context, msg redis.XMessage) {\n    var event EventMessage\n    \n    // 안전한 타입 단언\n    payloadRaw, ok := msg.Values[\"payload\"].(string)\n    if !ok {\n        w.moveToDeadLetter(ctx, msg, fmt.Errorf(\"invalid payload type\"))\n        return\n    }\n\n    if err := json.Unmarshal([]byte(payloadRaw), &event); err != nil {\n        w.moveToDeadLetter(ctx, msg, err)\n        return\n    }\n\n    // 핸들러 호출\n    errs := w.handler.Handle(ctx, []*EventMessage{&event})\n    \n    if len(errs) > 0 && errs[0] != nil {\n        w.handleFailure(ctx, msg, errs[0])\n        return\n    }\n    \n    // 성공 시 ACK를 보내 PEL에서 제거\n    w.client.XAck(ctx, w.config.Stream, w.config.Group, msg.ID)\n}\n\nfunc (w *StreamWorker) handleFailure(ctx context.Context, msg redis.XMessage, err error) {\n    // XPENDING으로 현재 메시지의 전달 횟수(delivery count) 확인\n    pends, _ := w.client.XPendingExt(ctx, &redis.XPendingExtArgs{\n        Stream: w.config.Stream,\n        Group:  w.config.Group,\n        Start:  msg.ID,\n        End:    msg.ID,\n        Count:  1,\n    }).Result()\n\n    if len(pends) > 0 && int(pends[0].Count) >= w.config.MaxRetries {\n        // 최대 재시도 초과 시 Dead Letter 이동 후 ACK\n        w.moveToDeadLetter(ctx, msg, err)\n        w.client.XAck(ctx, w.config.Stream, w.config.Group, msg.ID)\n        return\n    }\n    \n    // ACK를 하지 않으면 다음 \"0\" ID 조회 시 재전달됨\n}\n\nfunc (w *StreamWorker) moveToDeadLetter(ctx context.Context, msg redis.XMessage, reason error) {\n    w.client.XAdd(ctx, &redis.XAddArgs{\n        Stream: w.config.DeadLetterStream,\n        Values: map[string]interface{}{\n            \"original_id\": msg.ID,\n            \"payload\":     msg.Values[\"payload\"],\n            \"error\":       reason.Error(),\n            \"failed_at\":   time.Now().Format(time.RFC3339),\n        },\n    })\n}\n\n```\n\n## 모범 사례\n\n1. **ID \"0\"과 \">\"의 조합**: `>`만 사용하면 장애 발생 시 처리 중이던 메시지가 영원히 Pending 상태로 남게 됩니다. 반드시 `0` ID 조회를 병행하세요.\n2. **ACK 신중히**: 로직이 완전히 성공한 후에만 `XACK`를 호출해야 At-least-once를 보장할 수 있습니다.\n3. **타입 안전성**: Redis 데이터 유효성을 믿지 마세요. 타입 단언 시 반드시 `ok` 패턴을 사용해 패닉을 방지해야 합니다.\n4. **XTRIM 정기 실행**: 감사 로그는 양이 매우 많으므로 스트림 생성 시 혹은 주기적으로 `XTRIM`을 수행해 메모리를 관리하세요.\n\n## 참고 자료\n\n* [Redis Streams 공식 문서](https://redis.io/docs/data-types/streams/)\n* [go-redis 라이브러리](https://github.com/redis/go-redis)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "Redis",
      "Streams",
      "Event-Driven",
      "Architecture"
    ],
    "readingTime": 5,
    "wordCount": 819,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "postgis-geojson-guide",
    "slug": "postgis-geojson-guide",
    "path": "database/postgresql",
    "fullPath": "database/postgresql/postgis-geojson-guide",
    "title": "PostGIS와 GeoJSON을 활용한 공간 데이터 관리",
    "excerpt": "PostGIS에서 GeoJSON 형식의 공간 데이터를 저장, 변환, 조회하는 핵심 함수와 인덱싱 전략을 알아봅니다.",
    "content": "# PostGIS와 GeoJSON을 활용한 공간 데이터 관리\n\n## 개요\n\n**PostGIS**는 PostgreSQL의 공간 확장으로, 지리 데이터를 저장하고 쿼리할 수 있습니다. **GeoJSON**은 지리 정보를 표현하는 JSON 기반 표준(RFC 7946)입니다.\n\n## 테이블 설계\n\n### 기본 공간 테이블\n\n```sql\nCREATE EXTENSION IF NOT EXISTS postgis;\n\nCREATE TABLE regions (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) NOT NULL,\n    -- SRID 4326 = WGS84 (위경도)\n    geom GEOMETRY(MultiPolygon, 4326)\n);\n\n-- 공간 인덱스 필수\nCREATE INDEX idx_regions_geom ON regions USING GIST(geom);\n```\n\n### SRID 선택\n\n| SRID | 좌표계 | 용도 |\n|------|--------|------|\n| 4326 | WGS84 위경도 | GeoJSON 표준, GPS |\n| 3857 | Web Mercator | 웹 지도 타일 |\n| 5186 | Korea TM | 한국 측량 |\n\n## GeoJSON → PostGIS 저장\n\n### ST_GeomFromGeoJSON\n\nGeoJSON 문자열을 Geometry로 변환:\n\n```sql\n-- 단일 폴리곤 삽입\nINSERT INTO regions (name, geom)\nVALUES (\n    '서울시',\n    ST_GeomFromGeoJSON('{\n        \"type\": \"Polygon\",\n        \"coordinates\": [[[126.9, 37.5], [127.1, 37.5], [127.1, 37.6], [126.9, 37.6], [126.9, 37.5]]]\n    }')\n);\n\n-- SRID 명시 (PostGIS 3.0+는 기본 4326)\nINSERT INTO regions (name, geom)\nVALUES (\n    '부산시',\n    ST_SetSRID(ST_GeomFromGeoJSON('{\"type\": \"Polygon\", \"coordinates\": ...}'), 4326)\n);\n```\n\n### 배치 삽입\n\n```sql\n-- JSON 배열에서 일괄 삽입\nINSERT INTO regions (name, geom)\nSELECT \n    feature->>'name',\n    ST_GeomFromGeoJSON(feature->'geometry')\nFROM jsonb_array_elements(:geojson_features::jsonb) AS feature;\n```\n\n## PostGIS → GeoJSON 조회\n\n### ST_AsGeoJSON\n\nGeometry를 GeoJSON 문자열로 변환:\n\n```sql\n-- 기본 변환\nSELECT id, name, ST_AsGeoJSON(geom) AS geojson\nFROM regions;\n\n-- 좌표 소수점 6자리로 제한 (위경도 약 0.1m 정밀도)\nSELECT ST_AsGeoJSON(geom, 6) FROM regions;\n\n-- BBox 포함 (옵션 1)\nSELECT ST_AsGeoJSON(geom, 6, 1) FROM regions;\n```\n\n### FeatureCollection 생성\n\n클라이언트에 전달할 완전한 GeoJSON 생성:\n\n```sql\nSELECT json_build_object(\n    'type', 'FeatureCollection',\n    'features', json_agg(\n        json_build_object(\n            'type', 'Feature',\n            'id', id,\n            'geometry', ST_AsGeoJSON(geom, 6)::json,\n            'properties', json_build_object('name', name)\n        )\n    )\n) AS geojson\nFROM regions;\n```\n\n## 공간 쿼리\n\n### 포함 관계\n\n```sql\n-- 특정 좌표가 어느 지역에 속하는지\nSELECT name FROM regions\nWHERE ST_Contains(geom, ST_SetSRID(ST_Point(127.0, 37.5), 4326));\n```\n\n### 반경 검색\n\n```sql\n-- 반경 10km 내 지역 (Geography 타입 활용)\nSELECT name, ST_Distance(geom::geography, ST_Point(127.0, 37.5)::geography) AS distance_m\nFROM regions\nWHERE ST_DWithin(geom::geography, ST_Point(127.0, 37.5)::geography, 10000)\nORDER BY distance_m;\n```\n\n### 교차 영역\n\n```sql\n-- 두 지역의 교집합\nSELECT ST_AsGeoJSON(ST_Intersection(a.geom, b.geom))\nFROM regions a, regions b\nWHERE a.name = '서울시' AND b.name = '경기도';\n```\n\n## 인덱스 전략\n\n### GIST 인덱스\n\n공간 쿼리 성능의 핵심:\n\n```sql\n-- 기본 공간 인덱스\nCREATE INDEX idx_geom ON regions USING GIST(geom);\n\n-- Geography 인덱스 (거리 계산용)\nCREATE INDEX idx_geom_geog ON regions USING GIST((geom::geography));\n```\n\n### 클러스터링\n\n자주 함께 조회되는 데이터를 물리적으로 인접 배치:\n\n```sql\nCLUSTER regions USING idx_regions_geom;\n```\n\n## 좌표계 변환\n\n```sql\n-- WGS84 → Web Mercator\nSELECT ST_Transform(geom, 3857) FROM regions;\n\n-- 면적 계산 (정확한 계산을 위해 적절한 투영 사용)\nSELECT name, ST_Area(ST_Transform(geom, 5186)) AS area_m2\nFROM regions;\n```\n\n## 폴리곤 유효성\n\n```sql\n-- 유효성 검사\nSELECT name, ST_IsValid(geom), ST_IsValidReason(geom)\nFROM regions\nWHERE NOT ST_IsValid(geom);\n\n-- 자동 수정\nUPDATE regions SET geom = ST_MakeValid(geom) WHERE NOT ST_IsValid(geom);\n\n-- GeoJSON 표준 준수 (Right-Hand Rule)\nUPDATE regions SET geom = ST_ForcePolygonCCW(geom);\n```\n\n## 모범 사례\n\n1. **SRID 4326**: GeoJSON과 호환, 웹 서비스 표준\n2. **GIST 인덱스 필수**: 공간 쿼리 성능 결정\n3. **좌표 정밀도 제한**: `ST_AsGeoJSON(geom, 6)`으로 불필요한 정밀도 제거\n4. **유효성 검사**: 삽입 전 `ST_IsValid` 확인\n5. **Geography 타입**: 거리 계산이 중요하면 Geography 사용\n\n## 참고 자료\n\n- [PostGIS 3.4 Documentation](https://postgis.net/docs/)\n- [GeoJSON RFC 7946](https://datatracker.ietf.org/doc/html/rfc7946)",
    "docType": "original",
    "category": "Database",
    "tags": [
      "PostGIS",
      "PostgreSQL",
      "GeoJSON",
      "Spatial",
      "GIS"
    ],
    "readingTime": 3,
    "wordCount": 538,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "wiredtiger-storage-engine",
    "slug": "wiredtiger-storage-engine",
    "path": "database/mongodb",
    "fullPath": "database/mongodb/wiredtiger-storage-engine",
    "title": "MongoDB WiredTiger 스토리지 엔진 이해하기",
    "excerpt": "MongoDB의 기본 스토리지 엔진인 WiredTiger의 아키텍처, 캐시, 체크포인트, Lock-Free 알고리즘까지 깊이 있게 알아봅니다.",
    "content": "# MongoDB WiredTiger 스토리지 엔진 이해하기\n\n## 개요\n\n**WiredTiger**는 MongoDB 3.2부터 기본 스토리지 엔진으로 채택된 고성능 스토리지 엔진입니다. 문서 수준 동시성 제어와 압축을 지원하며, 대부분의 워크로드에서 뛰어난 성능을 제공합니다.\n\n## 핵심 아키텍처\n\n### 문서 수준 잠금 (Document-Level Locking)\n\nWiredTiger의 가장 큰 장점은 **문서 수준의 동시성 제어**입니다.\n\n| 스토리지 엔진 | 잠금 수준 | 동시성 |\n|-------------|---------|-------|\n| MMAPv1 (레거시) | 컬렉션 수준 | 낮음 |\n| WiredTiger | 문서 수준 | 높음 |\n\n```javascript\n// 서로 다른 문서에 대한 동시 쓰기가 병렬로 처리됨\ndb.users.updateOne({ _id: 1 }, { $set: { name: \"Alice\" } })\ndb.users.updateOne({ _id: 2 }, { $set: { name: \"Bob\" } })  // 블로킹 없음\n```\n\n### MVCC (Multi-Version Concurrency Control)\n\nWiredTiger는 **MVCC**를 사용하여 읽기와 쓰기 작업이 서로를 차단하지 않습니다.\n\n- 읽기 작업: 시작 시점의 스냅샷을 참조\n- 쓰기 작업: 새 버전 생성\n- 충돌 시: 자동 재시도 메커니즘\n\n---\n\n## 데이터 적용 순서\n\nMongoDB에서 데이터가 저장되는 순서를 이해하는 것이 중요합니다:\n\n```\n1. WAL (Write-Ahead Log) 기록\n2. Data Memory 적용 (공유 캐시)\n3. OpLog 기록 (Replica Set용)\n4. Disk Flush (체크포인트)\n```\n\n이 순서 덕분에 장애 시에도 WAL을 통해 데이터를 복구할 수 있습니다.\n\n---\n\n## 공유 캐시 (Shared Cache)\n\nWiredTiger의 공유 캐시는 MySQL의 Buffer Pool과 유사한 역할을 합니다.\n\n### MySQL Buffer Pool과의 차이\n\n| 특성 | MySQL Buffer Pool | WiredTiger Cache |\n|-----|-------------------|------------------|\n| 캐싱 방식 | B-Tree 상의 주소 사용 | 메모리 주소로 변환하여 적재 |\n| 캐싱 속도 | 빠름 | 상대적으로 느림 (변환 과정) |\n| 읽기 성능 | 보통 | 캐싱 후 더 빠름 |\n\nWiredTiger는 데이터를 메모리에 적합한 트리 형태로 **재구성**하여 적재합니다. 이 변환 과정으로 인해 초기 캐싱은 느릴 수 있지만, 일단 캐싱되면 RDB보다 빠른 읽기 성능을 제공합니다.\n\n### 캐시 설정\n\n```yaml\n# mongod.conf\nstorage:\n  wiredTiger:\n    engineConfig:\n      cacheSizeGB: 4  # 권장: (RAM - 1GB) / 2\n```\n\n**기본 캐시 크기 계산:**\n\n- (RAM - 1GB) × 50%\n- 또는 256MB 중 큰 값\n\n---\n\n## Lock-Free 알고리즘\n\nWiredTiger는 높은 동시성을 위해 **Lock-Free 알고리즘**을 사용합니다.\n\n### Hazard Pointer\n\n- 현재 데이터를 참조하고 있는 메모리 주소를 Hazard Pointer에 등록\n- 캐시에서 제거(Eviction) 시 Hazard Pointer에 등록된 데이터는 보호\n- Disk Flush 여부도 Hazard Pointer를 통해 결정\n\n### Skip List\n\n- Undo Log를 Skip List로 관리\n- 레코드 변경 시 이전 버전을 Skip List에 추가\n- MVCC 구현의 핵심 자료구조\n\n---\n\n## Cache Eviction\n\n캐시의 빈 공간을 적절히 유지하여 새 데이터를 적재할 수 있도록 합니다.\n\n### 동작 방식\n\n- **백그라운드 스레드**: 평상시 Eviction 처리\n- **포그라운드 스레드**: 백그라운드가 공간 확보 실패 시 직접 수행 (성능 저하 발생)\n\n### 튜닝 파라미터\n\n| 파라미터 | 설명 | 기본값 |\n|---------|------|-------|\n| `threads_max` | Eviction 스레드 최대 개수 | 4 (1~20) |\n| `threads_min` | Eviction 스레드 최소 개수 | 1 (1~20) |\n| `eviction_dirty_target` | 더티 페이지 비율 유지 목표 | 5% |\n| `eviction_target` | 전체 캐시 사용률 목표 | 80% |\n\n```yaml\n# 고급 Eviction 설정\nstorage:\n  wiredTiger:\n    engineConfig:\n      eviction:\n        threads_max: 8\n        threads_min: 4\n```\n\n> **주의**: Eviction이 포그라운드에서 실행되면 쓰기 성능이 급격히 저하됩니다. `cache eviction` 관련 지표를 모니터링하세요.\n\n---\n\n## 데이터 압축\n\nWiredTiger는 두 수준의 압축을 지원합니다:\n\n### 컬렉션 데이터 압축\n\n```javascript\n// 컬렉션 생성 시 압축 알고리즘 지정\ndb.createCollection(\"logs\", {\n  storageEngine: {\n    wiredTiger: {\n      configString: \"block_compressor=zstd\"\n    }\n  }\n})\n```\n\n| 알고리즘 | 압축률 | 속도 | 용도 |\n|---------|-------|-----|------|\n| `snappy` (기본) | 보통 | 빠름 | 범용 |\n| `zlib` | 높음 | 느림 | 아카이브 |\n| `zstd` | 높음 | 빠름 | **권장** (4.2+) |\n| `none` | - | - | 실시간 처리 |\n\n> **zstd 권장 이유**: 무손실 압축이면서 압축/해제 속도가 준수함\n\n### 인덱스 프리픽스 압축\n\n인덱스는 기본적으로 **프리픽스 압축**이 적용됩니다:\n\n```javascript\n// 인덱스 압축 비활성화 예시\ndb.collection.createIndex(\n  { field: 1 },\n  { storageEngine: { wiredTiger: { configString: \"prefix_compression=false\" } } }\n)\n```\n\n---\n\n## 체크포인트 (Checkpoint)\n\n체크포인트는 **데이터 파일과 트랜잭션 로그가 동기화되는 시점**입니다. DB 장애 시 복구 시점을 결정하는 기준이 됩니다.\n\n### Sharp Checkpoint\n\nMongoDB는 **Sharp Checkpoint** 방식을 사용합니다:\n\n- 체크포인트 실행 시점에 더티 페이지를 **한 번에 모아서** 디스크에 내려씀\n- Fuzzy Checkpoint(점진적 방식)와 대비되는 개념\n\n### 체크포인트 트리거\n\n기본적으로 다음 조건에서 체크포인트가 발생합니다:\n\n- **60초** 경과\n- **2GB** 저널 데이터 누적\n\n### 체크포인트 옵션\n\n| 옵션 | 설명 | 기본값 |\n|-----|------|-------|\n| `log_size` | 이 크기만큼 트랜잭션 로그 쓰면 체크포인트 실행 | 0 (자동) |\n| `wait` | 주기적 체크포인트 간격 (초) | 0 (자동) |\n\n```yaml\n# mongod.conf\nstorage:\n  wiredTiger:\n    engineConfig:\n      checkpointSizeMB: 1024\n```\n\n---\n\n## 저널링 (Journaling)\n\nWrite-Ahead Logging(WAL)으로 데이터 내구성을 보장합니다.\n\n- Journal Log는 데이터 디렉토리 하위 `journal/` 폴더에 저장\n- 장애 발생 시 Journal Log를 사용해 데이터 복구\n\n```yaml\nstorage:\n  journal:\n    enabled: true\n    commitIntervalMs: 100  # 기본값\n```\n\n---\n\n## 성능 튜닝\n\n### 프로덕션 권장 설정\n\n```yaml\n# mongod.conf\nstorage:\n  wiredTiger:\n    engineConfig:\n      cacheSizeGB: 8\n      journalCompressor: snappy\n    collectionConfig:\n      blockCompressor: zstd\n    indexConfig:\n      prefixCompressionEnabled: true\n```\n\n### 모니터링 명령어\n\n```javascript\n// WiredTiger 전체 통계\ndb.serverStatus().wiredTiger\n\n// 캐시 상태\ndb.serverStatus().wiredTiger.cache\n\n// 컬렉션별 통계\ndb.collection.stats().wiredTiger\n```\n\n---\n\n## 주의사항\n\n1. **캐시 크기**: 시스템 RAM의 50% 이하 권장\n2. **압축**: CPU 오버헤드와 저장 공간 트레이드오프 고려\n3. **저널링**: 비활성화 시 데이터 손실 위험\n4. **Eviction 모니터링**: 포그라운드 Eviction 발생 시 성능 저하\n5. **체크포인트**: Sharp Checkpoint로 인한 일시적 I/O 스파이크 고려\n\n## 참고 자료\n\n- [MongoDB WiredTiger 공식 문서](https://www.mongodb.com/docs/manual/core/wiredtiger/)\n- [WiredTiger GitHub](https://github.com/wiredtiger/wiredtiger)\n- [MongoDB 총 정리 (liltdevs)](https://liltdevs.tistory.com/216)",
    "docType": "original",
    "category": "Database",
    "tags": [
      "MongoDB",
      "WiredTiger",
      "Database",
      "Storage Engine"
    ],
    "readingTime": 5,
    "wordCount": 865,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "sharding-guide",
    "slug": "sharding-guide",
    "path": "database/mongodb",
    "fullPath": "database/mongodb/sharding-guide",
    "title": "MongoDB 샤딩(Sharding) 완벽 가이드",
    "excerpt": "MongoDB 샤딩의 개념부터 샤드 키 선택, 클러스터 구성까지 실전 가이드를 제공합니다.",
    "content": "# MongoDB 샤딩(Sharding) 완벽 가이드\n\n## 샤딩이란?\n\n**샤딩**은 대용량 데이터를 여러 서버에 분산 저장하는 수평 확장(Horizontal Scaling) 방식입니다. MongoDB는 자동 샤딩을 지원하여 데이터가 증가해도 성능을 유지할 수 있습니다.\n\n## 샤딩 아키텍처\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                      Application                         │\n└─────────────────────────────────────────────────────────┘\n                            │\n                            ▼\n┌─────────────────────────────────────────────────────────┐\n│                       mongos                             │\n│                   (Query Router)                         │\n└─────────────────────────────────────────────────────────┘\n                            │\n        ┌───────────────────┼───────────────────┐\n        ▼                   ▼                   ▼\n┌───────────────┐   ┌───────────────┐   ┌───────────────┐\n│   Shard 1     │   │   Shard 2     │   │   Shard 3     │\n│  (Replica Set)│   │  (Replica Set)│   │  (Replica Set)│\n└───────────────┘   └───────────────┘   └───────────────┘\n                            │\n                            ▼\n┌─────────────────────────────────────────────────────────┐\n│              Config Servers (Replica Set)                │\n│                  (메타데이터 저장)                        │\n└─────────────────────────────────────────────────────────┘\n```\n\n### 구성 요소\n\n| 구성 요소 | 역할 |\n|---------|------|\n| **mongos** | 클라이언트 요청을 적절한 샤드로 라우팅 |\n| **Shard** | 실제 데이터를 저장하는 레플리카 셋 |\n| **Config Server** | 클러스터 메타데이터 및 청크 정보 저장 |\n\n## 샤드 키 (Shard Key)\n\n샤드 키는 데이터를 분산하는 기준이 되는 필드입니다. **샤드 키 선택은 성능에 직접적인 영향**을 미칩니다.\n\n### 좋은 샤드 키의 조건\n\n1. **높은 카디널리티**: 다양한 값을 가져야 함\n2. **균등한 분포**: 데이터가 골고루 분산되어야 함\n3. **쿼리 패턴 부합**: 자주 사용되는 쿼리 조건과 일치\n\n### 샤드 키 예시\n\n```javascript\n// 좋은 예: 높은 카디널리티 + 균등 분포\nsh.shardCollection(\"mydb.orders\", { orderId: \"hashed\" })\n\n// 범위 샤딩: 범위 쿼리에 유리\nsh.shardCollection(\"mydb.logs\", { timestamp: 1 })\n\n// 복합 샤드 키: 더 세밀한 분산\nsh.shardCollection(\"mydb.users\", { country: 1, createdAt: 1 })\n```\n\n### 샤드 키 전략\n\n| 전략 | 장점 | 단점 | 적합한 경우 |\n|-----|------|------|-----------|\n| **Hashed** | 균등 분산 | 범위 쿼리 비효율 | 랜덤 액세스 |\n| **Ranged** | 범위 쿼리 효율적 | 핫스팟 위험 | 시계열 데이터 |\n| **Compound** | 유연성 | 설계 복잡 | 복잡한 쿼리 |\n\n## 청크 (Chunk)\n\n데이터는 **청크** 단위로 샤드에 분산됩니다.\n\n```javascript\n// 청크 크기 확인\nuse config\ndb.settings.find({ _id: \"chunksize\" })\n\n// 청크 크기 변경 (MB 단위, 기본 128MB)\ndb.settings.updateOne(\n  { _id: \"chunksize\" },\n  { $set: { value: 64 } },\n  { upsert: true }\n)\n```\n\n### 청크 밸런싱\n\nMongoDB는 **밸런서**를 통해 청크를 자동으로 균형 분배합니다:\n\n```javascript\n// 밸런서 상태 확인\nsh.getBalancerState()\n\n// 밸런서 활성화/비활성화\nsh.startBalancer()\nsh.stopBalancer()\n\n// 특정 시간대에만 밸런싱\ndb.settings.updateOne(\n  { _id: \"balancer\" },\n  { $set: { activeWindow: { start: \"02:00\", stop: \"06:00\" } } }\n)\n```\n\n## 샤딩 클러스터 구성\n\n### 1. Config Server 설정\n\n```yaml\n# config-server.conf\nsharding:\n  clusterRole: configsvr\nreplication:\n  replSetName: configReplSet\nnet:\n  port: 27019\n```\n\n### 2. Shard 설정\n\n```yaml\n# shard.conf\nsharding:\n  clusterRole: shardsvr\nreplication:\n  replSetName: shard1ReplSet\nnet:\n  port: 27018\n```\n\n### 3. mongos 설정\n\n```yaml\n# mongos.conf\nsharding:\n  configDB: configReplSet/config1:27019,config2:27019,config3:27019\nnet:\n  port: 27017\n```\n\n### 4. 샤드 추가\n\n```javascript\n// mongos에 접속하여 샤드 추가\nsh.addShard(\"shard1ReplSet/shard1-1:27018,shard1-2:27018\")\nsh.addShard(\"shard2ReplSet/shard2-1:27018,shard2-2:27018\")\n\n// 샤딩 활성화\nsh.enableSharding(\"mydb\")\n\n// 컬렉션 샤딩\nsh.shardCollection(\"mydb.orders\", { customerId: \"hashed\" })\n```\n\n## 쿼리 라우팅\n\n### Targeted Query (효율적)\n\n샤드 키를 포함한 쿼리는 특정 샤드로만 전달됩니다:\n\n```javascript\n// customerId가 샤드 키일 때 - 특정 샤드만 조회\ndb.orders.find({ customerId: \"user123\" })\n```\n\n### Scatter-Gather Query (비효율적)\n\n샤드 키가 없으면 모든 샤드에 쿼리 전송:\n\n```javascript\n// 모든 샤드에 쿼리 전송 후 결과 병합\ndb.orders.find({ status: \"pending\" })\n```\n\n## 모니터링\n\n```javascript\n// 샤딩 상태 확인\nsh.status()\n\n// 각 샤드별 데이터 분포\ndb.orders.getShardDistribution()\n\n// 청크 정보\nuse config\ndb.chunks.find({ ns: \"mydb.orders\" }).pretty()\n```\n\n## 주의사항\n\n1. **샤드 키는 변경 불가**: 설계 단계에서 신중히 선택\n2. **샤드 키 값은 불변**: 한번 설정된 문서의 샤드 키 변경 불가\n3. **트랜잭션 제한**: 다중 샤드 트랜잭션은 성능 저하 가능\n4. **인덱스 필수**: 샤드 키에는 반드시 인덱스 존재해야 함\n\n## 참고 자료\n\n- [MongoDB Sharding 공식 문서](https://www.mongodb.com/docs/manual/sharding/)\n- [샤드 키 선택 가이드](https://www.mongodb.com/docs/manual/core/sharding-choose-a-shard-key/)",
    "docType": "original",
    "category": "Database",
    "tags": [
      "MongoDB",
      "Sharding",
      "Distributed Systems",
      "Database"
    ],
    "readingTime": 3,
    "wordCount": 577,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "merkle-trie-integrity",
    "slug": "merkle-trie-integrity",
    "path": "blockchain/ethereum",
    "fullPath": "blockchain/ethereum/merkle-trie-integrity",
    "title": "go-ethereum Merkle Trie를 활용한 데이터 무결성 검증",
    "excerpt": "go-ethereum의 Merkle Trie 구현을 활용하여 대량 데이터의 무결성을 효율적으로 검증하는 방법을 알아봅니다.",
    "content": "# go-ethereum Merkle Trie를 활용한 데이터 무결성 검증\n\n## 개요\n\n**Merkle Trie**는 대량의 데이터 무결성을 단일 해시값(Merkle Root)으로 증명할 수 있는 자료구조입니다. 이 글에서는 go-ethereum의 Trie 패키지를 활용하여 데이터 무결성 검증 시스템을 구축하는 방법을 다룹니다.\n\n## Merkle Trie란?\n\n### 핵심 개념\n\n```mermaid\ngraph TD\n    %% 노드 정의\n    Root[\"Merkle Root (H_root)\"]\n    HAB[\"H(AB)\"]\n    HCD[\"H(CD)\"]\n    HA[\"H(A)\"]\n    HB[\"H(B)\"]\n    HC[\"H(C)\"]\n    HD[\"H(D)\"]\n    A[\"A\"]\n    B[\"B\"]\n    C[\"C\"]\n    D[\"D\"]\n\n    %% 연결 정의 (해시 과정: 아래에서 위로)\n    HAB --> Root\n    HCD --> Root\n    HA --> HAB\n    HB --> HAB\n    HC --> HCD\n    HD --> HCD\n    A --> HA\n    B --> HB\n    C --> HC\n    D --> HD\n\n    %% 스타일링 (선택사항: 루트와 리프 노드 강조)\n    style Root fill:#f9f,stroke:#333,stroke-width:2px,color:white\n    style A fill:#fff,stroke:#333,stroke-dasharray: 5 5\n    style B fill:#fff,stroke:#333,stroke-dasharray: 5 5\n    style C fill:#fff,stroke:#333,stroke-dasharray: 5 5\n    style D fill:#fff,stroke:#333,stroke-dasharray: 5 5\n```\n\n- **Leaf 노드**: 원본 데이터의 해시\n- **내부 노드**: 자식 노드들의 해시 조합\n- **Root 노드**: 전체 데이터를 대표하는 단일 해시\n\n### 왜 Merkle Trie인가?\n\n| 장점 | 설명 |\n|------|------|\n| **효율적 검증** | O(log n) 복잡도로 특정 데이터 포함 증명 |\n| **배치 검증** | 수천 개 데이터를 단일 루트로 검증 |\n| **변조 감지** | 하나라도 변경되면 루트 해시 변경 |\n| **블록체인 호환** | 대부분의 블록체인이 사용하는 표준 구조 |\n\n## go-ethereum Trie 패키지\n\n### 설치\n\n```bash\ngo get github.com/ethereum/go-ethereum\n```\n\n### 핵심 인터페이스\n\n```go\npackage integrity\n\nimport (\n    \"github.com/ethereum/go-ethereum/common\"\n    \"github.com/ethereum/go-ethereum/core/rawdb\"\n    ethtrie \"github.com/ethereum/go-ethereum/trie\"\n    \"github.com/ethereum/go-ethereum/triedb\"\n)\n```\n\n## 핵심 구현\n\n### Trie 래퍼\n\n```go\npackage integrity\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"sync\"\n    \n    \"github.com/ethereum/go-ethereum/common\"\n    \"github.com/ethereum/go-ethereum/core/rawdb\"\n    ethtrie \"github.com/ethereum/go-ethereum/trie\"\n    \"github.com/ethereum/go-ethereum/triedb\"\n)\n\nvar (\n    ErrNodeNotFound = errors.New(\"node not found in trie\")\n    ErrInvalidProof = errors.New(\"invalid merkle proof\")\n)\n\n// LeafNode는 Trie의 리프 노드입니다.\ntype LeafNode struct {\n    key   []byte\n    value []byte\n}\n\nfunc NewLeafNode(key, value []byte) *LeafNode {\n    return &LeafNode{key: key, value: value}\n}\n\nfunc (n *LeafNode) Key() []byte   { return n.key }\nfunc (n *LeafNode) Value() []byte { return n.value }\nfunc (n *LeafNode) Hash() []byte  { return n.value }\n\n// IntegrityTrie는 데이터 무결성 검증을 위한 Merkle Trie입니다.\ntype IntegrityTrie struct {\n    trie *ethtrie.Trie\n    db   *triedb.Database\n    mu   sync.RWMutex\n}\n\n// NewIntegrityTrie는 새 Trie를 생성합니다.\nfunc NewIntegrityTrie(seedNodes []*LeafNode) (*IntegrityTrie, error) {\n    // 인메모리 데이터베이스 생성\n    memDB := rawdb.NewMemoryDatabase()\n    trieDB := triedb.NewDatabase(memDB, nil)\n    \n    // 빈 Trie 생성\n    t := ethtrie.NewEmpty(trieDB)\n    \n    integrityTrie := &IntegrityTrie{\n        trie: t,\n        db:   trieDB,\n    }\n    \n    // 초기 노드 삽입\n    for _, node := range seedNodes {\n        if err := integrityTrie.Insert(node.Key(), node.Value()); err != nil {\n            return nil, fmt.Errorf(\"insert seed node: %w\", err)\n        }\n    }\n    \n    return integrityTrie, nil\n}\n\n// Insert는 키-값 쌍을 Trie에 추가합니다.\nfunc (t *IntegrityTrie) Insert(key, value []byte) error {\n    t.mu.Lock()\n    defer t.mu.Unlock()\n    \n    return t.trie.Update(key, value)\n}\n\n// RootHash는 현재 Merkle Root를 반환합니다.\nfunc (t *IntegrityTrie) RootHash() common.Hash {\n    t.mu.RLock()\n    defer t.mu.RUnlock()\n    \n    return t.trie.Hash()\n}\n\n// Commit은 Trie 상태를 저장하고 Root를 반환합니다.\nfunc (t *IntegrityTrie) Commit() (common.Hash, error) {\n    t.mu.Lock()\n    defer t.mu.Unlock()\n    \n    // Trie 커밋\n    rootHash, _, err := t.trie.Commit(false)\n    if err != nil {\n        return common.Hash{}, fmt.Errorf(\"trie commit: %w\", err)\n    }\n    \n    // 데이터베이스에 저장\n    if err := t.db.Commit(rootHash, false); err != nil {\n        return common.Hash{}, fmt.Errorf(\"db commit: %w\", err)\n    }\n    \n    return rootHash, nil\n}\n```\n\n### 배치 데이터 처리\n\n감사 로그 등 대량 데이터를 배치로 처리:\n\n```go\n// BatchData는 배치 처리할 데이터 항목입니다.\ntype BatchData struct {\n    ID      string\n    Content []byte\n}\n\n// ComputeBatchRoot는 배치 데이터의 Merkle Root를 계산합니다.\nfunc ComputeBatchRoot(items []BatchData) (common.Hash, error) {\n    nodes := make([]*LeafNode, len(items))\n    \n    for i, item := range items {\n        // 키: 고유 ID의 해시\n        key := crypto.Keccak256([]byte(item.ID))\n        // 값: 콘텐츠의 해시\n        value := crypto.Keccak256(item.Content)\n        \n        nodes[i] = NewLeafNode(key, value)\n    }\n    \n    trie, err := NewIntegrityTrie(nodes)\n    if err != nil {\n        return common.Hash{}, err\n    }\n    \n    return trie.Commit()\n}\n```\n\n### 감사 로그 통합 예시\n\n```go\npackage audit\n\nimport (\n    \"context\"\n    \"time\"\n    \"encoding/json\"\n)\n\n// AuditBatch는 감사 로그 배치입니다.\ntype AuditBatch struct {\n    ID        string       `json:\"id\"`\n    Logs      []AuditLog   `json:\"logs\"`\n    CreatedAt time.Time    `json:\"created_at\"`\n}\n\n// AuditLog는 개별 감사 로그입니다.\ntype AuditLog struct {\n    DocumentID string `json:\"document_id\"`\n    Action     string `json:\"action\"`\n    Version    int32  `json:\"version\"`\n    Hash       string `json:\"hash\"`\n}\n\n// AnchoringService는 블록체인 앵커링 서비스입니다.\ntype AnchoringService struct {\n    blockchain BlockchainClient\n}\n\n// ProcessBatch는 배치 감사 로그를 처리하고 앵커링합니다.\nfunc (s *AnchoringService) ProcessBatch(ctx context.Context, logs []AuditLog) (*AnchorResult, error) {\n    // 1. 각 로그를 Merkle Trie 노드로 변환\n    items := make([]BatchData, len(logs))\n    for i, log := range logs {\n        content, _ := json.Marshal(log)\n        items[i] = BatchData{\n            ID:      log.DocumentID + \"_\" + fmt.Sprint(log.Version),\n            Content: content,\n        }\n    }\n    \n    // 2. Merkle Root 계산\n    merkleRoot, err := ComputeBatchRoot(items)\n    if err != nil {\n        return nil, fmt.Errorf(\"compute merkle root: %w\", err)\n    }\n    \n    // 3. 블록체인에 앵커링\n    txHash, err := s.blockchain.SubmitAnchor(ctx, merkleRoot.Hex())\n    if err != nil {\n        return nil, fmt.Errorf(\"submit anchor: %w\", err)\n    }\n    \n    return &AnchorResult{\n        MerkleRoot:      merkleRoot.Hex(),\n        TransactionHash: txHash,\n        AnchoredAt:      time.Now(),\n        LogCount:        len(logs),\n    }, nil\n}\n\ntype AnchorResult struct {\n    MerkleRoot      string    `json:\"merkle_root\"`\n    TransactionHash string    `json:\"transaction_hash\"`\n    AnchoredAt      time.Time `json:\"anchored_at\"`\n    LogCount        int       `json:\"log_count\"`\n}\n```\n\n## Merkle Proof 생성 및 검증\n\n특정 데이터가 Merkle Root에 포함되어 있음을 증명:\n\n```go\nimport (\n    \"github.com/ethereum/go-ethereum/trie\"\n)\n\n// GenerateProof는 특정 키에 대한 Merkle Proof를 생성합니다.\nfunc (t *IntegrityTrie) GenerateProof(key []byte) ([][]byte, error) {\n    t.mu.RLock()\n    defer t.mu.RUnlock()\n    \n    // Proof 노드들을 담을 메모리 DB\n    proofDB := rawdb.NewMemoryDatabase()\n    \n    // Proof 생성\n    if err := t.trie.Prove(key, proofDB); err != nil {\n        return nil, fmt.Errorf(\"generate proof: %w\", err)\n    }\n    \n    // Proof 데이터 추출\n    var proofNodes [][]byte\n    it := proofDB.NewIterator(nil, nil)\n    defer it.Release()\n    \n    for it.Next() {\n        proofNodes = append(proofNodes, common.CopyBytes(it.Value()))\n    }\n    \n    return proofNodes, nil\n}\n\n// VerifyProof는 Merkle Proof를 검증합니다.\nfunc VerifyProof(rootHash common.Hash, key []byte, proofNodes [][]byte) ([]byte, error) {\n    // Proof DB 구성\n    proofDB := rawdb.NewMemoryDatabase()\n    for _, node := range proofNodes {\n        hash := crypto.Keccak256(node)\n        proofDB.Put(hash, node)\n    }\n    \n    // Proof 검증 및 값 반환\n    value, err := trie.VerifyProof(rootHash, key, proofDB)\n    if err != nil {\n        return nil, ErrInvalidProof\n    }\n    \n    return value, nil\n}\n```\n\n### 사용 예시\n\n```go\nfunc ExampleMerkleProof() {\n    // 1. 데이터 준비\n    items := []BatchData{\n        {ID: \"doc-001\", Content: []byte(`{\"action\":\"CREATE\"}`)},\n        {ID: \"doc-002\", Content: []byte(`{\"action\":\"UPDATE\"}`)},\n        {ID: \"doc-003\", Content: []byte(`{\"action\":\"DELETE\"}`)},\n    }\n    \n    nodes := make([]*LeafNode, len(items))\n    for i, item := range items {\n        key := crypto.Keccak256([]byte(item.ID))\n        value := crypto.Keccak256(item.Content)\n        nodes[i] = NewLeafNode(key, value)\n    }\n    \n    // 2. Trie 생성 및 Root 계산\n    trie, _ := NewIntegrityTrie(nodes)\n    rootHash, _ := trie.Commit()\n    \n    fmt.Printf(\"Merkle Root: %s\\n\", rootHash.Hex())\n    \n    // 3. 특정 문서의 Proof 생성\n    targetKey := crypto.Keccak256([]byte(\"doc-002\"))\n    proof, _ := trie.GenerateProof(targetKey)\n    \n    fmt.Printf(\"Proof nodes: %d\\n\", len(proof))\n    \n    // 4. Proof 검증 (다른 시스템에서)\n    expectedValue := crypto.Keccak256([]byte(`{\"action\":\"UPDATE\"}`))\n    verifiedValue, err := VerifyProof(rootHash, targetKey, proof)\n    \n    if err != nil {\n        fmt.Println(\"Proof invalid!\")\n    } else if bytes.Equal(verifiedValue, expectedValue) {\n        fmt.Println(\"Proof verified! Data integrity confirmed.\")\n    }\n}\n```\n\n## 무결성 검증 API\n\n외부에서 데이터 무결성을 검증할 수 있는 API:\n\n```go\npackage api\n\ntype IntegrityVerification struct {\n    DocumentID   string `json:\"document_id\"`\n    Version      int32  `json:\"version\"`\n    ContentHash  string `json:\"content_hash\"`\n    MerkleRoot   string `json:\"merkle_root\"`\n    BlockchainTx string `json:\"blockchain_tx\"`\n    Verified     bool   `json:\"verified\"`\n    VerifiedAt   string `json:\"verified_at\"`\n}\n\nfunc (s *APIServer) VerifyIntegrity(ctx context.Context, req VerifyRequest) (*IntegrityVerification, error) {\n    // 1. 문서 조회\n    doc, err := s.docService.FindByVersion(ctx, req.Collection, req.URI, req.Version)\n    if err != nil {\n        return nil, err\n    }\n    \n    // 2. 문서의 앵커링 메타데이터 확인\n    anchor := doc.AnchoringMetadata\n    if anchor.Status != \"COMPLETED\" {\n        return nil, errors.New(\"document not yet anchored\")\n    }\n    \n    // 3. 블록체인에서 Merkle Root 조회\n    blockchainRoot, err := s.blockchain.GetAnchor(ctx, anchor.TransactionHash)\n    if err != nil {\n        return nil, err\n    }\n    \n    // 4. 현재 데이터로 해시 재계산\n    currentHash := computeDocumentHash(doc)\n    \n    // 5. 저장된 Merkle Root와 블록체인 Root 비교\n    verified := anchor.MerkleRoot == blockchainRoot\n    \n    return &IntegrityVerification{\n        DocumentID:   doc.URI,\n        Version:      doc.Version,\n        ContentHash:  currentHash,\n        MerkleRoot:   anchor.MerkleRoot,\n        BlockchainTx: anchor.TransactionHash,\n        Verified:     verified,\n        VerifiedAt:   time.Now().Format(time.RFC3339),\n    }, nil\n}\n```\n\n## 성능 최적화\n\n### 배치 크기 조정\n\n```go\nconst (\n    OptimalBatchSize = 1000 // Trie 연산에 최적화된 배치 크기\n    MaxBatchSize     = 10000\n)\n\nfunc ProcessWithOptimalBatch(items []BatchData) ([]common.Hash, error) {\n    var roots []common.Hash\n    \n    for i := 0; i < len(items); i += OptimalBatchSize {\n        end := i + OptimalBatchSize\n        if end > len(items) {\n            end = len(items)\n        }\n        \n        batch := items[i:end]\n        root, err := ComputeBatchRoot(batch)\n        if err != nil {\n            return nil, err\n        }\n        \n        roots = append(roots, root)\n    }\n    \n    return roots, nil\n}\n```\n\n### 캐싱\n\n```go\ntype TrieCache struct {\n    mu    sync.RWMutex\n    roots map[string]common.Hash // batchID -> rootHash\n}\n\nfunc (c *TrieCache) Get(batchID string) (common.Hash, bool) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    root, ok := c.roots[batchID]\n    return root, ok\n}\n\nfunc (c *TrieCache) Set(batchID string, root common.Hash) {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.roots[batchID] = root\n}\n```\n\n## 모범 사례\n\n1. **배치 처리**: 개별 데이터마다 Trie 생성하지 말고 배치 단위로 처리\n2. **Root 저장**: 계산된 Merkle Root는 영구 저장소에 저장\n3. **Proof 캐싱**: 자주 조회되는 데이터의 Proof는 캐싱\n4. **해시 일관성**: 동일한 해시 함수(Keccak256) 일관되게 사용\n5. **동시성 제어**: Trie 접근 시 뮤텍스로 보호\n\n## 참고 자료\n\n- [go-ethereum Trie 패키지](https://pkg.go.dev/github.com/ethereum/go-ethereum/trie)\n- [Merkle Tree 위키피디아](https://en.wikipedia.org/wiki/Merkle_tree)\n- [Ethereum Yellow Paper](https://ethereum.github.io/yellowpaper/paper.pdf)",
    "docType": "original",
    "category": "Blockchain",
    "tags": [
      "Go",
      "Ethereum",
      "MerkleTrie",
      "Cryptography",
      "DataIntegrity"
    ],
    "readingTime": 8,
    "wordCount": 1409,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "functional-options-pattern",
    "slug": "functional-options-pattern",
    "path": "backend/patterns",
    "fullPath": "backend/patterns/functional-options-pattern",
    "title": "Functional Options 패턴을 활용한 Go 설정 관리",
    "excerpt": "Go의 Functional Options 패턴을 활용하여 필수 파라미터와 선택적 설정을 명확히 분리하고, 합리적인 기본값 위에 유연한 커스터마이징을 제공하는 방법을 알아봅니다.",
    "content": "# Functional Options 패턴을 활용한 Go 설정 관리\n\n## 개요\n\n**Functional Options 패턴**은 Go에서 객체 생성 시 **필수 파라미터**와 **선택적 설정**을 명확히 분리하는 관용적인 패턴입니다.\n\n핵심 원칙:\n\n- **필수값**: 생성자의 명시적 파라미터로 전달 (없으면 컴파일 에러)\n- **선택값**: 합리적인 기본값을 정의하고, `With...` 옵션 함수로 오버라이드\n\n## 패턴의 핵심: 필수 vs 선택\n\n### 설계 의도\n\n```\nNewWorker(client, handler, opts...)\n         ↑       ↑        ↑\n      필수값   필수값   선택적 옵션들\n      \n생성자 시그니처가 \"무엇이 필수인지\"를 명확히 선언합니다.\n옵션을 전달하지 않아도 기본값으로 동작합니다.\n```\n\n| 구분 | 전달 방식 | 특징 |\n|------|----------|------|\n| **필수 파라미터** | 생성자의 명시적 인자 | 누락 시 컴파일 에러, 기본값 없음 |\n| **선택적 설정** | `...WorkerOption` 가변 인자 | 기본값 존재, 필요 시 오버라이드 |\n\n### 왜 이 구분이 중요한가?\n\n```go\n// ❌ 나쁜 예: 모든 것이 옵션\n// client가 nil이어도 컴파일은 통과 → 런타임 에러\nworker := NewWorker(\n    WithClient(client),     // 필수인데 옵션처럼 보임\n    WithHandler(handler),   // 필수인데 옵션처럼 보임\n    WithBatchSize(100),\n)\n\n// ✅ 좋은 예: 필수값은 명시적 파라미터\n// client나 handler 누락 시 컴파일 에러\nworker := NewWorker(\n    client,                 // 필수: 첫 번째 인자\n    handler,                // 필수: 두 번째 인자  \n    WithBatchSize(100),     // 선택: 기본값 10을 100으로 오버라이드\n)\n```\n\n## 기본 구현\n\n### 1. 내부 설정 구조체 (기본값 정의)\n\n```go\npackage worker\n\nimport \"time\"\n\n// workerConfig는 Worker의 \"선택적\" 설정을 담습니다.\n// 필수값(client, handler)은 여기에 포함되지 않습니다.\ntype workerConfig struct {\n    batchSize        int\n    pollInterval     time.Duration\n    maxRetries       int\n    shutdownTimeout  time.Duration\n    deadLetterStream string\n}\n\n// defaultConfig는 합리적인 기본값을 반환합니다.\n// 옵션을 전혀 전달하지 않아도 이 값으로 동작합니다.\nfunc defaultConfig() workerConfig {\n    return workerConfig{\n        batchSize:        10,                    // 기본: 10개씩 처리\n        pollInterval:     100 * time.Millisecond, // 기본: 100ms 폴링\n        maxRetries:       3,                     // 기본: 3회 재시도\n        shutdownTimeout:  30 * time.Second,      // 기본: 30초 종료 대기\n        deadLetterStream: \"dead-letter-stream\",  // 기본 DLQ 이름\n    }\n}\n```\n\n### 2. 옵션 타입과 With 함수들 (기본값 오버라이드)\n\n```go\n// WorkerOption은 기본 설정을 변경하는 함수 타입입니다.\ntype WorkerOption func(*workerConfig)\n\n// WithBatchSize는 기본값(10)을 오버라이드합니다.\nfunc WithBatchSize(size int) WorkerOption {\n    return func(c *workerConfig) {\n        if size > 0 {\n            c.batchSize = size\n        }\n    }\n}\n\n// WithPollInterval은 기본값(100ms)을 오버라이드합니다.\nfunc WithPollInterval(interval time.Duration) WorkerOption {\n    return func(c *workerConfig) {\n        if interval > 0 {\n            c.pollInterval = interval\n        }\n    }\n}\n\n// WithMaxRetries는 기본값(3)을 오버라이드합니다.\nfunc WithMaxRetries(retries int) WorkerOption {\n    return func(c *workerConfig) {\n        c.maxRetries = retries\n    }\n}\n\n// WithShutdownTimeout은 기본값(30s)을 오버라이드합니다.\nfunc WithShutdownTimeout(timeout time.Duration) WorkerOption {\n    return func(c *workerConfig) {\n        c.shutdownTimeout = timeout\n    }\n}\n\n// WithDeadLetterStream은 기본값을 오버라이드합니다.\nfunc WithDeadLetterStream(stream string) WorkerOption {\n    return func(c *workerConfig) {\n        c.deadLetterStream = stream\n    }\n}\n```\n\n### 3. 생성자 (필수 파라미터 + 선택적 옵션)\n\n```go\n// StreamWorker는 메시지 스트림을 처리하는 워커입니다.\ntype StreamWorker struct {\n    // 필수 의존성 (생성자 파라미터로 주입)\n    client  redis.UniversalClient\n    handler MessageHandler\n    \n    // 선택적 설정 (기본값 + 옵션으로 구성)\n    config  workerConfig\n    \n    stopCh  chan struct{}\n}\n\n// NewStreamWorker는 새 워커를 생성합니다.\n//\n// 파라미터:\n//   - client: Redis 클라이언트 (필수)\n//   - handler: 메시지 핸들러 (필수)\n//   - opts: 선택적 설정 (기본값 존재, 필요 시 오버라이드)\nfunc NewStreamWorker(\n    client redis.UniversalClient,   // 필수: 없으면 컴파일 에러\n    handler MessageHandler,          // 필수: 없으면 컴파일 에러\n    opts ...WorkerOption,            // 선택: 없어도 기본값으로 동작\n) *StreamWorker {\n    // 1. 기본값으로 시작\n    cfg := defaultConfig()\n    \n    // 2. 전달된 옵션들로 기본값 오버라이드\n    for _, opt := range opts {\n        opt(&cfg)\n    }\n    \n    return &StreamWorker{\n        client:  client,\n        handler: handler,\n        config:  cfg,\n        stopCh:  make(chan struct{}),\n    }\n}\n```\n\n### 4. 사용 예시\n\n```go\nfunc main() {\n    // 필수 의존성 준비\n    client := redis.NewClusterClient(&redis.ClusterOptions{\n        Addrs: []string{\"localhost:7001\"},\n    })\n    handler := &AuditHandler{}\n    \n    // Case 1: 기본값 그대로 사용 (옵션 없음)\n    // batchSize=10, pollInterval=100ms, maxRetries=3 ...\n    worker1 := NewStreamWorker(client, handler)\n    \n    // Case 2: 일부 설정만 오버라이드\n    // batchSize=100 (오버라이드), 나머지는 기본값\n    worker2 := NewStreamWorker(client, handler,\n        WithBatchSize(100),\n    )\n    \n    // Case 3: 여러 설정 오버라이드\n    worker3 := NewStreamWorker(client, handler,\n        WithBatchSize(100),              // 10 → 100\n        WithPollInterval(50*time.Millisecond), // 100ms → 50ms\n        WithMaxRetries(5),               // 3 → 5\n    )\n    \n    worker3.Start(context.Background())\n}\n```\n\n## 실제 활용 예시\n\n### 데이터베이스 클라이언트\n\n```go\ntype dbConfig struct {\n    // 선택적 설정 (기본값 존재)\n    host       string\n    port       int\n    poolSize   int\n    timeout    time.Duration\n}\n\nfunc defaultDBConfig() dbConfig {\n    return dbConfig{\n        host:     \"localhost\",\n        port:     5432,\n        poolSize: 10,\n        timeout:  5 * time.Second,\n    }\n}\n\ntype DBOption func(*dbConfig)\n\nfunc WithHost(host string) DBOption {\n    return func(c *dbConfig) { c.host = host }\n}\n\nfunc WithPort(port int) DBOption {\n    return func(c *dbConfig) { c.port = port }\n}\n\nfunc WithPoolSize(size int) DBOption {\n    return func(c *dbConfig) { c.poolSize = size }\n}\n\n// NewDBClient: database는 필수, 나머지는 선택\nfunc NewDBClient(database string, opts ...DBOption) (*DBClient, error) {\n    // database: 필수 파라미터 (기본값 없음)\n    if database == \"\" {\n        return nil, errors.New(\"database name is required\")\n    }\n    \n    // 선택적 설정: 기본값 + 옵션 오버라이드\n    cfg := defaultDBConfig()\n    for _, opt := range opts {\n        opt(&cfg)\n    }\n    \n    return &DBClient{\n        database: database,  // 필수\n        config:   cfg,       // 선택 (기본값 + 오버라이드)\n    }, nil\n}\n\n// 사용\ndb, _ := NewDBClient(\"mydb\")                           // 기본값 사용\ndb, _ := NewDBClient(\"mydb\", WithHost(\"db.prod.com\"))  // host만 오버라이드\ndb, _ := NewDBClient(\"mydb\", WithHost(\"db.prod.com\"), WithPoolSize(50))\n```\n\n## 응용 패턴\n\n### 옵션 프리셋 (자주 쓰는 설정 조합)\n\n```go\n// ProductionOptions는 프로덕션 환경용 설정 프리셋입니다.\nfunc ProductionOptions() []WorkerOption {\n    return []WorkerOption{\n        WithBatchSize(100),\n        WithMaxRetries(5),\n        WithShutdownTimeout(60 * time.Second),\n    }\n}\n\n// 프리셋 사용\nworker := NewStreamWorker(client, handler, ProductionOptions()...)\n\n// 프리셋 + 추가 오버라이드\nopts := append(ProductionOptions(), WithBatchSize(200))\nworker := NewStreamWorker(client, handler, opts...)\n```\n\n### 검증 포함 옵션\n\n```go\nfunc WithBatchSize(size int) WorkerOption {\n    return func(c *workerConfig) {\n        // 검증: 범위 제한\n        if size < 1 {\n            size = 1\n        }\n        if size > 1000 {\n            size = 1000\n        }\n        c.batchSize = size\n    }\n}\n```\n\n### 에러 반환 옵션 (고급)\n\n```go\ntype WorkerOptionWithError func(*workerConfig) error\n\nfunc NewStreamWorkerSafe(\n    client redis.UniversalClient,\n    handler MessageHandler,\n    opts ...WorkerOptionWithError,\n) (*StreamWorker, error) {\n    cfg := defaultConfig()\n    \n    for _, opt := range opts {\n        if err := opt(&cfg); err != nil {\n            return nil, err\n        }\n    }\n    \n    return &StreamWorker{config: cfg}, nil\n}\n\nfunc WithStreamFromEnv(key string) WorkerOptionWithError {\n    return func(c *workerConfig) error {\n        value := os.Getenv(key)\n        if value == \"\" {\n            return fmt.Errorf(\"env %s is not set\", key)\n        }\n        // 설정 적용\n        return nil\n    }\n}\n```\n\n## 테스트 용이성\n\n옵션 패턴은 테스트에서 특히 유용합니다:\n\n```go\nfunc TestWorker_ProcessMessages(t *testing.T) {\n    // 테스트용 짧은 타임아웃으로 오버라이드\n    worker := NewStreamWorker(\n        mockClient,\n        mockHandler,\n        WithBatchSize(1),                        // 빠른 테스트를 위해 1개씩\n        WithPollInterval(10*time.Millisecond),   // 빠른 폴링\n        WithMaxRetries(1),                       // 재시도 최소화\n        WithShutdownTimeout(100*time.Millisecond),\n    )\n    \n    // 테스트 로직...\n}\n```\n\n## 핵심 정리\n\n```mermaid\nflowchart TD\n    subgraph Constructor [\"NewStreamWorker(client, handler, opts...)\"]\n        direction LR\n        P1[\"client\"] --> |\"필수\"| REQ[\"없으면<br/>컴파일 에러\"]\n        P2[\"handler\"] --> |\"필수\"| REQ\n        P3[\"opts...\"] --> |\"선택\"| OPT[\"없으면<br/>기본값 사용\"]\n    end\n\n    subgraph Internal [\"내부 동작\"]\n        direction TB\n        S1[\"1. cfg := defaultConfig()\"] --> |\"기본값 초기화\"| S2\n        S2[\"2. for opt := range opts\"] --> |\"오버라이드\"| S3\n        S3[\"opt(&cfg)\"]\n    end\n\n    Constructor --> Internal\n\n    style REQ fill:#ffebee,stroke:#c62828\n    style OPT fill:#e8f5e9,stroke:#2e7d32\n```\n\n## 모범 사례\n\n1. **필수/선택 분리**: 없으면 안 되는 것은 파라미터, 기본값이 있는 것은 옵션\n2. **기본값 명시**: `defaultConfig()` 함수로 합리적인 기본값 정의\n3. **With 접두사**: 옵션 함수는 `With...` 네이밍 컨벤션 준수\n4. **검증 포함**: 옵션 함수 내에서 값 검증\n5. **불변성**: 내부 config 구조체는 외부에 노출하지 않음\n\n## 참고 자료\n\n- [Dave Cheney - Functional Options](https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis)\n- [Rob Pike - Self-referential functions](https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html)\n- [Uber Go Style Guide](https://github.com/uber-go/guide/blob/master/style.md#functional-options)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "Design Patterns",
      "Configuration",
      "Clean Code"
    ],
    "readingTime": 6,
    "wordCount": 1163,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "append-only-versioning",
    "slug": "append-only-versioning",
    "path": "backend/patterns",
    "fullPath": "backend/patterns/append-only-versioning",
    "title": "Append-Only 문서 버저닝 설계 및 구현",
    "excerpt": "데이터 불변성과 완전한 감사 추적을 보장하는 Append-Only 문서 버저닝 아키텍처의 설계 원칙과 Go 구현 방법을 알아봅니다.",
    "content": "# Append-Only 문서 버저닝 설계 및 구현\n\n## 개요\n\n데이터의 불변성(Immutability)과 완전한 감사 추적(Audit Trail)이 요구되는 시스템에서는 Append-Only 아키텍처가 효과적입니다. 이 글에서는 문서 버저닝 시스템을 설계하고 구현하는 방법을 다룹니다.\n\n## 왜 Append-Only인가?\n\n### 장점\n\n| 특성 | 설명 |\n|------|------|\n| **불변성 보장** | 기존 데이터를 수정하지 않아 데이터 무결성 유지 |\n| **감사 추적** | 모든 변경 이력이 자동으로 보존 |\n| **충돌 방지** | 동시 수정으로 인한 데이터 손실 위험 감소 |\n| **복구 용이** | 특정 시점으로 롤백 가능 |\n| **규정 준수** | 금융/의료 등 규제 산업의 데이터 보존 요건 충족 |\n\n### 단점\n\n| 특성 | 설명 |\n|------|------|\n| **저장 공간** | 버전마다 전체 스냅샷 저장으로 용량 증가 |\n| **쿼리 복잡도** | 최신 버전 조회 시 추가 로직 필요 |\n| **삭제 처리** | 물리적 삭제 대신 소프트 삭제 필요 |\n\n## 아키텍처 설계\n\n### 듀얼 컬렉션 구조\n\n```mermaid\ngraph LR\n    subgraph StorageLayer [Storage Layer]\n        direction TB\n        subgraph AllVersions [\"&lt;collection&gt; (All Version Snapshots)\"]\n            direction TB\n            v1[\"doc_uri: 'user-001'<br/>version: 1<br/>created_at: ...\"]\n            v2[\"doc_uri: 'user-001'<br/>version: 2\"]\n            v3[\"doc_uri: 'user-001'<br/>version: 3\"]\n        end\n\n        subgraph Current [\"current_&lt;collection&gt; (Latest Only)\"]\n            direction TB\n            latest[\"doc_uri: 'user-001'<br/>version: 3 (latest)<br/>updated_at: ...\"]\n        end\n    end\n\n    %% 스타일링\n    style StorageLayer fill:#f9f9f9,stroke:#333,stroke-dasharray: 5 5\n    style AllVersions fill:#fff,stroke:#007bff\n    style Current fill:#fff,stroke:#28a745\n```\n\n**두 컬렉션을 사용하는 이유:**\n\n- `<collection>`: 히스토리 보존, 감사 추적, 규정 준수\n- `current_<collection>`: 최신 데이터 빠른 조회, 인덱스 최적화\n\n### 문서 상태 관리\n\n```go\ntype DocumentState string\n\nconst (\n    DocStateActive  DocumentState = \"ACTIVE\"\n    DocStateDeleted DocumentState = \"DELETED\"\n    DocStatePending DocumentState = \"PENDING\"\n)\n```\n\n## 핵심 구현\n\n### 문서 모델\n\n```go\npackage model\n\nimport (\n    \"time\"\n)\n\n// VersionedDocument는 버전 관리되는 문서의 기본 구조입니다.\ntype VersionedDocument struct {\n    ID        string                 `bson:\"_id,omitempty\"`\n    URI       string                 `bson:\"uri\"`\n    Version   int32                  `bson:\"version\"`\n    DocStatus DocumentState          `bson:\"doc_status\"`\n    Fields    map[string]interface{} `bson:\"fields\"`\n    CreatedAt time.Time              `bson:\"created_at\"`\n    UpdatedAt time.Time              `bson:\"updated_at\"`\n}\n\n// AuditEntry는 변경 감사 로그 항목입니다.\ntype AuditEntry struct {\n    ID            string                 `bson:\"_id,omitempty\"`\n    Collection    string                 `bson:\"collection\"`\n    DocumentURI   string                 `bson:\"document_uri\"`\n    Action        string                 `bson:\"action\"` // CREATE, UPDATE, DELETE\n    ChangedBy     string                 `bson:\"changed_by\"`\n    ChangedAt     time.Time              `bson:\"changed_at\"`\n    PreviousData  map[string]interface{} `bson:\"previous_data,omitempty\"`\n    NewData       map[string]interface{} `bson:\"new_data,omitempty\"`\n    ChangedFields []string               `bson:\"changed_fields,omitempty\"`\n}\n```\n\n### 서비스 인터페이스\n\n```go\npackage document\n\nimport (\n    \"context\"\n)\n\n// VersionedService는 버전 관리 문서 서비스 인터페이스입니다.\ntype VersionedService interface {\n    // Create는 버전 1의 새 문서를 생성합니다.\n    Create(ctx context.Context, collection string, data BsonDocument) (*BsonDocument, error)\n    \n    // FindLatest는 URI의 최신 버전 문서를 조회합니다.\n    FindLatest(ctx context.Context, collection, uri string) (*BsonDocument, error)\n    \n    // FindByVersion는 특정 버전의 문서를 조회합니다.\n    FindByVersion(ctx context.Context, collection, uri string, version int32) (*BsonDocument, error)\n    \n    // SoftUpdate는 새 버전을 생성하여 문서를 업데이트합니다.\n    SoftUpdate(ctx context.Context, collection, uri string, updates BsonDocument) (*BsonDocument, error)\n    \n    // SoftDelete는 삭제 상태의 새 버전을 생성합니다.\n    SoftDelete(ctx context.Context, collection, uri string) (*BsonDocument, error)\n    \n    // GetHistory는 문서의 전체 버전 히스토리를 조회합니다.\n    GetHistory(ctx context.Context, collection, uri string) ([]BsonDocument, error)\n}\n```\n\n### 문서 생성\n\n```go\nfunc (s *versionService) Create(ctx context.Context, collection string, data BsonDocument) (*BsonDocument, error) {\n    now := time.Now()\n    \n    doc := &VersionedDocument{\n        URI:       data.URI,\n        Version:   1, // 첫 버전\n        DocStatus: DocStateActive,\n        Fields:    data.Fields,\n        CreatedAt: now,\n        UpdatedAt: now,\n    }\n    \n    // 트랜잭션으로 두 컬렉션에 동시 저장\n    _, err := s.WithTransaction(ctx, func(sessCtx context.Context) (interface{}, error) {\n        // 1. 버전 히스토리 컬렉션에 저장\n        if _, err := s.collection(collection).InsertOne(sessCtx, doc); err != nil {\n            return nil, err\n        }\n        \n        // 2. 최신 버전 컬렉션에도 저장\n        currentColl := s.currentCollection(collection)\n        if _, err := currentColl.InsertOne(sessCtx, doc); err != nil {\n            return nil, err\n        }\n        \n        // 3. 감사 로그 생성\n        if err := s.createAuditLog(sessCtx, collection, doc, \"CREATE\", nil); err != nil {\n            return nil, err\n        }\n        \n        return doc, nil\n    })\n    \n    if err != nil {\n        return nil, err\n    }\n    \n    return doc, nil\n}\n```\n\n### 소프트 업데이트\n\n기존 버전은 그대로 두고 새 버전을 추가합니다:\n\n```go\nfunc (s *versionService) SoftUpdate(ctx context.Context, collection, uri string, updates BsonDocument) (*BsonDocument, error) {\n    // 현재 최신 버전 조회\n    current, err := s.FindLatest(ctx, collection, uri)\n    if err != nil {\n        return nil, err\n    }\n    \n    if current.DocStatus == DocStateDeleted {\n        return nil, ErrDocumentDeleted\n    }\n    \n    now := time.Now()\n    \n    // 새 버전 문서 생성 (기존 필드 + 업데이트 필드)\n    newFields := mergeFields(current.Fields, updates.Fields)\n    changedFields := detectChangedFields(current.Fields, newFields)\n    \n    newDoc := &VersionedDocument{\n        URI:       uri,\n        Version:   current.Version + 1, // 버전 증가\n        DocStatus: DocStateActive,\n        Fields:    newFields,\n        CreatedAt: current.CreatedAt, // 원본 생성 시간 유지\n        UpdatedAt: now,\n    }\n    \n    _, err = s.WithTransaction(ctx, func(sessCtx context.Context) (interface{}, error) {\n        // 1. 새 버전을 히스토리 컬렉션에 추가 (Append)\n        if _, err := s.collection(collection).InsertOne(sessCtx, newDoc); err != nil {\n            return nil, err\n        }\n        \n        // 2. 최신 버전 컬렉션 업데이트 (Replace)\n        filter := bson.M{\"uri\": uri}\n        if _, err := s.currentCollection(collection).ReplaceOne(sessCtx, filter, newDoc); err != nil {\n            return nil, err\n        }\n        \n        // 3. 감사 로그\n        auditLog := &AuditEntry{\n            Collection:    collection,\n            DocumentURI:   uri,\n            Action:        \"UPDATE\",\n            ChangedAt:     now,\n            PreviousData:  current.Fields,\n            NewData:       newFields,\n            ChangedFields: changedFields,\n        }\n        if err := s.insertAuditLog(sessCtx, auditLog); err != nil {\n            return nil, err\n        }\n        \n        return newDoc, nil\n    })\n    \n    if err != nil {\n        return nil, err\n    }\n    \n    return newDoc, nil\n}\n```\n\n### 소프트 삭제\n\n물리적 삭제 대신 삭제 상태의 새 버전을 생성합니다:\n\n```go\nfunc (s *versionService) SoftDelete(ctx context.Context, collection, uri string) (*BsonDocument, error) {\n    current, err := s.FindLatest(ctx, collection, uri)\n    if err != nil {\n        return nil, err\n    }\n    \n    now := time.Now()\n    \n    // 삭제 상태의 새 버전 생성\n    deletedDoc := &VersionedDocument{\n        URI:       uri,\n        Version:   current.Version + 1,\n        DocStatus: DocStateDeleted, // DELETED 상태\n        Fields:    current.Fields,  // 마지막 데이터 보존\n        CreatedAt: current.CreatedAt,\n        UpdatedAt: now,\n    }\n    \n    _, err = s.WithTransaction(ctx, func(sessCtx context.Context) (interface{}, error) {\n        // 1. 삭제 버전 히스토리에 추가\n        if _, err := s.collection(collection).InsertOne(sessCtx, deletedDoc); err != nil {\n            return nil, err\n        }\n        \n        // 2. 최신 버전 컬렉션도 삭제 상태로 업데이트\n        filter := bson.M{\"uri\": uri}\n        if _, err := s.currentCollection(collection).ReplaceOne(sessCtx, filter, deletedDoc); err != nil {\n            return nil, err\n        }\n        \n        // 3. 감사 로그\n        if err := s.createAuditLog(sessCtx, collection, deletedDoc, \"DELETE\", current.Fields); err != nil {\n            return nil, err\n        }\n        \n        return deletedDoc, nil\n    })\n    \n    return deletedDoc, err\n}\n```\n\n### 변경 필드 감지\n\n```go\nfunc detectChangedFields(previous, current map[string]interface{}) []string {\n    var changed []string\n    \n    for key, newVal := range current {\n        oldVal, exists := previous[key]\n        if !exists || !reflect.DeepEqual(oldVal, newVal) {\n            changed = append(changed, key)\n        }\n    }\n    \n    // 삭제된 필드 감지\n    for key := range previous {\n        if _, exists := current[key]; !exists {\n            changed = append(changed, key)\n        }\n    }\n    \n    return changed\n}\n```\n\n## Optimistic Locking\n\n동시 업데이트 충돌 방지를 위한 낙관적 잠금:\n\n```go\nfunc (s *versionService) SoftUpdateWithLock(\n    ctx context.Context, \n    collection, uri string, \n    expectedVersion int32,\n    updates BsonDocument,\n) (*BsonDocument, error) {\n    current, err := s.FindLatest(ctx, collection, uri)\n    if err != nil {\n        return nil, err\n    }\n    \n    // 버전 불일치 시 충돌 에러\n    if current.Version != expectedVersion {\n        return nil, fmt.Errorf(\n            \"version conflict: expected %d, actual %d\",\n            expectedVersion, current.Version,\n        )\n    }\n    \n    return s.SoftUpdate(ctx, collection, uri, updates)\n}\n```\n\n## 쿼리 패턴\n\n### 최신 버전 조회 (빠름)\n\n```go\n// current_<collection>에서 직접 조회\nfunc (s *versionService) FindLatest(ctx context.Context, collection, uri string) (*BsonDocument, error) {\n    filter := bson.M{\n        \"uri\":        uri,\n        \"doc_status\": bson.M{\"$ne\": DocStateDeleted},\n    }\n    \n    var doc VersionedDocument\n    err := s.currentCollection(collection).FindOne(ctx, filter).Decode(&doc)\n    if err != nil {\n        return nil, err\n    }\n    \n    return &doc, nil\n}\n```\n\n### 특정 버전 조회\n\n```go\nfunc (s *versionService) FindByVersion(ctx context.Context, collection, uri string, version int32) (*BsonDocument, error) {\n    filter := bson.M{\n        \"uri\":     uri,\n        \"version\": version,\n    }\n    \n    var doc VersionedDocument\n    err := s.collection(collection).FindOne(ctx, filter).Decode(&doc)\n    if err != nil {\n        return nil, err\n    }\n    \n    return &doc, nil\n}\n```\n\n### 히스토리 조회\n\n```go\nfunc (s *versionService) GetHistory(ctx context.Context, collection, uri string) ([]BsonDocument, error) {\n    filter := bson.M{\"uri\": uri}\n    opts := options.Find().SetSort(bson.D{{Key: \"version\", Value: 1}})\n    \n    cursor, err := s.collection(collection).Find(ctx, filter, opts)\n    if err != nil {\n        return nil, err\n    }\n    defer cursor.Close(ctx)\n    \n    var docs []VersionedDocument\n    if err := cursor.All(ctx, &docs); err != nil {\n        return nil, err\n    }\n    \n    return docs, nil\n}\n```\n\n## 인덱스 전략\n\n```go\n// 히스토리 컬렉션 인덱스\nindexes := []mongo.IndexModel{\n    {\n        Keys: bson.D{{Key: \"uri\", Value: 1}, {Key: \"version\", Value: -1}},\n        Options: options.Index().SetUnique(true),\n    },\n    {\n        Keys: bson.D{{Key: \"created_at\", Value: -1}},\n    },\n}\n\n// 최신 버전 컬렉션 인덱스\ncurrentIndexes := []mongo.IndexModel{\n    {\n        Keys: bson.D{{Key: \"uri\", Value: 1}},\n        Options: options.Index().SetUnique(true),\n    },\n    {\n        Keys: bson.D{{Key: \"doc_status\", Value: 1}},\n    },\n}\n```\n\n## 스토리지 최적화\n\n버전 누적으로 인한 저장 공간 증가 대응:\n\n### 1. 필드 압축\n\n```go\n// 변경된 필드만 저장하는 Delta 방식 (선택적)\ntype DeltaDocument struct {\n    URI         string                 `bson:\"uri\"`\n    Version     int32                  `bson:\"version\"`\n    BaseVersion int32                  `bson:\"base_version,omitempty\"`\n    Delta       map[string]interface{} `bson:\"delta,omitempty\"`\n    IsSnapshot  bool                   `bson:\"is_snapshot\"`\n}\n```\n\n### 2. TTL 정책\n\n```go\n// 오래된 버전 자동 정리 (최신 N개 유지)\nindexes := mongo.IndexModel{\n    Keys:    bson.D{{Key: \"created_at\", Value: 1}},\n    Options: options.Index().SetExpireAfterSeconds(86400 * 365), // 1년\n}\n```\n\n## 모범 사례\n\n1. **트랜잭션 필수**: 두 컬렉션 동시 업데이트 시 원자성 보장\n2. **URI 불변성**: 문서 식별자(URI)는 생성 후 변경 금지\n3. **감사 로그 분리**: 감사 로그는 별도 컬렉션에 저장하여 독립적 접근\n4. **인덱스 최적화**: 최신 버전 조회 패턴에 맞는 인덱스 설계\n5. **버전 상한 설정**: 무한 버전 증가 방지 정책 고려\n\n## 참고 자료\n\n- [Event Sourcing Pattern](https://martinfowler.com/eaaDev/EventSourcing.html)\n- [MongoDB Transactions](https://www.mongodb.com/docs/manual/core/transactions/)\n- [Immutable Data Patterns](https://www.cidrdb.org/cidr2015/Papers/CIDR15_Paper16.pdf)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Architecture",
      "Go",
      "MongoDB",
      "Versioning",
      "Audit"
    ],
    "readingTime": 8,
    "wordCount": 1447,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "grpc-gateway-dual-protocol",
    "slug": "grpc-gateway-dual-protocol",
    "path": "backend/http",
    "fullPath": "backend/http/grpc-gateway-dual-protocol",
    "title": "gRPC-Gateway로 단일 API 듀얼 프로토콜 지원",
    "excerpt": "하나의 Proto 정의로 gRPC와 RESTful HTTP API를 동시에 제공하는 gRPC-Gateway 구현 방법을 알아봅니다.",
    "content": "# gRPC-Gateway로 단일 API 듀얼 프로토콜 지원\n\n## 개요\n\n**gRPC-Gateway**는 gRPC 서비스에 RESTful HTTP/JSON 인터페이스를 자동으로 추가해주는 리버스 프록시입니다. 하나의 Proto 정의로 두 프로토콜을 모두 지원할 수 있습니다.\n\n## 왜 듀얼 프로토콜인가?\n\n### 장점\n\n| 프로토콜 | 사용 시나리오 |\n|----------|--------------|\n| **gRPC** | 마이크로서비스 간 통신, 고성능 필요, 스트리밍 |\n| **HTTP/JSON** | 웹 브라우저, 외부 API 클라이언트, 디버깅 |\n\n단일 코드베이스로 두 니즈를 모두 충족할 수 있습니다.\n\n### 단점\n\n| 특성 | 설명 |\n|------|------|\n| 추가 레이어 | HTTP → gRPC 변환 오버헤드 |\n| 기능 제한 | HTTP에서 gRPC 스트리밍 일부 지원 제한 |\n| 복잡성 | 두 프로토콜의 에러 처리 매핑 필요 |\n\n## 아키텍처\n\n```mermaid\ngraph LR\n    %% 외부 클라이언트 정의\n    subgraph Clients [\"Clients\"]\n        HTTP_Client[\"HTTP Client<br/>(Browser, etc)\"]\n        gRPC_Client[\"gRPC Client<br/>(Microservice)\"]\n    end\n\n    %% API 서버 내부 구조 정의\n    subgraph APIServer [\"API Server\"]\n        direction TB\n        \n        subgraph Ports [\"Incoming Ports\"]\n            HTTP_Port[\":8080 HTTP\"]\n            gRPC_Port[\":9090 gRPC\"]\n        end\n\n        Mux[\"gRPC-Gateway Mux\"]\n        gRPC_Srv[\"gRPC Server<br/>(Core Logic)\"]\n        \n        subgraph Endpoints [\"Misc Endpoints\"]\n            OpenAPI[\"OpenAPI<br/>/openapi\"]\n            Health[\"Health<br/>/ready\"]\n        end\n\n        %% 내부 흐름\n        HTTP_Port --> Mux\n        Mux --> gRPC_Srv\n        gRPC_Port --> gRPC_Srv\n    end\n\n    %% 클라이언트 연결\n    HTTP_Client -- \"JSON/REST\" --> HTTP_Port\n    gRPC_Client -- \"Protobuf\" --> gRPC_Port\n\n    %% 스타일링\n    style APIServer fill:#f5f5f5,stroke:#333,stroke-width:2px\n    style Mux fill:#e1f5fe,stroke:#01579b\n    style gRPC_Srv fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px\n    style HTTP_Client fill:#fff,stroke:#333\n    style gRPC_Client fill:#fff,stroke:#333\n```\n\n## Proto 정의\n\n### HTTP 어노테이션 추가\n\n```protobuf\nsyntax = \"proto3\";\n\npackage v1beta;\n\nimport \"google/api/annotations.proto\";\nimport \"google/protobuf/struct.proto\";\n\nservice DocumentService {\n  // POST /v1beta/collections/{collection}/documents\n  rpc CreateDocument(CreateDocumentRequest) returns (CreateDocumentResponse) {\n    option (google.api.http) = {\n      post: \"/v1beta/collections/{collection}/documents\"\n      body: \"*\"\n    };\n  }\n  \n  // GET /v1beta/collections/{collection}/documents/{uri}\n  rpc GetDocument(GetDocumentRequest) returns (GetDocumentResponse) {\n    option (google.api.http) = {\n      get: \"/v1beta/collections/{collection}/documents/{uri}\"\n    };\n  }\n  \n  // PATCH /v1beta/collections/{collection}/documents/{uri}\n  rpc UpdateDocument(UpdateDocumentRequest) returns (UpdateDocumentResponse) {\n    option (google.api.http) = {\n      patch: \"/v1beta/collections/{collection}/documents/{uri}\"\n      body: \"*\"\n    };\n  }\n  \n  // DELETE /v1beta/collections/{collection}/documents/{uri}\n  rpc DeleteDocument(DeleteDocumentRequest) returns (DeleteDocumentResponse) {\n    option (google.api.http) = {\n      delete: \"/v1beta/collections/{collection}/documents/{uri}\"\n    };\n  }\n  \n  // POST로 쿼리 (URL 길이 제한 회피)\n  // POST /v1beta/collections/{collection}/documents:query\n  rpc QueryDocuments(QueryDocumentsRequest) returns (QueryDocumentsResponse) {\n    option (google.api.http) = {\n      post: \"/v1beta/collections/{collection}/documents:query\"\n      body: \"*\"\n    };\n  }\n  \n  // 배치 작업\n  // POST /v1beta/collections/{collection}/documents:batchCreate\n  rpc BatchCreateDocuments(BatchCreateRequest) returns (BatchCreateResponse) {\n    option (google.api.http) = {\n      post: \"/v1beta/collections/{collection}/documents:batchCreate\"\n      body: \"*\"\n    };\n  }\n}\n\nmessage CreateDocumentRequest {\n  // URL 경로 파라미터로 추출됨\n  string collection = 1;\n  DocumentInput document = 2;\n}\n\nmessage GetDocumentRequest {\n  string collection = 1;\n  string uri = 2;\n  // 쿼리 파라미터: ?version=3\n  optional int32 version = 3;\n  // 쿼리 파라미터: ?skip_validation=true\n  optional bool skip_validation = 4;\n}\n\n// ... 나머지 메시지 정의\n```\n\n### URL 매핑 규칙\n\n| gRPC 필드 위치 | HTTP 위치 |\n|---------------|-----------|\n| `{field}` in path | URL 경로 파라미터 |\n| `body: \"*\"` | 나머지 필드는 JSON body |\n| `body: \"field\"` | 특정 필드만 body |\n| 그 외 필드 | 쿼리 파라미터 |\n\n## 코드 생성 설정\n\n### buf.gen.yaml\n\n```yaml\nversion: v2\nplugins:\n  # gRPC 서버/클라이언트\n  - remote: buf.build/grpc/go:v1.5.1\n    out: generated/go/proto\n    opt: paths=source_relative\n  \n  # gRPC-Gateway 핸들러\n  - remote: buf.build/grpc-ecosystem/gateway:v2.25.1\n    out: generated/go/proto\n    opt:\n      - paths=source_relative\n      - standalone=true       # 독립 파일로 생성\n      - generate_unbound_methods=true\n```\n\n### 생성 실행\n\n```bash\nbuf generate\n```\n\n생성된 파일:\n\n- `api_grpc.pb.go`: gRPC 서버/클라이언트\n- `api.pb.gw.go`: HTTP Gateway 핸들러\n\n## 서버 구현\n\n### 통합 서버\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"net\"\n    \"net/http\"\n    \"sync\"\n    \n    \"github.com/grpc-ecosystem/grpc-gateway/v2/runtime\"\n    \"google.golang.org/grpc\"\n    \"google.golang.org/grpc/credentials/insecure\"\n    \n    pb \"github.com/myorg/myservice/generated/go/proto/v1beta\"\n)\n\ntype Server struct {\n    grpcServer *grpc.Server\n    httpServer *http.Server\n    \n    grpcPort string\n    httpPort string\n}\n\nfunc NewServer(service DocumentService) *Server {\n    // gRPC 서버 설정\n    grpcServer := grpc.NewServer(\n        grpc.UnaryInterceptor(loggingInterceptor),\n    )\n    pb.RegisterDocumentServiceServer(grpcServer, &documentHandler{service})\n    \n    return &Server{\n        grpcServer: grpcServer,\n        grpcPort:   \":9090\",\n        httpPort:   \":8080\",\n    }\n}\n\nfunc (s *Server) Start(ctx context.Context) error {\n    var wg sync.WaitGroup\n    errCh := make(chan error, 2)\n    \n    // 1. gRPC 서버 시작\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        lis, err := net.Listen(\"tcp\", s.grpcPort)\n        if err != nil {\n            errCh <- err\n            return\n        }\n        if err := s.grpcServer.Serve(lis); err != nil {\n            errCh <- err\n        }\n    }()\n    \n    // 2. HTTP Gateway 시작\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        if err := s.startHTTPGateway(ctx); err != nil {\n            errCh <- err\n        }\n    }()\n    \n    select {\n    case err := <-errCh:\n        return err\n    case <-ctx.Done():\n        s.Shutdown()\n        return ctx.Err()\n    }\n}\n\nfunc (s *Server) startHTTPGateway(ctx context.Context) error {\n    mux := runtime.NewServeMux(\n        // JSON 필드 이름 설정\n        runtime.WithMarshalerOption(runtime.MIMEWildcard, &runtime.JSONPb{\n            MarshalOptions: protojson.MarshalOptions{\n                UseProtoNames:   true,\n                EmitUnpopulated: true,\n            },\n            UnmarshalOptions: protojson.UnmarshalOptions{\n                DiscardUnknown: true,\n            },\n        }),\n        // 에러 핸들링 커스터마이즈\n        runtime.WithErrorHandler(customErrorHandler),\n    )\n    \n    opts := []grpc.DialOption{grpc.WithTransportCredentials(insecure.NewCredentials())}\n    \n    // gRPC 서버에 연결\n    err := pb.RegisterDocumentServiceHandlerFromEndpoint(ctx, mux, \"localhost\"+s.grpcPort, opts)\n    if err != nil {\n        return err\n    }\n    \n    // 추가 HTTP 엔드포인트\n    handler := http.NewServeMux()\n    handler.Handle(\"/\", mux)\n    handler.HandleFunc(\"/openapi.yaml\", serveOpenAPI)\n    handler.HandleFunc(\"/ready\", healthCheck)\n    \n    s.httpServer = &http.Server{\n        Addr:    s.httpPort,\n        Handler: handler,\n    }\n    \n    return s.httpServer.ListenAndServe()\n}\n\nfunc (s *Server) Shutdown() {\n    s.grpcServer.GracefulStop()\n    if s.httpServer != nil {\n        s.httpServer.Shutdown(context.Background())\n    }\n}\n```\n\n### 에러 핸들링\n\ngRPC 상태 코드를 HTTP 상태 코드로 매핑:\n\n```go\nfunc customErrorHandler(\n    ctx context.Context,\n    mux *runtime.ServeMux,\n    marshaler runtime.Marshaler,\n    w http.ResponseWriter,\n    r *http.Request,\n    err error,\n) {\n    // gRPC 에러에서 상태 추출\n    st, _ := status.FromError(err)\n    \n    // HTTP 상태 코드 매핑\n    httpStatus := runtime.HTTPStatusFromCode(st.Code())\n    \n    // 커스텀 에러 응답\n    response := map[string]interface{}{\n        \"code\":    st.Code().String(),\n        \"message\": st.Message(),\n    }\n    \n    if details := st.Details(); len(details) > 0 {\n        response[\"details\"] = details\n    }\n    \n    w.Header().Set(\"Content-Type\", \"application/json\")\n    w.WriteHeader(httpStatus)\n    json.NewEncoder(w).Encode(response)\n}\n```\n\n## 인-프로세스 vs 네트워크 연결\n\n### 네트워크 연결 (기본)\n\n```go\n// gRPC 서버에 네트워크로 연결\npb.RegisterDocumentServiceHandlerFromEndpoint(ctx, mux, \"localhost:9090\", opts)\n```\n\n### 인-프로세스 연결 (권장)\n\n네트워크 오버헤드 없이 직접 연결:\n\n```go\nfunc (s *Server) startHTTPGatewayInProcess(ctx context.Context) error {\n    mux := runtime.NewServeMux()\n    \n    // 서버 구현체를 직접 등록 (네트워크 경유 없음)\n    err := pb.RegisterDocumentServiceHandlerServer(ctx, mux, s.documentHandler)\n    if err != nil {\n        return err\n    }\n    \n    s.httpServer = &http.Server{\n        Addr:    s.httpPort,\n        Handler: mux,\n    }\n    \n    return s.httpServer.ListenAndServe()\n}\n```\n\n## 미들웨어\n\n### HTTP 미들웨어 체인\n\n```go\nfunc (s *Server) buildHTTPHandler(mux *runtime.ServeMux) http.Handler {\n    // 미들웨어 체인\n    handler := corsMiddleware(mux)\n    handler = loggingMiddleware(handler)\n    handler = metricsMiddleware(handler)\n    \n    return handler\n}\n\nfunc corsMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        w.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\n        w.Header().Set(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, PATCH, DELETE, OPTIONS\")\n        w.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\")\n        \n        if r.Method == \"OPTIONS\" {\n            w.WriteHeader(http.StatusNoContent)\n            return\n        }\n        \n        next.ServeHTTP(w, r)\n    })\n}\n\nfunc loggingMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        start := time.Now()\n        \n        wrapped := &responseWriter{ResponseWriter: w, status: 200}\n        next.ServeHTTP(wrapped, r)\n        \n        log.Printf(\"%s %s %d %v\", r.Method, r.URL.Path, wrapped.status, time.Since(start))\n    })\n}\n```\n\n### gRPC 인터셉터\n\n```go\nfunc loggingInterceptor(\n    ctx context.Context,\n    req interface{},\n    info *grpc.UnaryServerInfo,\n    handler grpc.UnaryHandler,\n) (interface{}, error) {\n    start := time.Now()\n    \n    resp, err := handler(ctx, req)\n    \n    log.Printf(\"gRPC %s %v err=%v\", info.FullMethod, time.Since(start), err)\n    \n    return resp, err\n}\n```\n\n## OpenAPI 스펙 제공\n\n### 자동 생성된 스펙 제공\n\n```go\n//go:embed generated/docs/openapi.yaml\nvar openAPISpec []byte\n\nfunc serveOpenAPI(w http.ResponseWriter, r *http.Request) {\n    w.Header().Set(\"Content-Type\", \"application/x-yaml\")\n    w.Write(openAPISpec)\n}\n```\n\n### Stoplight Elements 통합\n\n정적 HTML과 Stoplight Elements 웹 컴포넌트로 인터랙티브 API 문서를 제공합니다:\n\n```html\n<!-- docs/openapi.html -->\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n    <title>API Documentation</title>\n    <script src=\"https://unpkg.com/@stoplight/elements/web-components.min.js\"></script>\n    <link rel=\"stylesheet\" href=\"https://unpkg.com/@stoplight/elements/styles.min.css\" />\n  </head>\n  <body>\n    <elements-api\n      apiDescriptionUrl=\"openapi.swagger.json\"\n      router=\"hash\"\n      layout=\"sidebar\"\n      hideInternal=\"true\"\n    />\n  </body>\n</html>\n```\n\nProto 프로젝트에서 embed.FS로 정적 파일 제공:\n\n```go\n// generated/go/docs/embed.go\npackage docs\n\nimport \"embed\"\n\n//go:embed openapi.html openapi.swagger.json\nvar StaticFiles embed.FS\n```\n\ngRPC-Gateway Mux에 직접 경로 등록:\n\n```go\nimport (\n    \"io/fs\"\n    \"net/http\"\n    \n    \"github.com/grpc-ecosystem/grpc-gateway/v2/runtime\"\n    \"myproject/generated/go/docs\"\n)\n\nfunc setupAPIRoutes(gatewayMux *runtime.ServeMux) {\n    // 파일 서빙 헬퍼\n    serveEmbeddedFile := func(w http.ResponseWriter, r *http.Request, fsys fs.FS, name string) {\n        fileServer := http.FileServer(http.FS(fsys))\n        r.URL.Path = name\n        fileServer.ServeHTTP(w, r)\n    }\n    \n    // OpenAPI JSON 스펙\n    gatewayMux.HandlePath(\"GET\", \"/openapi.swagger.json\", \n        func(w http.ResponseWriter, r *http.Request, _ map[string]string) {\n            serveEmbeddedFile(w, r, docs.StaticFiles, \"openapi.swagger.json\")\n        })\n    \n    // Stoplight Elements UI (HTML)\n    gatewayMux.HandlePath(\"GET\", \"/openapi.html\", \n        func(w http.ResponseWriter, r *http.Request, _ map[string]string) {\n            serveEmbeddedFile(w, r, docs.StaticFiles, \"openapi.html\")\n        })\n    \n    // 루트 접속 시 문서로 리다이렉트\n    gatewayMux.HandlePath(\"GET\", \"/\", \n        func(w http.ResponseWriter, r *http.Request, _ map[string]string) {\n            http.Redirect(w, r, \"/openapi.html\", http.StatusFound)\n        })\n}\n```\n\n## 요청/응답 예시\n\n### HTTP 요청\n\n```bash\n# 문서 생성\ncurl -X POST http://localhost:8080/v1beta/collections/users/documents \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"document\": {\n      \"uri\": \"user-001\",\n      \"fields\": {\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\"\n      }\n    }\n  }'\n\n# 문서 조회\ncurl http://localhost:8080/v1beta/collections/users/documents/user-001?version=1\n\n# 문서 업데이트\ncurl -X PATCH http://localhost:8080/v1beta/collections/users/documents/user-001 \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"fields\": {\"name\": \"Jane Doe\"}}'\n```\n\n### gRPC 요청 (grpcurl)\n\n```bash\n# 문서 생성\ngrpcurl -plaintext -d '{\n  \"collection\": \"users\",\n  \"document\": {\n    \"uri\": \"user-001\",\n    \"fields\": {\"name\": \"John Doe\"}\n  }\n}' localhost:9090 v1beta.DocumentService/CreateDocument\n\n# 문서 조회\ngrpcurl -plaintext -d '{\n  \"collection\": \"users\",\n  \"uri\": \"user-001\"\n}' localhost:9090 v1beta.DocumentService/GetDocument\n```\n\n## 모범 사례\n\n1. **인-프로세스 연결**: 가능하면 `RegisterHandlerServer` 사용\n2. **일관된 에러 처리**: gRPC/HTTP 에러 매핑 통일\n3. **OpenAPI 통합**: 자동 생성 스펙으로 문서화\n4. **미들웨어 분리**: HTTP/gRPC 각각 적절한 미들웨어 적용\n5. **Health Check**: `/ready` 엔드포인트로 헬스체크 분리\n\n## 참고 자료\n\n- [gRPC-Gateway 공식 문서](https://grpc-ecosystem.github.io/grpc-gateway/)\n- [google.api.http 어노테이션](https://cloud.google.com/endpoints/docs/grpc/transcoding)\n- [runtime.ServeMux 옵션](https://pkg.go.dev/github.com/grpc-ecosystem/grpc-gateway/v2/runtime)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "gRPC",
      "REST",
      "HTTP",
      "API",
      "Gateway"
    ],
    "readingTime": 7,
    "wordCount": 1375,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "wire-dependency-injection",
    "slug": "wire-dependency-injection",
    "path": "backend/go",
    "fullPath": "backend/go/wire-dependency-injection",
    "title": "Wire를 활용한 Go 의존성 주입(DI) 구현",
    "excerpt": "Google의 Wire를 사용하여 Go 애플리케이션에서 컴파일 타임 의존성 주입을 구현하는 방법을 알아봅니다.",
    "content": "# Wire를 활용한 Go 의존성 주입(DI) 구현\n\n## 개요\n\n**Wire**는 Google에서 개발한 Go용 컴파일 타임 의존성 주입 도구입니다. 리플렉션 없이 코드 생성을 통해 DI를 구현하므로 런타임 오버헤드가 없습니다.\n\n## 왜 Wire인가?\n\n| 도구 | 방식 | 장점 | 단점 |\n|-----|------|------|------|\n| 수동 DI | 직접 구성 | 단순, 명시적 | 보일러플레이트 |\n| dig/fx | 런타임 리플렉션 | 유연 | 런타임 오버헤드, 디버깅 어려움 |\n| **Wire** | 컴파일 타임 코드 생성 | 타입 안전, 오버헤드 없음 | 초기 설정 필요 |\n\n## 설치\n\n```bash\ngo install github.com/google/wire/cmd/wire@latest\n```\n\n## 기본 개념\n\n### Provider\n\n**Provider**는 의존성을 생성하는 함수입니다:\n\n```go\n// providers.go\npackage main\n\ntype Config struct {\n    DBHost string\n    DBPort int\n}\n\nfunc NewConfig() *Config {\n    return &Config{\n        DBHost: \"localhost\",\n        DBPort: 5432,\n    }\n}\n\ntype Database struct {\n    config *Config\n}\n\nfunc NewDatabase(cfg *Config) (*Database, error) {\n    return &Database{config: cfg}, nil\n}\n\ntype UserRepository struct {\n    db *Database\n}\n\nfunc NewUserRepository(db *Database) *UserRepository {\n    return &UserRepository{db: db}\n}\n\ntype UserService struct {\n    repo *UserRepository\n}\n\nfunc NewUserService(repo *UserRepository) *UserService {\n    return &UserService{repo: repo}\n}\n```\n\n### Injector\n\n**Injector**는 의존성 그래프를 정의하는 함수입니다:\n\n```go\n// wire.go\n//go:build wireinject\n\npackage main\n\nimport \"github.com/google/wire\"\n\nfunc InitializeUserService() (*UserService, error) {\n    wire.Build(\n        NewConfig,\n        NewDatabase,\n        NewUserRepository,\n        NewUserService,\n    )\n    return nil, nil // Wire가 이 부분을 생성된 코드로 대체\n}\n```\n\n### 코드 생성\n\n```bash\nwire ./...\n\n# 생성된 파일: wire_gen.go\n```\n\n생성된 `wire_gen.go`:\n\n```go\n// Code generated by Wire. DO NOT EDIT.\n//go:build !wireinject\n\npackage main\n\nfunc InitializeUserService() (*UserService, error) {\n    config := NewConfig()\n    database, err := NewDatabase(config)\n    if err != nil {\n        return nil, err\n    }\n    userRepository := NewUserRepository(database)\n    userService := NewUserService(userRepository)\n    return userService, nil\n}\n```\n\n## Provider Set\n\n관련 Provider들을 그룹화할 수 있습니다:\n\n```go\n// infrastructure/wire.go\npackage infrastructure\n\nimport \"github.com/google/wire\"\n\nvar InfraSet = wire.NewSet(\n    NewConfig,\n    NewDatabase,\n    NewRedisClient,\n    NewLogger,\n)\n```\n\n```go\n// repository/wire.go\npackage repository\n\nimport \"github.com/google/wire\"\n\nvar RepositorySet = wire.NewSet(\n    NewUserRepository,\n    NewOrderRepository,\n    NewProductRepository,\n)\n```\n\n```go\n// service/wire.go\npackage service\n\nimport \"github.com/google/wire\"\n\nvar ServiceSet = wire.NewSet(\n    NewUserService,\n    NewOrderService,\n    NewProductService,\n)\n```\n\n```go\n// wire.go\npackage main\n\nimport \"github.com/google/wire\"\n\nfunc InitializeApp() (*App, error) {\n    wire.Build(\n        infrastructure.InfraSet,\n        repository.RepositorySet,\n        service.ServiceSet,\n        NewApp,\n    )\n    return nil, nil\n}\n```\n\n## 인터페이스 바인딩\n\n인터페이스에 구현체를 바인딩할 수 있습니다:\n\n```go\n// 인터페이스 정의\ntype UserRepository interface {\n    FindByID(id string) (*User, error)\n    Save(user *User) error\n}\n\n// 구현체\ntype userRepositoryImpl struct {\n    db *Database\n}\n\nfunc NewUserRepository(db *Database) *userRepositoryImpl {\n    return &userRepositoryImpl{db: db}\n}\n\n// Wire 바인딩\nvar RepositorySet = wire.NewSet(\n    NewUserRepository,\n    wire.Bind(new(UserRepository), new(*userRepositoryImpl)),\n)\n```\n\n## Struct Provider\n\n구조체 필드를 직접 주입할 수 있습니다:\n\n```go\ntype App struct {\n    UserService  *UserService\n    OrderService *OrderService\n    Logger       *Logger\n}\n\nvar AppSet = wire.NewSet(\n    wire.Struct(new(App), \"*\"), // 모든 필드 주입\n    // 또는 특정 필드만\n    // wire.Struct(new(App), \"UserService\", \"Logger\"),\n)\n```\n\n## Value Provider\n\n정적 값을 제공할 수 있습니다:\n\n```go\nfunc InitializeApp(cfg *Config) (*App, error) {\n    wire.Build(\n        wire.Value(&Config{DBHost: \"localhost\"}), // 정적 값\n        NewDatabase,\n        NewApp,\n    )\n    return nil, nil\n}\n```\n\n## 실전 프로젝트 구조\n\n```\nmyapp/\n├── cmd/\n│   └── api/\n│       ├── main.go\n│       ├── wire.go          # Injector 정의\n│       └── wire_gen.go      # 생성된 코드\n├── internal/\n│   ├── config/\n│   │   └── config.go\n│   ├── infrastructure/\n│   │   ├── database.go\n│   │   ├── redis.go\n│   │   └── wire.go          # Provider Set\n│   ├── repository/\n│   │   ├── user_repository.go\n│   │   └── wire.go\n│   ├── service/\n│   │   ├── user_service.go\n│   │   └── wire.go\n│   └── handler/\n│       ├── user_handler.go\n│       └── wire.go\n└── go.mod\n```\n\n### cmd/api/wire.go\n\n```go\n//go:build wireinject\n\npackage main\n\nimport (\n    \"github.com/google/wire\"\n    \"myapp/internal/config\"\n    \"myapp/internal/infrastructure\"\n    \"myapp/internal/repository\"\n    \"myapp/internal/service\"\n    \"myapp/internal/handler\"\n)\n\nfunc InitializeServer(cfg *config.Config) (*Server, error) {\n    wire.Build(\n        infrastructure.InfraSet,\n        repository.RepositorySet,\n        service.ServiceSet,\n        handler.HandlerSet,\n        NewServer,\n    )\n    return nil, nil\n}\n```\n\n### cmd/api/main.go\n\n```go\npackage main\n\nfunc main() {\n    cfg := config.Load()\n    \n    server, err := InitializeServer(cfg)\n    if err != nil {\n        log.Fatal(err)\n    }\n    \n    server.Run()\n}\n```\n\n## 테스트에서 Wire 활용\n\n```go\n// wire_test.go\n//go:build wireinject\n\npackage main\n\nimport \"github.com/google/wire\"\n\nfunc InitializeTestUserService(mockDB *MockDatabase) *UserService {\n    wire.Build(\n        NewUserRepository,\n        NewUserService,\n    )\n    return nil\n}\n```\n\n## Makefile 통합\n\n```makefile\n.PHONY: generate wire\n\nwire:\n wire ./...\n\ngenerate: wire\n go generate ./...\n\nbuild: generate\n go build -o bin/app ./cmd/api\n```\n\n## 주의사항\n\n1. **빌드 태그 필수**: `//go:build wireinject` 잊지 말 것\n2. **wire_gen.go 커밋**: 생성된 코드는 버전 관리에 포함\n3. **순환 의존성 불가**: Wire가 에러로 감지\n4. **에러 처리**: Provider가 error를 반환하면 자동 전파\n\n## 참고 자료\n\n- [Wire GitHub](https://github.com/google/wire)\n- [Wire Tutorial](https://github.com/google/wire/blob/main/docs/guide.md)\n- [Wire Best Practices](https://github.com/google/wire/blob/main/docs/best-practices.md)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "DI",
      "Wire",
      "Architecture"
    ],
    "readingTime": 4,
    "wordCount": 720,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "pprof-profiling-guide",
    "slug": "pprof-profiling-guide",
    "path": "backend/go",
    "fullPath": "backend/go/pprof-profiling-guide",
    "title": "Go pprof를 활용한 성능 프로파일링 가이드",
    "excerpt": "Go의 내장 프로파일링 도구 pprof를 활용하여 CPU, 메모리, 고루틴 병목을 분석하는 방법을 알아봅니다.",
    "content": "# Go pprof를 활용한 성능 프로파일링 가이드\n\n## 개요\n\n**pprof**는 Go에 내장된 프로파일링 도구로, CPU 사용량, 메모리 할당, 고루틴 상태 등을 분석할 수 있습니다. 프로덕션 환경에서도 안전하게 사용할 수 있어 성능 최적화에 필수적입니다.\n\n## 기본 설정\n\n### HTTP 서버에 pprof 엔드포인트 추가\n\n```go\npackage main\n\nimport (\n    \"net/http\"\n    _ \"net/http/pprof\" // 자동으로 /debug/pprof/* 엔드포인트 등록\n)\n\nfunc main() {\n    go func() {\n        // 별도 포트에서 pprof 서버 실행 (보안상 권장)\n        http.ListenAndServe(\"localhost:6060\", nil)\n    }()\n    \n    // 메인 애플리케이션 로직\n    // ...\n}\n```\n\n### 제공되는 엔드포인트\n\n| 엔드포인트 | 설명 |\n|----------|------|\n| `/debug/pprof/` | 프로파일 인덱스 페이지 |\n| `/debug/pprof/heap` | 메모리 할당 프로파일 |\n| `/debug/pprof/goroutine` | 고루틴 스택 트레이스 |\n| `/debug/pprof/profile` | CPU 프로파일 (30초) |\n| `/debug/pprof/trace` | 실행 트레이스 |\n\n## CPU 프로파일링\n\n### 프로파일 수집\n\n```bash\n# 30초간 CPU 프로파일 수집\ngo tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n\n# 또는 파일로 저장\ncurl -o cpu.prof http://localhost:6060/debug/pprof/profile?seconds=30\ngo tool pprof cpu.prof\n```\n\n### 주요 명령어\n\n```bash\n# pprof 인터랙티브 모드에서\n(pprof) top10          # 상위 10개 함수\n(pprof) list funcName  # 특정 함수의 라인별 분석\n(pprof) web            # 그래프 시각화 (브라우저)\n(pprof) pdf            # PDF로 저장\n```\n\n### 출력 예시\n\n```\n      flat  flat%   sum%        cum   cum%\n     2.50s 25.00% 25.00%      4.00s 40.00%  main.processData\n     1.50s 15.00% 40.00%      1.50s 15.00%  runtime.mallocgc\n     1.00s 10.00% 50.00%      3.00s 30.00%  encoding/json.Marshal\n```\n\n| 컬럼 | 설명 |\n|-----|------|\n| `flat` | 해당 함수 자체 실행 시간 |\n| `cum` | 해당 함수 + 호출한 함수 합계 시간 |\n\n## 메모리 프로파일링\n\n### 힙 프로파일 수집\n\n```bash\n# 현재 힙 상태\ngo tool pprof http://localhost:6060/debug/pprof/heap\n\n# 할당된 객체 수 기준\ngo tool pprof -alloc_objects http://localhost:6060/debug/pprof/heap\n\n# 할당된 메모리 크기 기준\ngo tool pprof -alloc_space http://localhost:6060/debug/pprof/heap\n```\n\n### 메모리 누수 탐지\n\n```go\n// runtime.MemStats 활용\nimport \"runtime\"\n\nfunc printMemStats() {\n    var m runtime.MemStats\n    runtime.ReadMemStats(&m)\n    \n    fmt.Printf(\"Alloc = %v MiB\\n\", m.Alloc / 1024 / 1024)\n    fmt.Printf(\"TotalAlloc = %v MiB\\n\", m.TotalAlloc / 1024 / 1024)\n    fmt.Printf(\"Sys = %v MiB\\n\", m.Sys / 1024 / 1024)\n    fmt.Printf(\"NumGC = %v\\n\", m.NumGC)\n}\n```\n\n## 고루틴 프로파일링\n\n```bash\n# 현재 고루틴 상태 확인\ngo tool pprof http://localhost:6060/debug/pprof/goroutine\n\n# 덤프 파일로 저장\ncurl http://localhost:6060/debug/pprof/goroutine?debug=2 > goroutines.txt\n```\n\n고루틴 누수 징후:\n\n- 고루틴 수가 지속적으로 증가\n- 특정 함수에서 대기 중인 고루틴이 많음\n\n## 웹 UI로 시각화\n\n**pprof 웹 인터페이스** (Go 1.10+):\n\n```bash\ngo tool pprof -http=:8080 cpu.prof\n```\n\n브라우저에서 `http://localhost:8080`으로 접속하면:\n\n- **Top**: 함수별 CPU/메모리 사용량\n- **Graph**: 호출 그래프\n- **Flame Graph**: 플레임 차트\n- **Source**: 소스 코드 레벨 분석\n\n## 프로덕션 환경 고도화\n\n### 1. 보안 설정\n\n```go\npackage main\n\nimport (\n    \"net/http\"\n    \"net/http/pprof\"\n)\n\nfunc main() {\n    // 별도 서버에서 인증 추가\n    pprofMux := http.NewServeMux()\n    pprofMux.HandleFunc(\"/debug/pprof/\", pprof.Index)\n    pprofMux.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline)\n    pprofMux.HandleFunc(\"/debug/pprof/profile\", pprof.Profile)\n    pprofMux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol)\n    pprofMux.HandleFunc(\"/debug/pprof/trace\", pprof.Trace)\n    \n    // 인증 미들웨어 적용\n    go http.ListenAndServe(\"localhost:6060\", authMiddleware(pprofMux))\n}\n```\n\n### 2. 연속 프로파일링 (Continuous Profiling)\n\n```go\nimport (\n    \"os\"\n    \"runtime/pprof\"\n    \"time\"\n)\n\nfunc startContinuousProfiling() {\n    ticker := time.NewTicker(10 * time.Minute)\n    for range ticker.C {\n        f, _ := os.Create(fmt.Sprintf(\"heap_%s.prof\", time.Now().Format(\"20060102_150405\")))\n        pprof.WriteHeapProfile(f)\n        f.Close()\n    }\n}\n```\n\n### 3. 외부 서비스 연동\n\n- **Pyroscope**: 오픈소스 연속 프로파일링\n- **Datadog Continuous Profiler**: 상용 APM\n- **Google Cloud Profiler**: GCP 통합\n\n```go\n// Pyroscope 예시\nimport \"github.com/grafana/pyroscope-go\"\n\nfunc main() {\n    pyroscope.Start(pyroscope.Config{\n        ApplicationName: \"my-app\",\n        ServerAddress:   \"http://pyroscope:4040\",\n    })\n}\n```\n\n## 벤치마크와 함께 사용\n\n```bash\n# 벤치마크 실행 + CPU 프로파일\ngo test -bench=. -cpuprofile=cpu.prof\n\n# 벤치마크 실행 + 메모리 프로파일\ngo test -bench=. -memprofile=mem.prof\n\n# 분석\ngo tool pprof cpu.prof\n```\n\n## 주의사항\n\n1. **프로덕션 포트 분리**: pprof 엔드포인트는 별도 포트에서 실행\n2. **인증 필수**: 외부 노출 시 반드시 인증 적용\n3. **오버헤드**: CPU 프로파일링은 약 5% 오버헤드 발생\n4. **샘플링 주기**: `runtime.SetCPUProfileRate()`로 조절 가능\n\n## 참고 자료\n\n- [Go pprof 공식 문서](https://pkg.go.dev/net/http/pprof)\n- [Profiling Go Programs](https://go.dev/blog/pprof)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "Performance",
      "pprof",
      "Profiling"
    ],
    "readingTime": 4,
    "wordCount": 603,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "ginkgo-bdd-testing",
    "slug": "ginkgo-bdd-testing",
    "path": "backend/go",
    "fullPath": "backend/go/ginkgo-bdd-testing",
    "title": "Ginkgo와 Testcontainers를 활용한 통합 테스트 전략",
    "excerpt": "Ginkgo BDD 프레임워크와 Testcontainers를 결합하여 실제 데이터베이스를 사용하는 신뢰성 높은 통합 테스트를 구축하는 방법을 알아봅니다.",
    "content": "# Ginkgo와 Testcontainers를 활용한 통합 테스트 전략\n\n## 개요\n\n**Ginkgo**는 Go의 BDD 테스트 프레임워크이며, **Testcontainers**는 테스트에서 Docker 컨테이너를 프로그래매틱하게 관리합니다. 이 조합으로 Mock 없이 실제 데이터베이스를 사용하는 통합 테스트를 구축할 수 있습니다.\n\n## 왜 이 조합인가?\n\n### 장점\n\n| 특성 | 설명 |\n|------|------|\n| **실제 환경** | Mock 대신 실제 DB로 테스트 → 높은 신뢰도 |\n| **격리성** | 테스트마다 깨끗한 컨테이너 환경 |\n| **BDD 가독성** | Describe/Context/It으로 의도 명확히 표현 |\n| **병렬 실행** | 컨테이너 격리로 안전한 병렬 테스트 |\n\n### 단점\n\n| 특성 | 설명 |\n|------|------|\n| **속도** | 컨테이너 시작 시간으로 유닛 테스트보다 느림 |\n| **리소스** | Docker 실행 필요, CI에서 추가 설정 필요 |\n| **복잡성** | 컨테이너 라이프사이클 관리 필요 |\n\n## 설치\n\n```bash\n# Ginkgo CLI 및 라이브러리\ngo install github.com/onsi/ginkgo/v2/ginkgo@latest\ngo get github.com/onsi/gomega/...\n\n# Testcontainers\ngo get github.com/testcontainers/testcontainers-go\ngo get github.com/testcontainers/testcontainers-go/modules/mongodb\ngo get github.com/testcontainers/testcontainers-go/modules/redis\n```\n\n## 테스트 환경 구조\n\n### 테스트 헬퍼\n\n```go\n// testutils/mongodb.go\npackage testutils\n\nimport (\n    \"context\"\n    \"os\"\n    \n    \"github.com/testcontainers/testcontainers-go\"\n    \"github.com/testcontainers/testcontainers-go/modules/mongodb\"\n    \"go.mongodb.org/mongo-driver/mongo\"\n    \"go.mongodb.org/mongo-driver/mongo/options\"\n)\n\n// MongoDBFixture는 MongoDB 테스트 환경을 관리합니다.\ntype MongoDBFixture struct {\n    container *mongodb.MongoDBContainer\n    client    *mongo.Client\n    cleanup   func()\n}\n\nfunc (f *MongoDBFixture) GetConnectionString() (string, error) {\n    return f.container.ConnectionString(context.Background())\n}\n\nfunc (f *MongoDBFixture) GetClient() *mongo.Client {\n    return f.client\n}\n\nfunc (f *MongoDBFixture) Cleanup() {\n    f.cleanup()\n}\n\n// GetMongoDBFixture는 MongoDB 테스트 Fixture를 생성합니다.\n// packageName을 전달하면 동일 이름의 컨테이너를 재사용하여 테스트 속도를 높입니다.\nfunc GetMongoDBFixture(ctx context.Context, packageName string) (*MongoDBFixture, error) {\n    // Ryuk(리소스 정리 컨테이너) 비활성화 - CI 환경에서 권장\n    os.Setenv(\"TESTCONTAINERS_RYUK_DISABLED\", \"true\")\n    \n    // ReplicaSet 활성화 - 트랜잭션 테스트에 필요\n    replicaSetName := \"rs0\"\n    \n    mongoContainer, err := mongodb.Run(ctx,\n        \"public.ecr.aws/docker/library/mongo:8\",  // 공식 ECR 이미지\n        mongodb.WithReplicaSet(replicaSetName),   // 트랜잭션 지원\n        testcontainers.WithReuseByName(packageName), // 컨테이너 재사용으로 속도 향상\n    )\n    if err != nil {\n        return nil, err\n    }\n    \n    // 연결 문자열 가져오기\n    connString, err := mongoContainer.ConnectionString(ctx)\n    if err != nil {\n        return nil, err\n    }\n    \n    // ReplicaSet 사용 시 Direct 연결 필요\n    clientOpts := options.Client().ApplyURI(connString)\n    clientOpts.SetDirect(true)\n    \n    mongoClient, err := mongo.Connect(ctx, clientOpts)\n    if err != nil {\n        return nil, err\n    }\n    \n    // 연결 확인\n    if err := mongoClient.Ping(ctx, nil); err != nil {\n        return nil, err\n    }\n    \n    // cleanup 클로저 - 컨테이너와 클라이언트 정리\n    cleanup := func(client *mongo.Client, container *mongodb.MongoDBContainer) func() {\n        return func() {\n            client.Disconnect(ctx)\n            container.Terminate(ctx)\n        }\n    }(mongoClient, mongoContainer)\n    \n    return &MongoDBFixture{\n        container: mongoContainer,\n        client:    mongoClient,\n        cleanup:   cleanup,\n    }, nil\n}\n```\n\n### Redis Fixture\n\n```go\n// testutils/redis.go\npackage testutils\n\nimport (\n    \"context\"\n    \"os\"\n    \n    goredis \"github.com/redis/go-redis/v9\"\n    \"github.com/testcontainers/testcontainers-go/modules/redis\"\n)\n\ntype RedisFixture struct {\n    container *redis.RedisContainer\n    client    *goredis.Client\n    cleanup   func()\n}\n\nfunc (f *RedisFixture) GetClient() *goredis.Client {\n    return f.client\n}\n\nfunc (f *RedisFixture) Cleanup() {\n    f.cleanup()\n}\n\nfunc (f *RedisFixture) GetConnectionString() (string, error) {\n    return f.container.Endpoint(context.Background(), \"\")\n}\n\nfunc GetRedisFixture(ctx context.Context, packageName string) (*RedisFixture, error) {\n    os.Setenv(\"TESTCONTAINERS_RYUK_DISABLED\", \"true\")\n    \n    redisContainer, err := redis.Run(ctx,\n        \"public.ecr.aws/docker/library/redis:alpine\",\n    )\n    if err != nil {\n        return nil, err\n    }\n    \n    // Endpoint로 host:port 형태의 주소 획득\n    redisAddr, err := redisContainer.Endpoint(ctx, \"\")\n    if err != nil {\n        return nil, err\n    }\n    \n    // Options에 직접 Addr 설정\n    redisClient := goredis.NewClient(&goredis.Options{\n        Addr: redisAddr,\n    })\n    \n    if err := redisClient.Ping(ctx).Err(); err != nil {\n        return nil, err\n    }\n    \n    cleanup := func(client *goredis.Client, container *redis.RedisContainer) func() {\n        return func() {\n            client.Close()\n            container.Terminate(ctx)\n        }\n    }(redisClient, redisContainer)\n    \n    return &RedisFixture{\n        container: redisContainer,\n        client:    redisClient,\n        cleanup:   cleanup,\n    }, nil\n}\n```\n\n### 테스트 스위트 설정\n\n```go\n// internal/document/document_suite_test.go\npackage document_test\n\nimport (\n    \"context\"\n    \"testing\"\n    \n    . \"github.com/onsi/ginkgo/v2\"\n    . \"github.com/onsi/gomega\"\n    \n    \"myapp/testutil\"\n)\n\nvar (\n    testEnv *testutil.TestEnvironment\n    testCtx context.Context\n)\n\nfunc TestDocument(t *testing.T) {\n    RegisterFailHandler(Fail)\n    RunSpecs(t, \"Document Suite\")\n}\n\nvar _ = BeforeSuite(func() {\n    var err error\n    testCtx = context.Background()\n    \n    By(\"테스트 환경 초기화\")\n    testEnv, err = testutil.NewTestEnvironment(testCtx)\n    Expect(err).NotTo(HaveOccurred())\n    \n    By(\"MongoDB 연결 확인\")\n    // ... 연결 테스트\n})\n\nvar _ = AfterSuite(func() {\n    By(\"테스트 환경 정리\")\n    testEnv.Cleanup(testCtx)\n})\n```\n\n## 테스트 작성\n\n### 문서 서비스 통합 테스트\n\n```go\n// internal/document/service_integration_test.go\npackage document_test\n\nimport (\n    \"context\"\n    \n    . \"github.com/onsi/ginkgo/v2\"\n    . \"github.com/onsi/gomega\"\n    \n    \"go.mongodb.org/mongo-driver/mongo\"\n    \"go.mongodb.org/mongo-driver/mongo/options\"\n    \n    \"myapp/internal/document\"\n)\n\nvar _ = Describe(\"DocumentService 통합 테스트\", Label(\"integration\"), func() {\n    var (\n        service    document.Service\n        collection *mongo.Collection\n        ctx        context.Context\n    )\n    \n    BeforeEach(func() {\n        ctx = context.Background()\n        \n        // 테스트용 MongoDB 클라이언트\n        client, err := mongo.Connect(ctx, options.Client().ApplyURI(testEnv.MongoURI))\n        Expect(err).NotTo(HaveOccurred())\n        \n        // 테스트마다 새 컬렉션 사용\n        dbName := \"test_db\"\n        collName := \"test_collection_\" + GinkgoParallelProcess()\n        collection = client.Database(dbName).Collection(collName)\n        \n        // 서비스 생성\n        service = document.NewService(client, dbName)\n    })\n    \n    AfterEach(func() {\n        // 테스트 데이터 정리\n        collection.Drop(ctx)\n    })\n    \n    Describe(\"Create\", func() {\n        Context(\"유효한 문서가 주어졌을 때\", func() {\n            It(\"버전 1의 새 문서를 생성한다\", func() {\n                input := document.CreateInput{\n                    URI: \"doc-001\",\n                    Fields: map[string]interface{}{\n                        \"name\":  \"Test Document\",\n                        \"value\": 42,\n                    },\n                }\n                \n                doc, err := service.Create(ctx, \"test_collection\", input)\n                \n                Expect(err).NotTo(HaveOccurred())\n                Expect(doc.URI).To(Equal(\"doc-001\"))\n                Expect(doc.Version).To(Equal(int32(1)))\n                Expect(doc.Fields[\"name\"]).To(Equal(\"Test Document\"))\n            })\n        })\n        \n        Context(\"중복 URI가 주어졌을 때\", func() {\n            BeforeEach(func() {\n                _, err := service.Create(ctx, \"test_collection\", document.CreateInput{\n                    URI:    \"doc-001\",\n                    Fields: map[string]interface{}{},\n                })\n                Expect(err).NotTo(HaveOccurred())\n            })\n            \n            It(\"에러를 반환한다\", func() {\n                _, err := service.Create(ctx, \"test_collection\", document.CreateInput{\n                    URI:    \"doc-001\",\n                    Fields: map[string]interface{}{},\n                })\n                \n                Expect(err).To(HaveOccurred())\n                Expect(err).To(MatchError(ContainSubstring(\"duplicate\")))\n            })\n        })\n    })\n    \n    Describe(\"SoftUpdate\", func() {\n        var existingDoc *document.Document\n        \n        BeforeEach(func() {\n            var err error\n            existingDoc, err = service.Create(ctx, \"test_collection\", document.CreateInput{\n                URI:    \"doc-update-test\",\n                Fields: map[string]interface{}{\"name\": \"Original\"},\n            })\n            Expect(err).NotTo(HaveOccurred())\n        })\n        \n        Context(\"정상적인 업데이트 요청일 때\", func() {\n            It(\"새 버전을 생성하고 기존 버전을 보존한다\", func() {\n                updated, err := service.SoftUpdate(ctx, \"test_collection\", \"doc-update-test\", \n                    document.UpdateInput{\n                        Fields: map[string]interface{}{\"name\": \"Updated\"},\n                    },\n                )\n                \n                Expect(err).NotTo(HaveOccurred())\n                Expect(updated.Version).To(Equal(int32(2)))\n                Expect(updated.Fields[\"name\"]).To(Equal(\"Updated\"))\n                \n                // 이전 버전이 보존되는지 확인\n                history, err := service.GetHistory(ctx, \"test_collection\", \"doc-update-test\")\n                Expect(err).NotTo(HaveOccurred())\n                Expect(history).To(HaveLen(2))\n                Expect(history[0].Version).To(Equal(int32(1)))\n                Expect(history[1].Version).To(Equal(int32(2)))\n            })\n        })\n    })\n    \n    Describe(\"SoftDelete\", func() {\n        BeforeEach(func() {\n            _, err := service.Create(ctx, \"test_collection\", document.CreateInput{\n                URI:    \"doc-delete-test\",\n                Fields: map[string]interface{}{\"data\": \"value\"},\n            })\n            Expect(err).NotTo(HaveOccurred())\n        })\n        \n        It(\"문서를 DELETED 상태로 마킹한다\", func() {\n            deleted, err := service.SoftDelete(ctx, \"test_collection\", \"doc-delete-test\")\n            \n            Expect(err).NotTo(HaveOccurred())\n            Expect(deleted.Status).To(Equal(document.StatusDeleted))\n            \n            // 최신 버전 조회 시 찾을 수 없음\n            _, err = service.FindLatest(ctx, \"test_collection\", \"doc-delete-test\")\n            Expect(err).To(MatchError(document.ErrNotFound))\n        })\n    })\n})\n```\n\n### Redis 통합 테스트\n\n```go\n// internal/worker/worker_integration_test.go\npackage worker_test\n\nimport (\n    \"context\"\n    \"time\"\n    \n    . \"github.com/onsi/ginkgo/v2\"\n    . \"github.com/onsi/gomega\"\n    \n    \"github.com/redis/go-redis/v9\"\n    \n    \"myapp/internal/worker\"\n)\n\nvar _ = Describe(\"StreamWorker 통합 테스트\", Label(\"integration\"), func() {\n    var (\n        redisClient redis.UniversalClient\n        ctx         context.Context\n    )\n    \n    BeforeEach(func() {\n        ctx = context.Background()\n        \n        redisClient = redis.NewClient(&redis.Options{\n            Addr: testEnv.RedisAddr,\n        })\n        \n        // 이전 테스트 데이터 정리\n        redisClient.FlushAll(ctx)\n    })\n    \n    AfterEach(func() {\n        redisClient.Close()\n    })\n    \n    Describe(\"메시지 처리\", func() {\n        Context(\"정상 메시지가 발행되었을 때\", func() {\n            It(\"핸들러가 호출되고 ACK 처리된다\", func() {\n                processed := make(chan string, 1)\n                \n                handler := &testHandler{\n                    onHandle: func(msgs []*worker.Message) []error {\n                        for _, m := range msgs {\n                            processed <- m.ID\n                        }\n                        return nil\n                    },\n                }\n                \n                w := worker.NewStreamWorker(\n                    redisClient,\n                    handler,\n                    worker.WithStream(\"test-stream\"),\n                    worker.WithGroup(\"test-group\"),\n                    worker.WithBatchSize(1),\n                    worker.WithPollInterval(50*time.Millisecond),\n                )\n                \n                w.Start(ctx)\n                defer w.Stop()\n                \n                // 메시지 발행\n                redisClient.XAdd(ctx, &redis.XAddArgs{\n                    Stream: \"test-stream\",\n                    Values: map[string]interface{}{\"data\": \"test\"},\n                })\n                \n                // 처리 확인\n                Eventually(processed).Should(Receive())\n                \n                // ACK 확인 (Pending 없음)\n                pending, _ := redisClient.XPending(ctx, \"test-stream\", \"test-group\").Result()\n                Expect(pending.Count).To(BeZero())\n            })\n        })\n        \n        Context(\"처리 실패 시\", func() {\n            It(\"Dead Letter 스트림으로 이동한다\", func() {\n                handler := &testHandler{\n                    onHandle: func(msgs []*worker.Message) []error {\n                        return []error{errors.New(\"processing failed\")}\n                    },\n                }\n                \n                w := worker.NewStreamWorker(\n                    redisClient,\n                    handler,\n                    worker.WithStream(\"test-stream\"),\n                    worker.WithGroup(\"test-group\"),\n                    worker.WithMaxRetries(1),\n                    worker.WithDeadLetterStream(\"dead-letters\"),\n                )\n                \n                w.Start(ctx)\n                defer w.Stop()\n                \n                // 메시지 발행\n                redisClient.XAdd(ctx, &redis.XAddArgs{\n                    Stream: \"test-stream\",\n                    Values: map[string]interface{}{\"data\": \"fail\"},\n                })\n                \n                // Dead Letter 확인\n                Eventually(func() int64 {\n                    len, _ := redisClient.XLen(ctx, \"dead-letters\").Result()\n                    return len\n                }).Should(BeNumerically(\">\", 0))\n            })\n        })\n    })\n})\n\ntype testHandler struct {\n    onHandle func([]*worker.Message) []error\n}\n\nfunc (h *testHandler) Handle(ctx context.Context, msgs []*worker.Message) []error {\n    return h.onHandle(msgs)\n}\n```\n\n## 테이블 드리븐 테스트\n\nGinkgo의 `DescribeTable`로 다양한 케이스 커버:\n\n```go\nvar _ = Describe(\"스키마 검증\", func() {\n    DescribeTable(\"유효한 문서\",\n        func(fields map[string]interface{}, expectValid bool) {\n            err := validator.Validate(schema, fields)\n            \n            if expectValid {\n                Expect(err).NotTo(HaveOccurred())\n            } else {\n                Expect(err).To(HaveOccurred())\n            }\n        },\n        Entry(\"모든 필수 필드 존재\", map[string]interface{}{\n            \"name\": \"test\", \"email\": \"test@example.com\",\n        }, true),\n        Entry(\"필수 필드 누락\", map[string]interface{}{\n            \"name\": \"test\",\n        }, false),\n        Entry(\"잘못된 타입\", map[string]interface{}{\n            \"name\": 123, \"email\": \"test@example.com\",\n        }, false),\n    )\n})\n```\n\n## 테스트 실행\n\n### 기본 실행\n\n```bash\n# 모든 테스트\nginkgo ./...\n\n# 상세 출력\nginkgo -v ./...\n\n# 통합 테스트만\nginkgo --label-filter=\"integration\" ./...\n\n# 유닛 테스트만 (통합 제외)\nginkgo --label-filter=\"!integration\" ./...\n```\n\n### 병렬 실행\n\n```bash\n# 프로세스 자동 결정\nginkgo -p ./...\n\n# 프로세스 수 지정\nginkgo -procs=4 ./...\n```\n\n### 커버리지\n\n```bash\nginkgo -cover -coverprofile=coverage.out ./...\ngo tool cover -html=coverage.out -o coverage.html\n```\n\n## Makefile 통합\n\n```makefile\n# 기본 테스트 플래그 + 추가 인자는 TESTFLAGS로 전달\nTEST_FLAGS = --skip-package \"./deps\"\nTEST_FLAGS += $(TESTFLAGS)\nTEST_TIMEOUT = 30m\nCOVERAGE_OUT = coverage.out\n\n.PHONY: test test-verbose unit-test integration-test coverage-test cov-html\n\ntest:\n ginkgo -r $(TEST_FLAGS) --timeout=$(TEST_TIMEOUT)\n\ntest-verbose:\n ginkgo -r $(TEST_FLAGS) --timeout=$(TEST_TIMEOUT) -v\n\nunit-test:\n ginkgo -r $(TEST_FLAGS) --label-filter=\"!integration\" --junit-report=unit-test-report.xml --timeout=$(TEST_TIMEOUT)\n\nintegration-test:\n ginkgo -r $(TEST_FLAGS) --label-filter=\"integration\" --junit-report=integration-test-report.xml --timeout=$(TEST_TIMEOUT)\n\ncoverage-test:\n ginkgo -r -cover --coverprofile=$(COVERAGE_OUT) --timeout=$(TEST_TIMEOUT)\n\ncov-html: coverage-test\n go tool cover -html=$(COVERAGE_OUT) -o coverage.html\n```\n\n### 사용 예시\n\n```bash\n# 전체 테스트\nmake test\n\n# 상세 출력\nmake test-verbose\n\n# 유닛 테스트만\nmake unit-test\n\n# 통합 테스트만\nmake integration-test\n\n# 커버리지 HTML 리포트\nmake cov-html\n\n# 추가 인자 전달 (특정 패키지, focus 등)\nmake test TESTFLAGS=\"./internal/document/...\"\nmake test TESTFLAGS='--focus=\"CreateDocument\"'\nmake test-verbose TESTFLAGS=\"-p\"\n```\n\n## CI 설정\n\n```yaml\n# .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  unit-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.24'\n      \n      - name: Install Ginkgo\n        run: go install github.com/onsi/ginkgo/v2/ginkgo@latest\n      \n      - name: Run Unit Tests\n        run: ginkgo -r --label-filter=\"!integration\"\n  \n  integration-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.24'\n      \n      - name: Install Ginkgo\n        run: go install github.com/onsi/ginkgo/v2/ginkgo@latest\n      \n      - name: Run Integration Tests\n        run: ginkgo -r --label-filter=\"integration\" --timeout=30m\n```\n\n## 모범 사례\n\n1. **Label 사용**: `integration` 라벨로 유닛/통합 테스트 분리\n2. **병렬 안전**: `GinkgoParallelProcess()`로 리소스 이름 분리\n3. **정리 철저**: `AfterEach`로 테스트 데이터 반드시 정리\n4. **타임아웃 설정**: 통합 테스트는 충분한 타임아웃 설정\n5. **실패 격리**: 한 테스트 실패가 다른 테스트에 영향 없도록\n\n## 참고 자료\n\n- [Ginkgo 공식 문서](https://onsi.github.io/ginkgo/)\n- [Gomega 공식 문서](https://onsi.github.io/gomega/)\n- [Testcontainers Go](https://golang.testcontainers.org/)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "Testing",
      "BDD",
      "Ginkgo",
      "Testcontainers",
      "Docker",
      "MongoDB",
      "Redis"
    ],
    "readingTime": 8,
    "wordCount": 1520,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "gc-tuning-experience",
    "slug": "gc-tuning-experience",
    "path": "backend/go",
    "fullPath": "backend/go/gc-tuning-experience",
    "title": "Go 가비지 컬렉터(GC) 이해와 튜닝 경험",
    "excerpt": "Go의 가비지 컬렉터 동작 원리와 프로덕션 환경에서의 GC 튜닝 경험을 공유합니다.",
    "content": "# Go 가비지 컬렉터(GC) 이해와 튜닝 경험\n\n## 개요\n\nGo는 **Concurrent Mark-and-Sweep** 방식의 가비지 컬렉터를 사용합니다. Go 1.5 이후 STW(Stop-The-World) 시간을 최소화하는 방향으로 지속적으로 개선되어, 대부분의 경우 1ms 이하의 pause time을 달성합니다.\n\n## GC 동작 원리\n\n### Tricolor Mark-and-Sweep\n\nGo GC는 **삼색 마킹 알고리즘**을 사용합니다:\n\n| 색상 | 의미 |\n|-----|------|\n| **White** | 아직 스캔되지 않음 (수집 대상 후보) |\n| **Gray** | 스캔 중, 참조 객체 확인 필요 |\n| **Black** | 스캔 완료, 참조 객체 모두 확인됨 |\n\n### GC 단계\n\n```\n1. Mark Setup (STW)     → 0.1ms 미만\n2. Concurrent Marking   → 백그라운드에서 실행\n3. Mark Termination (STW) → 0.1ms 미만\n4. Concurrent Sweeping  → 백그라운드에서 실행\n```\n\n> Go 1.8+부터 대부분의 STW 시간이 **sub-millisecond** 수준입니다.\n\n## GC 모니터링\n\n### runtime 패키지 활용\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"time\"\n)\n\nfunc printGCStats() {\n    var stats runtime.MemStats\n    runtime.ReadMemStats(&stats)\n    \n    fmt.Printf(\"Alloc = %v MiB\\n\", stats.Alloc/1024/1024)\n    fmt.Printf(\"HeapAlloc = %v MiB\\n\", stats.HeapAlloc/1024/1024)\n    fmt.Printf(\"HeapSys = %v MiB\\n\", stats.HeapSys/1024/1024)\n    fmt.Printf(\"NumGC = %v\\n\", stats.NumGC)\n    fmt.Printf(\"PauseTotalNs = %v ms\\n\", stats.PauseTotalNs/1e6)\n    fmt.Printf(\"LastGC = %v\\n\", time.Unix(0, int64(stats.LastGC)))\n}\n```\n\n### GODEBUG 환경변수\n\n```bash\n# GC 트레이스 활성화\nGODEBUG=gctrace=1 ./myapp\n\n# 출력 예시:\n# gc 1 @0.012s 2%: 0.018+1.2+0.014 ms clock, 0.14+0.8/1.0/0+0.11 ms cpu, 4->4->1 MB, 5 MB goal, 8 P\n```\n\n| 필드 | 의미 |\n|-----|------|\n| `gc 1` | GC 번호 |\n| `2%` | CPU 사용률 |\n| `0.018+1.2+0.014 ms` | STW + concurrent + STW 시간 |\n| `4->4->1 MB` | 힙: 시작 → 종료 → 라이브 |\n| `5 MB goal` | 다음 GC 목표 힙 크기 |\n\n## GOGC 튜닝\n\n### GOGC 환경변수\n\n**GOGC**는 GC 트리거 임계값을 조절합니다:\n\n```bash\n# 기본값: 100 (힙이 2배가 되면 GC)\nGOGC=100 ./myapp\n\n# 더 자주 GC (메모리 절약, CPU 증가)\nGOGC=50 ./myapp\n\n# 덜 자주 GC (메모리 증가, CPU 절약)\nGOGC=200 ./myapp\n\n# GC 비활성화 (극단적 케이스)\nGOGC=off ./myapp\n```\n\n### 런타임에서 조절\n\n```go\nimport \"runtime/debug\"\n\n// GOGC 값 변경\ndebug.SetGCPercent(50)\n\n// 현재 값 확인 및 변경\nold := debug.SetGCPercent(200)\nfmt.Printf(\"Previous GOGC: %d\\n\", old)\n```\n\n## 메모리 제한 (Go 1.19+)\n\n### GOMEMLIMIT\n\nGo 1.19에서 도입된 **소프트 메모리 제한**:\n\n```bash\n# 최대 4GB 힙 제한\nGOMEMLIMIT=4GiB ./myapp\n```\n\n```go\nimport \"runtime/debug\"\n\n// 런타임에서 설정\ndebug.SetMemoryLimit(4 * 1024 * 1024 * 1024) // 4GB\n```\n\n### GOGC + GOMEMLIMIT 조합\n\n```bash\n# 권장: GOGC=off + GOMEMLIMIT\n# 메모리 제한에 도달하면 자동으로 GC\nGOGC=off GOMEMLIMIT=2GiB ./myapp\n```\n\n## 프로덕션 튜닝 경험\n\n### Case 1: 고빈도 할당 서비스\n\n**문제**: 초당 10만 건 요청 처리, GC pause가 p99 레이턴시에 영향\n\n**해결**:\n\n```go\n// sync.Pool로 객체 재사용\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return make([]byte, 4096)\n    },\n}\n\nfunc handleRequest() {\n    buf := bufferPool.Get().([]byte)\n    defer bufferPool.Put(buf)\n    \n    // buf 사용\n}\n```\n\n**결과**: 할당량 70% 감소, GC 빈도 50% 감소\n\n### Case 2: 대용량 캐시 서비스\n\n**문제**: 32GB 힙, GC marking 시간이 길어짐\n\n**해결**:\n\n```bash\n# 메모리 제한 설정으로 예측 가능한 GC\nGOMEMLIMIT=30GiB GOGC=100 ./cache-server\n```\n\n또한 **외부 캐시**(Redis, Memcached)로 대용량 데이터 오프로드\n\n### Case 3: 배치 처리 워커\n\n**문제**: 배치 처리 중 GC가 처리 시간에 영향\n\n**해결**:\n\n```go\nfunc processBatch(items []Item) {\n    // 배치 처리 전 GC 강제 실행\n    runtime.GC()\n    \n    // 처리 중 GC 비활성화\n    debug.SetGCPercent(-1)\n    defer debug.SetGCPercent(100)\n    \n    for _, item := range items {\n        process(item)\n    }\n}\n```\n\n## 메모리 할당 최적화\n\n### 1. 사전 할당\n\n```go\n// Bad\nvar result []int\nfor i := 0; i < 1000; i++ {\n    result = append(result, i)\n}\n\n// Good\nresult := make([]int, 0, 1000)\nfor i := 0; i < 1000; i++ {\n    result = append(result, i)\n}\n```\n\n### 2. 포인터 회피\n\n```go\n// 힙 할당 유발\ntype Bad struct {\n    data *int\n}\n\n// 스택 할당 가능\ntype Good struct {\n    data int\n}\n```\n\n### 3. Escape Analysis 활용\n\n```bash\n# 이스케이프 분석 결과 확인\ngo build -gcflags=\"-m\" ./...\n```\n\n## Ballast 기법 (레거시)\n\n> **Note**: Go 1.19+ GOMEMLIMIT 도입 이후 ballast 기법은 권장되지 않습니다.\n\n```go\n// 레거시: 큰 배열로 힙 크기 유지\nvar ballast = make([]byte, 1<<30) // 1GB\n\nfunc main() {\n    _ = ballast // 변수 유지\n    // ...\n}\n```\n\n## 모니터링 지표\n\n프로덕션에서 추적해야 할 GC 관련 지표:\n\n| 지표 | 설명 | 임계값 |\n|-----|------|-------|\n| `go_gc_duration_seconds` | GC pause 시간 | p99 < 10ms |\n| `go_memstats_heap_alloc_bytes` | 현재 힙 사용량 | GOMEMLIMIT의 80% |\n| `go_memstats_gc_cpu_fraction` | GC CPU 사용률 | < 5% |\n\n## 참고 자료\n\n- [Go GC Guide](https://tip.golang.org/doc/gc-guide)\n- [Go 1.19 Memory Limit](https://go.dev/blog/go1.19)\n- [Getting to Go: The Journey of Go's Garbage Collector](https://go.dev/blog/ismmkeynote)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "GC",
      "Performance",
      "Memory"
    ],
    "readingTime": 4,
    "wordCount": 740,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "buf-protobuf-management",
    "slug": "buf-protobuf-management",
    "path": "backend/go",
    "fullPath": "backend/go/buf-protobuf-management",
    "title": "Buf v2 기반 Proto 관리 및 코드 자동 생성",
    "excerpt": "Buf v2를 활용하여 Protobuf 스키마를 체계적으로 관리하고, gRPC 서버/클라이언트, HTTP Gateway, OpenAPI 스펙을 자동 생성하는 방법을 알아봅니다.",
    "content": "# Buf v2 기반 Proto 관리 및 코드 자동 생성\n\n## 개요\n\n대규모 gRPC 서비스에서 **Protobuf 스키마**는 서비스 계약의 핵심입니다. **Buf v2**는 Proto 파일의 린트, Breaking Change 감지, 다중 언어 코드 생성을 통합 관리합니다.\n\n## 왜 Buf인가?\n\n### protoc 대비 장점\n\n| 기능 | protoc | buf v2 |\n|------|--------|--------|\n| 의존성 관리 | 수동 (include 경로) | 자동 (BSR/deps) |\n| 린팅 | 별도 도구 필요 | 내장 + 커스텀 규칙 |\n| Breaking Change | 없음 | 자동 감지 |\n| 플러그인 관리 | 로컬 설치 필수 | Remote Plugins 지원 |\n| 설정 | 복잡한 CLI 플래그 | YAML 설정 파일 |\n\n### 단점\n\n| 특성 | 설명 |\n|------|------|\n| 학습 곡선 | 신규 설정 체계 이해 필요 |\n| BSR 의존성 | 일부 기능은 Buf Schema Registry 필요 |\n| 네트워크 | Remote Plugins 사용 시 인터넷 연결 필요 |\n\n## 프로젝트 구조\n\n### Proto 전용 레포지토리\n\n```\nproto-service/\n├── buf.yaml              # 모듈 설정\n├── buf.gen.yaml          # 코드 생성 설정\n├── buf.lock              # 의존성 락 파일\n├── deps/                 # 로컬 의존성 (선택)\n│   └── custom/\n│       └── options.proto\n└── proto/\n    └── v1beta/\n        └── api.proto     # 서비스 정의\n```\n\n## 설정 파일\n\n### buf.yaml (모듈 설정)\n\n```yaml\n# buf.yaml\nversion: v2\nmodules:\n  - path: proto/v1beta\n    name: buf.build/myorg/myservice\n  - path: deps/custom  # 로컬 의존성 모듈\ndeps:\n  # 외부 의존성 (Google APIs, gRPC-Gateway 등)\n  - buf.build/googleapis/googleapis\n  - buf.build/grpc-ecosystem/grpc-gateway\n  - buf.build/gnostic/gnostic\nlint:\n  use:\n    - STANDARD\n  except:\n    - FIELD_NOT_REQUIRED\n    - PACKAGE_NO_IMPORT_CYCLE\n  disallow_comment_ignores: true\nbreaking:\n  use:\n    - FILE\n  except:\n    - EXTENSION_NO_DELETE\n    - FIELD_SAME_DEFAULT\n```\n\n### buf.gen.yaml (코드 생성 설정)\n\n```yaml\n# buf.gen.yaml\nversion: v2\nmanaged:\n  enabled: true\n  disable:\n    - module: buf.build/googleapis/googleapis\n    - module: buf.build/grpc-ecosystem/grpc-gateway\n    - module: buf.build/gnostic/gnostic\n  override:\n    - file_option: go_package_prefix\n      value: github.com/myorg/myservice/generated/go/proto/\nplugins:\n  # Go Protobuf 메시지\n  - remote: buf.build/protocolbuffers/go:v1.36.2\n    out: generated/go/proto\n    opt: paths=source_relative\n  \n  # gRPC Go 서버/클라이언트\n  - remote: buf.build/grpc/go:v1.5.1\n    out: generated/go/proto\n    opt: paths=source_relative\n  \n  # gRPC-Gateway (HTTP 핸들러)\n  - remote: buf.build/grpc-ecosystem/gateway:v2.25.1\n    out: generated/go/proto/gateway\n    opt:\n      - paths=source_relative\n      - standalone=true\n  \n  # OpenAPI 스펙 자동 생성\n  - remote: buf.build/community/google-gnostic-openapi:v0.7.0\n    out: generated/docs\n    opt: paths=source_relative\n\ninputs:\n  - directory: proto/v1beta\n  - proto_file: deps/custom/options.proto  # 특정 파일만 포함\n```\n\n## Proto 작성 예시\n\n### 서비스 정의\n\n```protobuf\n// proto/v1beta/api.proto\nsyntax = \"proto3\";\n\npackage v1beta;\n\nimport \"gnostic/openapi/v3/annotations.proto\";\nimport \"google/api/annotations.proto\";\nimport \"google/protobuf/struct.proto\";\nimport \"google/protobuf/timestamp.proto\";\n\n// DocumentService는 버전 관리 문서를 관리합니다.\nservice DocumentService {\n  // 새 문서를 생성합니다. 버전 1로 시작됩니다.\n  rpc CreateDocument(CreateDocumentRequest) returns (CreateDocumentResponse) {\n    option (google.api.http) = {\n      post: \"/v1beta/collections/{collection}/documents\"\n      body: \"*\"\n    };\n  }\n  \n  // URI로 문서를 조회합니다. 버전 미지정 시 최신 버전을 반환합니다.\n  rpc GetDocument(GetDocumentRequest) returns (GetDocumentResponse) {\n    option (google.api.http) = {\n      get: \"/v1beta/collections/{collection}/documents/{uri}\"\n    };\n  }\n  \n  // 문서를 업데이트합니다. 새 버전이 생성됩니다.\n  rpc UpdateDocument(UpdateDocumentRequest) returns (UpdateDocumentResponse) {\n    option (google.api.http) = {\n      patch: \"/v1beta/collections/{collection}/documents/{uri}\"\n      body: \"*\"\n    };\n  }\n  \n  // 문서를 삭제합니다. 소프트 삭제로 처리됩니다.\n  rpc DeleteDocument(DeleteDocumentRequest) returns (DeleteDocumentResponse) {\n    option (google.api.http) = {\n      delete: \"/v1beta/collections/{collection}/documents/{uri}\"\n    };\n  }\n}\n\n// 문서 상태\nenum DocumentStatus {\n  DOCUMENT_STATUS_UNSPECIFIED = 0;\n  DOCUMENT_STATUS_ACTIVE = 1;\n  DOCUMENT_STATUS_DELETED = 2;\n}\n\n// 문서 모델\nmessage Document {\n  // MongoDB ObjectID 문자열\n  optional string id = 1 [(gnostic.openapi.v3.property) = {\n    description: \"문서의 데이터베이스 ID\"\n    nullable: true\n  }];\n  \n  // 논리적 문서 식별자 (버전 전체에서 공유)\n  string uri = 2 [(gnostic.openapi.v3.property) = {\n    description: \"문서의 고유 식별자\"\n    nullable: false\n  }];\n  \n  // JSON 스키마를 준수하는 문서 데이터\n  google.protobuf.Struct fields = 3 [(gnostic.openapi.v3.property) = {\n    description: \"문서 필드 데이터\"\n    nullable: false\n  }];\n  \n  // 버전 번호 (1부터 시작, 업데이트마다 증가)\n  int32 version = 4;\n  \n  // 문서 상태\n  DocumentStatus status = 5;\n  \n  // 생성 시각\n  google.protobuf.Timestamp created_at = 6;\n  \n  // 업데이트 시각\n  google.protobuf.Timestamp updated_at = 7;\n}\n\n// 요청/응답 메시지들\nmessage CreateDocumentRequest {\n  string collection = 1;\n  DocumentInput document = 2;\n}\n\nmessage DocumentInput {\n  string uri = 1;\n  google.protobuf.Struct fields = 2;\n}\n\nmessage CreateDocumentResponse {\n  Document document = 1;\n}\n\nmessage GetDocumentRequest {\n  string collection = 1;\n  string uri = 2;\n  optional int32 version = 3;  // 미지정 시 최신 버전\n}\n\nmessage GetDocumentResponse {\n  Document document = 1;\n}\n\nmessage UpdateDocumentRequest {\n  string collection = 1;\n  string uri = 2;\n  google.protobuf.Struct fields = 3;\n  optional int32 expected_version = 4;  // Optimistic Locking\n}\n\nmessage UpdateDocumentResponse {\n  Document document = 1;\n}\n\nmessage DeleteDocumentRequest {\n  string collection = 1;\n  string uri = 2;\n}\n\nmessage DeleteDocumentResponse {\n  bool success = 1;\n}\n```\n\n## 코드 생성\n\n### 기본 생성\n\n```bash\n# 의존성 업데이트\nbuf mod update\n\n# 코드 생성\nbuf generate\n\n# 생성 구조\ngenerated/\n├── go/\n│   └── proto/\n│       ├── v1beta/\n│       │   ├── api.pb.go         # 메시지 정의\n│       │   └── api_grpc.pb.go    # gRPC 서버/클라이언트\n│       └── gateway/\n│           └── v1beta/\n│               └── api.pb.gw.go  # HTTP Gateway\n└── docs/\n    └── v1beta/\n        └── openapi.yaml          # OpenAPI 스펙\n```\n\n### 특정 경로만 생성\n\n```bash\nbuf generate --path proto/v1beta/api.proto\n```\n\n## 생성된 코드 활용\n\n### gRPC 서버\n\n```go\npackage main\n\nimport (\n    \"net\"\n    \n    \"google.golang.org/grpc\"\n    pb \"github.com/myorg/myservice/generated/go/proto/v1beta\"\n)\n\ntype documentServer struct {\n    pb.UnimplementedDocumentServiceServer\n    service DocumentService\n}\n\nfunc (s *documentServer) CreateDocument(ctx context.Context, req *pb.CreateDocumentRequest) (*pb.CreateDocumentResponse, error) {\n    doc, err := s.service.Create(ctx, req.Collection, req.Document)\n    if err != nil {\n        return nil, err\n    }\n    return &pb.CreateDocumentResponse{Document: doc}, nil\n}\n\nfunc main() {\n    lis, _ := net.Listen(\"tcp\", \":9090\")\n    \n    grpcServer := grpc.NewServer()\n    pb.RegisterDocumentServiceServer(grpcServer, &documentServer{})\n    \n    grpcServer.Serve(lis)\n}\n```\n\n### HTTP Gateway\n\n```go\npackage main\n\nimport (\n    \"net/http\"\n    \n    \"github.com/grpc-ecosystem/grpc-gateway/v2/runtime\"\n    gw \"github.com/myorg/myservice/generated/go/proto/gateway/v1beta\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    mux := runtime.NewServeMux()\n    \n    // gRPC 서버에 연결하여 HTTP 요청 프록시\n    opts := []grpc.DialOption{grpc.WithTransportCredentials(insecure.NewCredentials())}\n    err := gw.RegisterDocumentServiceHandlerFromEndpoint(ctx, mux, \"localhost:9090\", opts)\n    if err != nil {\n        panic(err)\n    }\n    \n    // HTTP 서버 시작\n    http.ListenAndServe(\":8080\", mux)\n}\n```\n\n### OpenAPI 스펙\n\n생성된 `openapi.yaml`을 Swagger UI와 함께 제공:\n\n```go\nfunc main() {\n    // ... Gateway 설정 ...\n    \n    // OpenAPI 스펙 제공\n    http.HandleFunc(\"/openapi.yaml\", func(w http.ResponseWriter, r *http.Request) {\n        http.ServeFile(w, r, \"generated/docs/v1beta/openapi.yaml\")\n    })\n}\n```\n\n## 린팅 및 Breaking Change 감지\n\n### 린트 실행\n\n```bash\nbuf lint\n\n# 특정 파일만\nbuf lint --path proto/v1beta/api.proto\n\n# 에러 출력 예시:\n# proto/v1beta/api.proto:15:3:Field \"id\" should be marked as optional.\n```\n\n### Breaking Change 감지\n\n```bash\n# 현재 브랜치 vs main\nbuf breaking --against '.git#branch=main'\n\n# 현재 vs 이전 커밋\nbuf breaking --against '.git#ref=HEAD~1'\n\n# 현재 vs BSR 최신 버전\nbuf breaking --against 'buf.build/myorg/myservice'\n```\n\n## CI/CD 통합\n\n### GitHub Actions\n\n```yaml\n# .github/workflows/proto.yml\nname: Proto CI\n\non:\n  push:\n    paths: ['proto/**', 'buf.*']\n  pull_request:\n    paths: ['proto/**', 'buf.*']\n\njobs:\n  lint-and-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - uses: bufbuild/buf-setup-action@v1\n        with:\n          version: latest\n      \n      - name: Lint\n        run: buf lint\n      \n      - name: Breaking Change Check\n        run: buf breaking --against 'https://github.com/${{ github.repository }}.git#branch=main'\n  \n  generate:\n    needs: lint-and-check\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - uses: bufbuild/buf-setup-action@v1\n      \n      - name: Generate Code\n        run: buf generate\n      \n      - name: Check for uncommitted changes\n        run: |\n          if [[ -n $(git status --porcelain generated/) ]]; then\n            echo \"Generated code is out of sync!\"\n            git diff generated/\n            exit 1\n          fi\n```\n\n## Makefile 통합\n\n```makefile\n.PHONY: proto-deps proto-lint proto-breaking proto-gen proto-clean\n\n# 의존성 업데이트\nproto-deps:\n buf mod update\n\n# 린트\nproto-lint:\n buf lint\n\n# Breaking Change 검사\nproto-breaking:\n buf breaking --against '.git#branch=main'\n\n# 코드 생성\nproto-gen:\n buf generate\n\n# 정리\nproto-clean:\n rm -rf generated/\n\n# 전체 빌드\nproto-all: proto-deps proto-lint proto-gen\n```\n\n## 모범 사례\n\n1. **버전 네이밍**: 패키지에 `v1`, `v1beta` 등 버전 포함\n2. **Breaking Change CI**: PR마다 자동 검사\n3. **생성 코드 커밋**: `.gitignore`에 `generated/` 추가 권장\n4. **Proto 주석**: 서비스/메시지 주석은 생성 코드와 OpenAPI에 반영됨\n5. **Optional 명시**: Proto3에서 `optional` 키워드로 nullable 명확히 표현\n\n## 참고 자료\n\n- [Buf 공식 문서](https://buf.build/docs/)\n- [Buf Schema Registry](https://buf.build/docs/bsr/introduction)\n- [gRPC-Gateway](https://grpc-ecosystem.github.io/grpc-gateway/)\n- [gnostic OpenAPI](https://github.com/google/gnostic)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Go",
      "Protobuf",
      "buf",
      "gRPC",
      "gRPC-Gateway",
      "OpenAPI"
    ],
    "readingTime": 7,
    "wordCount": 1210,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "서비스-규모에-따른-스케일링-전략",
    "slug": "seobiseu-gyumoe-ddareun-seukeilring-jeonryag",
    "path": "backend/devops",
    "fullPath": "backend/devops/seobiseu-gyumoe-ddareun-seukeilring-jeonryag",
    "title": "서비스 규모에 따른 스케일링 전략",
    "excerpt": "사용자 1명부터 10만 명까지, 서비스 규모별로 적용해야 할 인프라 스케일링 전략을 단계별로 정리합니다.",
    "content": "# 서비스 규모에 따른 스케일링 전략\n\n서비스가 성장함에 따라 인프라도 함께 진화해야 합니다. 이 글에서는 사용자 규모별로 어떤 아키텍처 전략을 채택해야 하는지 정리합니다.\n\n## 1명 → 단일 서버\n\n모든 애플리케이션은 세 가지 핵심 컴포넌트로 구성됩니다:\n\n- **API 서버**: 데이터 요청 처리\n- **데이터베이스**: 영속성 데이터 저장\n- **클라이언트**: 사용자에게 데이터 렌더링\n\n초기 단계에서는 이 모든 것을 하나의 서버에서 실행할 수 있습니다. 개발 환경과 유사한 구성으로, 단일 EC2 인스턴스나 DigitalOcean Droplet으로 시작합니다.\n\n```mermaid\nflowchart TB\n    subgraph server[\"Single Server\"]\n        API[API]\n        DB[(DB)]\n        Client[Client]\n    end\n```\n\n## 10명 → 데이터베이스 분리\n\n한 명 이상의 사용자가 예상된다면, 데이터베이스 계층을 분리하는 것이 좋습니다.\n\n**관리형 데이터베이스 서비스 사용의 장점:**\n\n- 자동화된 백업\n- 다중 리전 중복성\n- 읽기 전용 복제본 쉽게 추가 가능\n\nAWS RDS, DigitalOcean Managed Database 등의 서비스를 활용합니다.\n\n```mermaid\nflowchart LR\n    AppServer[\"App Server<br/>(API + Client)\"] --> ManagedDB[(\"Managed DB<br/>(RDS, etc.)\")]\n```\n\n## 100명 → 클라이언트 분리\n\n**엔티티 분리**는 확장 가능한 애플리케이션 구축의 핵심 원칙입니다.\n\n클라이언트를 API와 분리하면:\n\n- 웹, 모바일 웹, iOS, Android, 데스크톱 등 다양한 플랫폼 지원 용이\n- 각 컴포넌트를 독립적으로 스케일링 가능\n- 트래픽 패턴에 따른 유연한 리소스 할당\n\n```mermaid\nflowchart LR\n    WebClient[Web Client] --> API[API Server]\n    MobileApp[Mobile App] --> API\n    API --> DB[(DB)]\n```\n\n## 1,000명 → 로드 밸런서 도입\n\n단일 API 인스턴스가 모든 트래픽을 처리하기 어려워지면, **로드 밸런서**를 도입합니다.\n\n**로드 밸런서의 이점:**\n\n- **수평적 확장(Horizontal Scaling)**: 동일한 코드를 실행하는 서버 추가\n- **중복성(Redundancy)**: 한 인스턴스가 다운되어도 서비스 지속\n- **오토 스케일링**: 트래픽에 따라 자동으로 인스턴스 수 조절\n\n```mermaid\nflowchart LR\n    Client[Client] --> LB[Load Balancer]\n    LB --> API1[API Server 1]\n    LB --> API2[API Server 2]\n    LB --> API3[API Server 3]\n    API1 --> DB[(DB)]\n    API2 --> DB\n    API3 --> DB\n```\n\n> 💡 **Tip**: Heroku나 AWS Elastic Beanstalk 같은 PaaS 서비스는 이 단계까지의 구성을 기본으로 제공합니다. 초기 스타트업이나 사이드 프로젝트에 적합합니다.\n\n## 10,000명 → CDN 도입\n\n이미지, 비디오 등 정적 콘텐츠가 서버에 부하를 주기 시작합니다.\n\n**해결책: 클라우드 스토리지 + CDN**\n\n- AWS S3, DigitalOcean Spaces 등으로 정적 콘텐츠 호스팅\n- CDN(CloudFront 등)으로 전 세계 데이터 센터에 캐싱\n\n**CDN의 작동 방식:**\n\n1. 메인 데이터 센터가 오하이오에 있다고 가정\n2. 일본에서 이미지 요청 시, 클라우드 제공자가 일본 데이터 센터에 사본 저장\n3. 이후 일본에서의 요청은 훨씬 빠르게 응답\n\n```mermaid\nflowchart TB\n    subgraph CDN[\"S3 + CDN\"]\n        Tokyo[Edge: Tokyo]\n        Seoul[Edge: Seoul]\n        Sydney[Edge: Sydney]\n    end\n    Client[Client] --> LB[Load Balancer]\n    LB --> API[API]\n    API --> DB[(DB)]\n    Client -.->|Static Assets| CDN\n```\n\n## 100,000명 → 데이터 계층 확장\n\nAPI 서버는 로드 밸런서로 쉽게 스케일링할 수 있지만, **데이터베이스 스케일링은 가장 까다로운 부분**입니다.\n\n### 캐싱 (Caching)\n\n**Redis** 또는 **Memcached**를 사용한 인메모리 캐시 도입:\n\n```python\n# 캐시 적용 예시\ndef get_user_profile(user_id):\n    # 1. 캐시 먼저 확인\n    cached = redis.get(f\"user:{user_id}\")\n    if cached:\n        return cached\n    \n    # 2. 캐시 미스 시 DB 조회\n    user = db.query(f\"SELECT * FROM users WHERE id = {user_id}\")\n    \n    # 3. 캐시에 저장 (TTL 30초)\n    redis.setex(f\"user:{user_id}\", 30, user)\n    return user\n```\n\n**캐싱이 효과적인 경우:**\n\n- 동일한 데이터에 대한 반복적인 요청\n- 자주 변경되지 않는 데이터 (프로필 정보, 설정 등)\n- 인기 콘텐츠 (인플루언서 프로필 등)\n\n### 읽기 전용 복제본 (Read Replicas)\n\n데이터베이스 읽기/쓰기 트래픽을 분리합니다:\n\n- **Master DB**: INSERT, UPDATE, DELETE 처리\n- **Read Replicas**: SELECT 쿼리 처리\n\n```mermaid\nflowchart TB\n    Write[\"INSERT/UPDATE/DELETE\"] --> Master[(Master DB)]\n    Master --> R1[(Read Replica 1)]\n    Master --> R2[(Read Replica 2)]\n    Master --> R3[(Read Replica 3)]\n    Read1[SELECT] --> R1\n    Read2[SELECT] --> R2\n    Read3[SELECT] --> R3\n```\n\n## 100,000명 이상 → 마이크로서비스 & 샤딩\n\n이 단계에서는 더 복잡한 전략이 필요합니다:\n\n### 서비스 분리 (마이크로서비스)\n\n- 독립적으로 스케일링이 필요한 기능을 별도 서비스로 분리\n- 예: WebSocket 처리, 알림 서비스, 검색 서비스\n\n### 데이터베이스 샤딩\n\n- 데이터를 여러 데이터베이스에 분산 저장\n- 수평 파티셔닝으로 데이터 계층 무한 확장 가능\n\n### 모니터링 강화\n\n- New Relic, Datadog 등으로 병목 지점 파악\n- 요청 지연 분석 및 개선 포인트 식별\n\n## 정리: 규모별 체크리스트\n\n| 사용자 수 | 핵심 전략 | 도입 기술 |\n|-----------|-----------|-----------|\n| 1명 | 단일 서버 | EC2, Droplet |\n| 10명 | DB 분리 | RDS, Managed DB |\n| 100명 | 클라이언트 분리 | 별도 프론트엔드 배포 |\n| 1,000명 | 로드 밸런싱 | ALB, ELB, Nginx |\n| 10,000명 | CDN | CloudFront, S3 |\n| 100,000명 | 캐싱 + 읽기 복제본 | Redis, Read Replicas |\n| 100,000명+ | 마이크로서비스 + 샤딩 | K8s, DB Sharding |\n\n## 핵심 원칙\n\n1. **과도한 엔지니어링 회피**: 현재 규모에 맞는 솔루션 선택\n2. **엔티티 분리**: 독립적으로 스케일링 가능한 구조 설계\n3. **모니터링 우선**: 병목 지점을 파악한 후 최적화\n4. **관리형 서비스 활용**: 운영 부담 감소\n\n---\n\n## References\n\n- [Scaling to 100k Users - Alex Pareto](https://alexpareto.com/scalability/systems/2020/02/03/scaling-100k.html)\n- [번역 - 10만명 접속을 허용하는 시스템 만들기](https://brunch.co.kr/@jowlee/102)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [
      "scaling",
      "architecture",
      "devops",
      "infrastructure"
    ],
    "readingTime": 4,
    "wordCount": 749,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "locust-e2e-testing",
    "slug": "locust-e2e-testing",
    "path": "backend/devops",
    "fullPath": "backend/devops/locust-e2e-testing",
    "title": "Locust 기반 환경별 E2E 테스트 자동화",
    "excerpt": "Locust를 활용하여 개발부터 프로덕션까지 환경별 E2E 테스트를 자동화하고 Kubernetes에서 실행하는 방법을 알아봅니다.",
    "content": "# Locust 기반 환경별 E2E 테스트 자동화\n\n## 개요\n\n**Locust**는 Python 기반의 오픈소스 부하 테스트 도구입니다. 코드로 테스트 시나리오를 작성하고, 다양한 환경(INT/STAGE/PROD)에서 일관된 E2E 테스트를 실행할 수 있습니다.\n\n## 왜 Locust인가?\n\n### 장점\n\n| 특성 | 설명 |\n|------|------|\n| **코드 기반** | Python으로 복잡한 시나리오 작성 |\n| **분산 실행** | 여러 워커로 대규모 부하 생성 |\n| **실시간 모니터링** | Web UI로 실시간 메트릭 확인 |\n| **유연성** | 다양한 프로토콜 지원 (HTTP, gRPC 등) |\n| **Kubernetes 친화** | Job/Pod으로 쉽게 배포 |\n\n### 단점\n\n| 특성 | 설명 |\n|------|------|\n| **Python 의존** | Python 환경 필요 |\n| **초기 설정** | 복잡한 시나리오는 코드 작성 필요 |\n\n## 프로젝트 구조\n\n```\ne2e/\n├── .python-version          # Python 버전\n├── pyproject.toml           # 의존성 정의\n├── Makefile                 # 실행 스크립트\n├── config/\n│   ├── local.yaml           # 로컬 환경 설정\n│   ├── int.yaml             # 통합 환경 설정\n│   ├── stage.yaml           # 스테이지 설정\n│   └── prod.yaml            # 프로덕션 설정\n├── suites/\n│   ├── smoke.py             # 스모크 테스트\n│   ├── functional.py        # 기능 테스트\n│   ├── performance.py       # 성능 테스트\n│   └── stress.py            # 스트레스 테스트\n├── utils/\n│   ├── client.py            # API 클라이언트\n│   └── data_generator.py    # 테스트 데이터 생성\n└── locustfile.py            # 메인 진입점\n```\n\n## 설정 파일\n\n### pyproject.toml\n\n```toml\n[project]\nname = \"e2e-tests\"\nversion = \"1.0.0\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"locust>=2.20.0\",\n    \"pyyaml>=6.0\",\n    \"grpcio>=1.60.0\",\n    \"grpcio-tools>=1.60.0\",\n]\n\n[tool.uv]\ndev-dependencies = [\n    \"pytest>=8.0.0\",\n]\n```\n\n### 환경별 설정\n\n```yaml\n# config/int.yaml\nenvironment: int\nbase_url: https://api-int.example.com\ngrpc_host: grpc-int.example.com:443\n\nsettings:\n  default_timeout: 30\n  max_retries: 3\n\ntest_data:\n  collection_prefix: \"e2e_test_\"\n  cleanup_after: true\n```\n\n## 테스트 스위트 구현\n\n### 기본 클라이언트\n\n```python\n# utils/client.py\nfrom typing import Any\nimport grpc\nfrom locust import events\n\nclass APIClient:\n    def __init__(self, base_url: str, timeout: int = 30):\n        self.base_url = base_url\n        self.timeout = timeout\n    \n    def create_document(self, collection: str, uri: str, fields: dict) -> dict:\n        \"\"\"문서를 생성합니다.\"\"\"\n        response = self._post(\n            f\"/v1beta/collections/{collection}/documents\",\n            json={\n                \"document\": {\n                    \"uri\": uri,\n                    \"fields\": fields\n                }\n            }\n        )\n        return response.json()\n    \n    def get_document(self, collection: str, uri: str) -> dict:\n        \"\"\"문서를 조회합니다.\"\"\"\n        response = self._get(f\"/v1beta/collections/{collection}/documents/{uri}\")\n        return response.json()\n    \n    def update_document(self, collection: str, uri: str, fields: dict) -> dict:\n        \"\"\"문서를 업데이트합니다.\"\"\"\n        response = self._patch(\n            f\"/v1beta/collections/{collection}/documents/{uri}\",\n            json={\"fields\": fields}\n        )\n        return response.json()\n    \n    def delete_document(self, collection: str, uri: str) -> bool:\n        \"\"\"문서를 삭제합니다.\"\"\"\n        response = self._delete(f\"/v1beta/collections/{collection}/documents/{uri}\")\n        return response.json().get(\"success\", False)\n```\n\n### 스모크 테스트\n\n빠른 헬스체크 및 기본 기능 확인:\n\n```python\n# suites/smoke.py\nfrom locust import HttpUser, task, between\nimport uuid\n\nclass SmokeTestUser(HttpUser):\n    \"\"\"30초 내 핵심 기능 검증\"\"\"\n    \n    wait_time = between(0.5, 1)\n    \n    def on_start(self):\n        \"\"\"테스트 시작 전 초기화\"\"\"\n        self.collection = f\"smoke_test_{uuid.uuid4().hex[:8]}\"\n        self.created_docs = []\n    \n    @task(3)\n    def create_and_get_document(self):\n        \"\"\"문서 생성 및 조회 테스트\"\"\"\n        doc_uri = f\"doc-{uuid.uuid4().hex[:8]}\"\n        \n        # 생성\n        with self.client.post(\n            f\"/v1beta/collections/{self.collection}/documents\",\n            json={\n                \"document\": {\n                    \"uri\": doc_uri,\n                    \"fields\": {\"test\": True, \"timestamp\": str(time.time())}\n                }\n            },\n            catch_response=True\n        ) as response:\n            if response.status_code == 200:\n                self.created_docs.append(doc_uri)\n                response.success()\n            else:\n                response.failure(f\"Create failed: {response.text}\")\n        \n        # 조회\n        with self.client.get(\n            f\"/v1beta/collections/{self.collection}/documents/{doc_uri}\",\n            catch_response=True\n        ) as response:\n            if response.status_code == 200:\n                data = response.json()\n                if data.get(\"document\", {}).get(\"uri\") == doc_uri:\n                    response.success()\n                else:\n                    response.failure(\"URI mismatch\")\n            else:\n                response.failure(f\"Get failed: {response.text}\")\n    \n    @task(1)\n    def health_check(self):\n        \"\"\"헬스체크\"\"\"\n        self.client.get(\"/ready\")\n    \n    def on_stop(self):\n        \"\"\"테스트 종료 후 정리\"\"\"\n        for uri in self.created_docs:\n            self.client.delete(f\"/v1beta/collections/{self.collection}/documents/{uri}\")\n```\n\n### 기능 테스트\n\nCRUD 전체 흐름 및 엣지 케이스:\n\n```python\n# suites/functional.py\nfrom locust import HttpUser, task, between, SequentialTaskSet\nimport uuid\n\nclass DocumentCRUDFlow(SequentialTaskSet):\n    \"\"\"순차적 CRUD 플로우 테스트\"\"\"\n    \n    def on_start(self):\n        self.doc_uri = f\"crud-test-{uuid.uuid4().hex[:8]}\"\n        self.version = 0\n    \n    @task\n    def step1_create(self):\n        \"\"\"1. 문서 생성\"\"\"\n        response = self.client.post(\n            f\"/v1beta/collections/functional_test/documents\",\n            json={\n                \"document\": {\n                    \"uri\": self.doc_uri,\n                    \"fields\": {\"step\": 1, \"status\": \"created\"}\n                }\n            }\n        )\n        if response.status_code == 200:\n            self.version = response.json()[\"document\"][\"version\"]\n    \n    @task\n    def step2_read(self):\n        \"\"\"2. 문서 조회\"\"\"\n        response = self.client.get(\n            f\"/v1beta/collections/functional_test/documents/{self.doc_uri}\"\n        )\n        assert response.json()[\"document\"][\"version\"] == self.version\n    \n    @task\n    def step3_update(self):\n        \"\"\"3. 문서 업데이트\"\"\"\n        response = self.client.patch(\n            f\"/v1beta/collections/functional_test/documents/{self.doc_uri}\",\n            json={\n                \"fields\": {\"step\": 2, \"status\": \"updated\"},\n                \"expected_version\": self.version\n            }\n        )\n        if response.status_code == 200:\n            self.version = response.json()[\"document\"][\"version\"]\n    \n    @task\n    def step4_verify_history(self):\n        \"\"\"4. 히스토리 확인\"\"\"\n        response = self.client.get(\n            f\"/v1beta/collections/functional_test/documents/{self.doc_uri}/history\"\n        )\n        history = response.json()[\"documents\"]\n        assert len(history) == 2  # 버전 1, 2\n    \n    @task\n    def step5_delete(self):\n        \"\"\"5. 문서 삭제\"\"\"\n        response = self.client.delete(\n            f\"/v1beta/collections/functional_test/documents/{self.doc_uri}\"\n        )\n        assert response.json()[\"success\"] == True\n        self.interrupt()  # 플로우 종료\n\n\nclass FunctionalTestUser(HttpUser):\n    wait_time = between(1, 3)\n    tasks = [DocumentCRUDFlow]\n```\n\n### 성능/스트레스 테스트\n\n```python\n# suites/performance.py\nfrom locust import HttpUser, task, between, LoadTestShape\nimport uuid\n\nclass PerformanceTestUser(HttpUser):\n    \"\"\"고부하 성능 테스트\"\"\"\n    \n    wait_time = between(0.1, 0.5)  # 빠른 요청\n    \n    @task(5)\n    def batch_create(self):\n        \"\"\"배치 생성\"\"\"\n        docs = [\n            {\"uri\": f\"perf-{uuid.uuid4().hex[:8]}\", \"fields\": {\"batch\": True}}\n            for _ in range(10)\n        ]\n        self.client.post(\n            \"/v1beta/collections/perf_test/documents:batchCreate\",\n            json={\"documents\": docs}\n        )\n    \n    @task(10)\n    def query_documents(self):\n        \"\"\"쿼리 테스트\"\"\"\n        self.client.post(\n            \"/v1beta/collections/perf_test/documents:query\",\n            json={\n                \"query\": {\"filter\": {}},\n                \"page_size\": 100\n            }\n        )\n\n\nclass StressTestShape(LoadTestShape):\n    \"\"\"점진적 부하 증가 테스트\"\"\"\n    \n    stages = [\n        {\"duration\": 60, \"users\": 10, \"spawn_rate\": 2},    # 램프업\n        {\"duration\": 120, \"users\": 50, \"spawn_rate\": 5},   # 유지\n        {\"duration\": 60, \"users\": 100, \"spawn_rate\": 10},  # 피크\n        {\"duration\": 60, \"users\": 50, \"spawn_rate\": 10},   # 다운\n    ]\n    \n    def tick(self):\n        run_time = self.get_run_time()\n        \n        for stage in self.stages:\n            if run_time < stage[\"duration\"]:\n                return (stage[\"users\"], stage[\"spawn_rate\"])\n            run_time -= stage[\"duration\"]\n        \n        return None  # 테스트 종료\n```\n\n### 메인 진입점\n\n```python\n# locustfile.py\nimport os\nimport yaml\nfrom locust import events\n\nfrom suites.smoke import SmokeTestUser\nfrom suites.functional import FunctionalTestUser\nfrom suites.performance import PerformanceTestUser\n\n# 환경 설정 로드\ndef load_config():\n    env = os.getenv(\"TEST_ENV\", \"local\")\n    config_path = f\"config/{env}.yaml\"\n    \n    with open(config_path) as f:\n        return yaml.safe_load(f)\n\nCONFIG = load_config()\n\n@events.init.add_listener\ndef on_locust_init(environment, **kwargs):\n    \"\"\"테스트 초기화\"\"\"\n    environment.host = CONFIG[\"base_url\"]\n    print(f\"Testing against: {CONFIG['environment']}\")\n\n# 테스트 모드에 따른 User 클래스 선택\nTEST_MODE = os.getenv(\"TEST_MODE\", \"smoke\")\n\nif TEST_MODE == \"smoke\":\n    class User(SmokeTestUser):\n        pass\nelif TEST_MODE == \"functional\":\n    class User(FunctionalTestUser):\n        pass\nelif TEST_MODE == \"performance\":\n    class User(PerformanceTestUser):\n        pass\n```\n\n## Makefile\n\n```makefile\n# e2e/Makefile\n\n.PHONY: install smoke functional performance stress\n\nLOCUST_FLAGS = --headless --only-summary\n\ninstall:\n uv sync\n\n# 스모크 테스트 (30초, 1 사용자)\nsmoke:\n TEST_MODE=smoke TEST_ENV=$(ENV) locust \\\n  $(LOCUST_FLAGS) \\\n  -u 1 -r 1 -t 30s\n\n# 기능 테스트 (5분, 10 사용자)\nfunctional:\n TEST_MODE=functional TEST_ENV=$(ENV) locust \\\n  $(LOCUST_FLAGS) \\\n  -u 10 -r 2 -t 300s\n\n# 성능 테스트 (10분, 50 사용자)\nperformance:\n TEST_MODE=performance TEST_ENV=$(ENV) locust \\\n  $(LOCUST_FLAGS) \\\n  -u 50 -r 5 -t 600s\n\n# 스트레스 테스트 (10분, 100 사용자)\nstress:\n TEST_MODE=stress TEST_ENV=$(ENV) locust \\\n  $(LOCUST_FLAGS) \\\n  -u 100 -r 10 -t 600s\n\n# 인터랙티브 모드 (Web UI)\ninteractive:\n TEST_MODE=$(MODE) TEST_ENV=$(ENV) locust\n\n# 환경별 실행\ntest-local:\n $(MAKE) smoke ENV=local\n\ntest-int:\n $(MAKE) functional ENV=int\n\ntest-stage:\n $(MAKE) performance ENV=stage\n```\n\n## Kubernetes 배포\n\n### ConfigMap\n\n```yaml\n# k8s/tests/locust/configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: locust-test-config\ndata:\n  test_mode: \"smoke\"\n  test_env: \"int\"\n  users: \"10\"\n  spawn_rate: \"2\"\n  duration: \"300s\"\n```\n\n### Job\n\n```yaml\n# k8s/tests/locust/job.yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: locust-e2e-test\nspec:\n  ttlSecondsAfterFinished: 86400\n  template:\n    spec:\n      containers:\n        - name: locust\n          image: myregistry/e2e-tests:latest\n          command:\n            - locust\n            - --headless\n            - --only-summary\n            - -u\n            - $(USERS)\n            - -r\n            - $(SPAWN_RATE)\n            - -t\n            - $(DURATION)\n          env:\n            - name: TEST_MODE\n              valueFrom:\n                configMapKeyRef:\n                  name: locust-test-config\n                  key: test_mode\n            - name: TEST_ENV\n              valueFrom:\n                configMapKeyRef:\n                  name: locust-test-config\n                  key: test_env\n            - name: USERS\n              valueFrom:\n                configMapKeyRef:\n                  name: locust-test-config\n                  key: users\n            - name: SPAWN_RATE\n              valueFrom:\n                configMapKeyRef:\n                  name: locust-test-config\n                  key: spawn_rate\n            - name: DURATION\n              valueFrom:\n                configMapKeyRef:\n                  name: locust-test-config\n                  key: duration\n      restartPolicy: Never\n  backoffLimit: 0\n```\n\n### 환경별 실행\n\n```bash\n# INT 환경 스모크 테스트\nkubectl -n testing patch configmap locust-test-config \\\n  --type=merge -p '{\"data\":{\"test_mode\":\"smoke\",\"test_env\":\"int\",\"users\":\"1\",\"duration\":\"30s\"}}'\nkubectl -n testing apply -f k8s/tests/locust/job.yaml\n\n# STAGE 환경 성능 테스트\nkubectl -n testing patch configmap locust-test-config \\\n  --type=merge -p '{\"data\":{\"test_mode\":\"performance\",\"test_env\":\"stage\",\"users\":\"50\",\"duration\":\"600s\"}}'\nkubectl delete job locust-e2e-test -n testing --ignore-not-found\nkubectl -n testing apply -f k8s/tests/locust/job.yaml\n\n# 로그 확인\nkubectl -n testing logs -f job/locust-e2e-test\n```\n\n## 프로덕션 테스트 안전 장치\n\n```makefile\n# 프로덕션 테스트 (극도로 제한된 설정)\ntest-prod:\n @echo \"⚠️  WARNING: Production test!\"\n @read -p \"Type 'I understand the risks': \" confirm && \\\n  [ \"$$confirm\" = \"I understand the risks\" ] || (echo \"Cancelled.\" && exit 1)\n TEST_MODE=smoke TEST_ENV=prod locust \\\n  $(LOCUST_FLAGS) \\\n  -u 1 -r 1 -t 60s  # 1명, 1분만\n```\n\n## 모범 사례\n\n1. **환경 분리**: 환경별 설정 파일로 엔드포인트/설정 관리\n2. **테스트 데이터 정리**: `on_stop`에서 생성한 데이터 삭제\n3. **점진적 부하**: `LoadTestShape`로 급격한 부하 방지\n4. **프로덕션 보호**: 프로덕션 테스트는 극도로 제한\n5. **결과 저장**: `--csv` 옵션으로 결과 기록\n\n## 참고 자료\n\n- [Locust 공식 문서](https://docs.locust.io/)\n- [Locust Kubernetes 배포](https://docs.locust.io/en/stable/running-distributed.html)\n- [LoadTestShape 가이드](https://docs.locust.io/en/stable/custom-load-shape.html)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Testing",
      "E2E",
      "Locust",
      "Python",
      "Performance",
      "Load Testing",
      "Kubernetes"
    ],
    "readingTime": 7,
    "wordCount": 1308,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "linux-ulimit-guide",
    "slug": "linux-ulimit-guide",
    "path": "backend/devops",
    "fullPath": "backend/devops/linux-ulimit-guide",
    "title": "Linux 파일 디스크립터 제한 (ulimit) 완벽 가이드",
    "excerpt": "대용량 트래픽 서버에서 'Too many open files' 오류를 해결하기 위한 ulimit 설정 방법을 알아봅니다.",
    "content": "# Linux 파일 디스크립터 제한 (ulimit) 완벽 가이드\n\n## 개요\n\n고트래픽 서버를 운영하다 보면 `Too many open files` 에러를 마주치게 됩니다. 이는 Linux의 **파일 디스크립터(File Descriptor)** 제한 때문입니다. 이 글에서는 ulimit의 개념과 실전 설정 방법을 다룹니다.\n\n## 파일 디스크립터란?\n\n파일 디스크립터는 Linux에서 열린 파일, 소켓, 파이프 등을 나타내는 정수 값입니다. 모든 I/O 작업은 파일 디스크립터를 통해 이루어집니다.\n\n```bash\n# 현재 프로세스의 열린 파일 디스크립터 확인\nls -la /proc/self/fd/\n```\n\n## 제한 종류\n\n### 시스템 전체 제한\n\n```bash\n# 시스템 전체 최대 파일 디스크립터 수\ncat /proc/sys/fs/file-max\n\n# 현재 사용 중인 파일 디스크립터 수\ncat /proc/sys/fs/file-nr\n```\n\n### 프로세스별 제한\n\n```bash\n# 현재 쉘의 제한 확인\nulimit -n       # soft limit\nulimit -Hn      # hard limit\n```\n\n| 구분 | 설명 |\n|-----|------|\n| **Soft Limit** | 실제 적용되는 제한, 사용자가 변경 가능 |\n| **Hard Limit** | 최대 상한선, root만 증가 가능 |\n\n## 일시적 변경 (현재 세션만)\n\n```bash\n# Soft limit 변경 (hard limit 범위 내에서)\nulimit -n 65535\n\n# Hard limit 변경 (root 권한 필요)\nsudo ulimit -Hn 100000\n```\n\n## 영구적 변경\n\n### 1. limits.conf 설정\n\n`/etc/security/limits.conf` 파일을 수정합니다:\n\n```bash\n# /etc/security/limits.conf\n# <domain>  <type>  <item>  <value>\n\n*           soft    nofile  65535\n*           hard    nofile  100000\nroot        soft    nofile  65535\nroot        hard    nofile  100000\n```\n\n| 필드 | 설명 | 예시 |\n|-----|------|------|\n| domain | 적용 대상 | `*` (모든 사용자), `root`, `@group` |\n| type | 제한 유형 | `soft`, `hard`, `-` (둘 다) |\n| item | 제한 항목 | `nofile` (파일 수), `nproc` (프로세스 수) |\n| value | 제한 값 | 숫자 또는 `unlimited` |\n\n### 2. systemd 서비스 설정\n\nsystemd로 관리되는 서비스는 별도 설정이 필요합니다:\n\n```ini\n# /etc/systemd/system/myapp.service\n[Service]\nLimitNOFILE=65535\nLimitNPROC=65535\n```\n\n또는 전역 설정:\n\n```ini\n# /etc/systemd/system.conf\nDefaultLimitNOFILE=65535\n```\n\n설정 후 재시작:\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl restart myapp\n```\n\n### 3. sysctl로 시스템 전체 제한 변경\n\n```bash\n# /etc/sysctl.conf\nfs.file-max = 2097152\nfs.nr_open = 2097152\n\n# 적용\nsudo sysctl -p\n```\n\n## 실전 예시: Nginx 설정\n\n```nginx\n# /etc/nginx/nginx.conf\nworker_rlimit_nofile 65535;\n\nevents {\n    worker_connections 65535;\n}\n```\n\n## 문제 해결\n\n### 설정이 적용되지 않을 때\n\n```bash\n# PAM 모듈 확인\ngrep pam_limits /etc/pam.d/common-session\n# session required pam_limits.so 가 있어야 함\n```\n\n### 현재 프로세스의 제한 확인\n\n```bash\n# 특정 프로세스의 제한 확인\ncat /proc/<PID>/limits\n```\n\n## 권장 설정값\n\n| 서버 용도 | nofile 권장값 |\n|---------|--------------|\n| 일반 웹 서버 | 65,535 |\n| 고트래픽 API 서버 | 100,000+ |\n| 데이터베이스 | 65,535 ~ 100,000 |\n| 메시지 브로커 | 500,000+ |\n\n## 주의사항\n\n- **과도한 값 설정 금지**: 메모리 오버헤드 발생 가능\n- **soft ≤ hard**: soft limit은 hard limit을 초과할 수 없음\n- **재부팅 후 확인**: 영구 설정 적용 여부 검증 필수\n\n## 참고 자료\n\n- [Linux man page: limits.conf](https://man7.org/linux/man-pages/man5/limits.conf.5.html)\n- [systemd LimitNOFILE](https://www.freedesktop.org/software/systemd/man/systemd.exec.html)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Linux",
      "DevOps",
      "Performance",
      "ulimit"
    ],
    "readingTime": 3,
    "wordCount": 458,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "helm-environment-management",
    "slug": "helm-environment-management",
    "path": "backend/devops",
    "fullPath": "backend/devops/helm-environment-management",
    "title": "Helm 환경별 Values 오버라이드 전략",
    "excerpt": "Helm Chart에서 공통 설정과 환경별 설정을 분리하여 GitOps 방식으로 관리하는 방법을 알아봅니다.",
    "content": "# Helm 환경별 Values 오버라이드 전략\n\n## 개요\n\nKubernetes 환경에서 동일한 애플리케이션을 INT/STAGE/REAL 등 여러 환경에 배포할 때, **공통 설정**과 **환경별 설정**을 분리하면 유지보수성이 크게 향상됩니다.\n\n## 핵심 개념\n\n```mermaid\nflowchart LR\n    subgraph Common [\"공통 설정\"]\n        VApp[\"values.application.yaml\"]\n        VInfra[\"values.infra.yaml\"]\n    end\n    \n    subgraph EnvOverride [\"환경별 오버라이드\"]\n        Int[\"int/values.application.yaml\"]\n        Stage[\"stage/values.application.yaml\"]\n        Real[\"real/values.application.yaml\"]\n    end\n    \n    VApp --> Int\n    VApp --> Stage\n    VApp --> Real\n    \n    Int --> Merge[\"helm template 병합\"]\n    Stage --> Merge\n    Real --> Merge\n```\n\n- **공통 설정**: 모든 환경에서 동일한 기본값\n- **환경별 오버라이드**: 해당 환경에만 다른 값을 덮어씌움\n\n## 디렉토리 구조\n\n```\nk8s/manifests/my-service/helm/\n├── values.application.yaml    # 공통 애플리케이션 설정\n├── values.infra.yaml          # 공통 인프라 설정\n├── dev/\n│   ├── Chart.yaml\n│   ├── values.application.yaml  # dev 환경 오버라이드\n│   └── values.infra.yaml\n├── int/\n│   ├── Chart.yaml\n│   ├── values.application.yaml  # int 환경 오버라이드\n│   └── values.infra.yaml\n├── stage/\n│   ├── Chart.yaml\n│   ├── values.application.yaml  # stage 환경 오버라이드\n│   └── values.infra.yaml\n└── real/\n    ├── Chart.yaml\n    ├── values.application.yaml  # real(production) 환경 오버라이드\n    └── values.infra.yaml\n```\n\n## 공통 설정\n\n### values.application.yaml (공통)\n\n모든 환경에서 동일한 기본값을 정의:\n\n```yaml\n# 공통 설정 - 모든 환경에서 동일\napp:\n  regionCode: \"apn2\"\n  enableProbe: \"true\"\n  \n  args: [\"run\", \"--config\", \"/etc/my-service/config.yaml\"]\n  \n  readinessProbe:\n    grpc:\n      port: 9090\n    initialDelaySeconds: 15\n    periodSeconds: 20\n    \n  livenessProbe:\n    grpc:\n      port: 9090\n    initialDelaySeconds: 15\n    periodSeconds: 20\n  \n  replicaCount: 1  # 기본값, 환경별로 오버라이드\n  \n  service:\n    ports:\n      - name: http\n        port: 8080\n        protocol: TCP\n      - name: grpc\n        port: 9090\n        protocol: TCP\n```\n\n## 환경별 오버라이드\n\n### int/values.application.yaml\n\nINT 환경에만 다른 설정:\n\n```yaml\n# int 환경 오버라이드 - 공통 값을 덮어씀\n\napp:\n  serviceAccount:\n    annotations:\n      eks.amazonaws.com/role-arn: \"arn:aws:iam::123456789:role/int-role\"\n    create: true\n    name: \"my-service-api\"\n  \n  # INT 환경 시크릿\n  secretsStores:\n    - path: /common/int/secrets\n      type: secretsmanager\n      keys:\n        - MONGO_CONNECTION_STRING\n        - REDIS_CONNECTION_STRING\n  \n  # INT 환경 ConfigMap\n  configmaps:\n    - name: my-service-config\n      mount:\n        enabled: true\n        path: /etc/my-service\n        filename: config.yaml\n      value: |\n        database:\n          mongo_connection_string: \"get_secret_from_secret_manager\"\n          redis_connection_strings:\n            - \"get_secret_from_secret_manager\"\n        stellar:\n          url: https://api.int.example.com\n  \n  # INT 환경 환경변수\n  env:\n    - name: ENV\n      value: \"int\"\n```\n\n### real/values.application.yaml\n\nREAL(Production) 환경:\n\n```yaml\n# real(production) 환경 오버라이드\n\napp:\n  replicaCount: 3  # 프로덕션은 3개 레플리카\n  \n  resources:\n    requests:\n      cpu: 500m\n      memory: 2Gi\n    limits:\n      cpu: 1000m\n      memory: 2Gi\n  \n  serviceAccount:\n    annotations:\n      eks.amazonaws.com/role-arn: \"arn:aws:iam::987654321:role/real-role\"\n    create: true\n    name: \"my-service-api\"\n  \n  secretsStores:\n    - path: /common/real/secrets\n      type: secretsmanager\n      keys:\n        - MONGO_CONNECTION_STRING\n        - REDIS_CONNECTION_STRING\n  \n  configmaps:\n    - name: my-service-config\n      mount:\n        enabled: true\n        path: /etc/my-service\n        filename: config.yaml\n      value: |\n        database:\n          mongo_connection_string: \"get_secret_from_secret_manager\"\n        stellar:\n          url: https://api.example.com\n  \n  env:\n    - name: ENV\n      value: \"real\"\n```\n\n## 로컬 테스트\n\n배포 전 템플릿 렌더링으로 검증:\n\n```bash\n# 의존성 업데이트\nhelm dependency update int\n\n# 템플릿 렌더링 (공통 + 환경별 병합)\nhelm template my-service \\\n  -f values.infra.yaml \\\n  -f values.application.yaml \\\n  -f int/values.infra.yaml \\\n  -f int/values.application.yaml \\\n  ./int | yq\n```\n\n순서가 중요합니다:\n\n1. 공통 infra → 2. 공통 application → 3. 환경별 infra → 4. 환경별 application\n\n뒤에 오는 파일이 앞의 값을 오버라이드합니다.\n\n## ArgoCD GitOps 배포\n\nArgoCD는 각 환경별 디렉토리를 별도 Application으로 등록:\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-service-int\n  namespace: argocd\nspec:\n  source:\n    repoURL: https://github.com/myorg/k8s-manifests.git\n    path: k8s/manifests/my-service/helm/int\n    helm:\n      valueFiles:\n        - ../values.infra.yaml\n        - ../values.application.yaml\n        - values.infra.yaml\n        - values.application.yaml\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: my-namespace-int\n```\n\n## 핵심 정리\n\n| 파일 | 위치 | 역할 |\n|------|------|------|\n| `values.application.yaml` | 루트 | 공통 애플리케이션 설정 |\n| `values.infra.yaml` | 루트 | 공통 인프라 설정 |\n| `{env}/values.application.yaml` | 환경 폴더 | 환경별 오버라이드 |\n| `{env}/Chart.yaml` | 환경 폴더 | 의존성 차트 정의 |\n\n## 모범 사례\n\n1. **공통 최대화**: 최대한 공통 설정에 넣고, 환경별은 최소화\n2. **시크릿 분리**: 민감 정보는 Secrets Manager/Vault 사용\n3. **리소스 차등**: 프로덕션은 더 높은 리소스 설정\n4. **로컬 검증**: 배포 전 `helm template`로 렌더링 확인\n5. **레플리카 차등**: dev=1, int=1~2, real=3+\n\n## 참고 자료\n\n- [Helm Values Files](https://helm.sh/docs/chart_template_guide/values_files/)\n- [ArgoCD Helm](https://argo-cd.readthedocs.io/en/stable/user-guide/helm/)",
    "docType": "original",
    "category": "Backend",
    "tags": [
      "Kubernetes",
      "Helm",
      "DevOps",
      "GitOps",
      "ArgoCD"
    ],
    "readingTime": 3,
    "wordCount": 587,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-30"
  },
  {
    "id": "김서규의-노트-seogyu-s-notes",
    "slug": "gimseogyuyi-noteu-seogyu-s-notes",
    "path": "misc",
    "fullPath": "misc/gimseogyuyi-noteu-seogyu-s-notes",
    "title": "김서규의 노트 Seogyu's notes",
    "excerpt": "김서규의 노트 Seogyu's notes how-to-go-root-dir Backend [NestJS, Cache-Manager v5 사용시 문제 해결법](./Backend/nestjs-cache-m...",
    "content": "# 김서규의 노트 Seogyu's notes\n\n[how-to-go-root-dir](./how-to-go-root-dir.md)\n\n## Backend\n\n1. [NestJS, Cache-Manager v5 사용시 문제 해결법](./Backend/nestjs-cache-manager-v5-problem.md)\n2. [NestJS Dynamic Module 주의점](./Backend/nestjs-dyn-mod-warn.md)\n3. [데코레이터를 이용한 Nest.js에서의 AOP 적용](./Backend/aop-using-decorators.md)\n4. [개체 vs 객체](./Backend/object.md)\n5. [개체지향프로그래밍](./Backend/oop.md)\n6. [SOLID](./Backend/solid.md)\n7. [10만명이 이용하는 서비스를 구성하는 법](./Backend/how-to-10m-service.md)\n8. [Http 요청을 최적화하는 방법](./Backend/how-to-reduce-http-req.md)\n9. [OOP](./Backend/oop.md)\n10. [Object](./Backend/object.md)\n11. [대용량 데이터 인덱싱 작업에서 데이터베이스 부하 최적화 방법](./Backend/upsert-vs-constraint.md)\n12. [트렁크 기반 개발](Backend/trunk-based-development.md)\n13. [how-to-query-with-transaction](Database/mysql/how-to-query-with-transaction.md)\n14. [Best Isolation Level](Database/mysql/best-isolation-lv.md)\n15. [ACID](Database/mysql/acid.md)\n16. [HTTP 전송 크기를 줄이는 방법](./Backend/reduce-http-transfer-size.md)\n17. [HTTP 쿠키 보안](./Backend/http-secure-cookie-ways.md)\n\n## Linux\n\n1. [EADDRNOTAVAIL과 TIME_AWAIT 문제 해결방법 in node.js](./Linux/EADDRNOTAVAIL.md)\n\n## Blockchain\n\n1. [What is Blockchain](Blockchain/101/what-is-blockchain.md)\n2. [What is Checksum](Blockchain/101/checksum.md)\n3. [HD Wallet](./Blockchain/101/hd-wallet.md)\n4. [Istanbul Bizantine Fault](./Blockchain/101/istanbul-byzantine-fault.md)\n5. [Bitcoin Address](./Blockchain/BTC/address.md)\n6. [SPV (Simplified Payment Verification)](./Blockchain/BTC/spv.md)\n7. [Bitcoin Script](./Blockchain/BTC/script.md)\n8. [Bitcoin Segwit Transaction](./Blockchain/BTC/segwit.md)\n9. [Bitcoin nft, brc-20](./Blockchain/BTC/ord.md)\n10. [Ethereum memo](./Blockchain/ETH/memo.md)\n11. [Binance chain memo](./Blockchain/BNB/memo.md)\n12. [Ripple memo](./Blockchain/XRP/memo.md)\n13. [Solana memo](./Blockchain/SOL/memo.md)\n14. [Stellar Lumens memo](./Blockchain/XLM/memo.md)\n15. [Tezos memo](./Blockchain/XTZ/memo.md)\n16. [Filecoin memo](./Blockchain/FIL/memo.md)\n17. [Harmony memo](./Blockchain/ONE/memo.md)\n18. [Aptos 통합가이드](./Blockchain/APT/system-integrators-guide.md)\n19. [Aptos 백서](./Blockchain/APT/aptos-white-paper-in-korean.md)\n20. [Aptos의 Move](./Blockchain/APT/Move/move-on-aptos.md)\n21. [Aptos Move 구조](./Blockchain/APT/Move/aptos-structure.md)\n\n## Languages\n\n### Java\n\n1. [비트연산자](./Languages/Java/bit-operators.md)\n2. [콜렉션](./Languages/Java/collection.md)\n3. [Data types](./Languages/Java/datatypes.md)\n\n### Typescript\n\n1. [데코레이터란?](./Languages/Typescript/decorators.md)\n2. [Enum 대신 사용할 수 있는 as const](./Languages/Typescript/enum-or-as-const.md)\n3. [Mocha의 NODE_ENV](./Languages/Typescript/mocha-node-env.md)\n4. [데코레이터 in TS 5.0](./Languages/Typescript/5.0-rc.md)\n\n### Rust\n\n1. [Rust에서 OS CPU 갯수 찾기](./Languages/Rust/how-to-get-num-os-cpu.md)\n\n### Dart\n\n1. [Dart programming language](./Languages/Dart/Basics.md)\n\n## Memo\n\n1. [Useful Links](./Memo/useful-links.md)",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 2,
    "wordCount": 215,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "useful-links",
    "slug": "useful-links",
    "path": "misc",
    "fullPath": "misc/useful-links",
    "title": "Useful Links",
    "excerpt": "Useful Links FreeCodeCamp [Database Systems - Cornell University Course (SQL, NoSQL, Large-Scale Data Analysis)](https://youtu.be/4cWkVbC2bN...",
    "content": "# Useful Links\n\n## FreeCodeCamp\n\n1. [Database Systems - Cornell University Course (SQL, NoSQL, Large-Scale Data Analysis)](https://youtu.be/4cWkVbC2bNE)\n2. [Database Systems - Cornell University Course (SQL, NoSQL, Large-Scale Data Analysis) - PART 2](https://youtu.be/lxEdaElkQhQ)\n3. [Introduction to Linux – Full Course for Beginners](https://youtu.be/sWbUDq4S6Y8)\n4. [College Algebra – Full Course with Python Code](https://youtu.be/i7vOAcUo5iA)\n5. [System Design for Beginners Course](https://youtu.be/m8Icp_Cid5o)\n6. [Learn Kotlin Programming – Full Course for Beginners](https://youtu.be/EExSSotojVI)\n7. [C++ Programming Course - Beginner to Advanced](https://youtu.be/8jLOx1hD3_o)\n8. [How to Build a Hackintosh - Step-by-Step Guide (Install MacOS Big Sur on PC)](https://youtu.be/Gaosub7FRf4)\n9. [Algorithms and Data Structures Tutorial - Full Course for Beginners](https://youtu.be/8hly31xKli0)\n10. [Data Structures - Full Course Using C and C++](https://youtu.be/B31LgI4Y4DQ)\n11. [Linear Algebra - Full College Course](https://youtu.be/JnTa9XtvmfI)\n12. [Flutter Course for Beginners – 37-hour Cross Platform App Development Tutorial](https://youtu.be/VPvVD8t02U8)\n13. [Data Structures Easy to Advanced Course - Full Tutorial from a Google Engineer](https://youtu.be/RBSGKlAvoiM)",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 1,
    "wordCount": 143,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "mac-os-finder에서-사용자-루트-디렉토리로-이동하는-법",
    "slug": "mac-os-findereseo-sayongja-ruteu-diregtoriro-idonghaneun-beob",
    "path": "misc",
    "fullPath": "misc/mac-os-findereseo-sayongja-ruteu-diregtoriro-idonghaneun-beob",
    "title": "Mac OS Finder에서 사용자 루트 디렉토리로 이동하는 법",
    "excerpt": "Mac OS Finder에서 사용자 루트 디렉토리로 이동하는 법 를 눌러보면 순간이동한다!...",
    "content": "# Mac OS Finder에서 사용자 루트 디렉토리로 이동하는 법\n\n`CMD + SHIFT + H`를 눌러보면 순간이동한다!",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 1,
    "wordCount": 17,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "freecodecamp",
    "slug": "freecodecamp",
    "path": "misc",
    "fullPath": "misc/freecodecamp",
    "title": "FreeCodeCamp",
    "excerpt": "FreeCodeCamp https://www.youtube.com/watch?v=VPvVD8t02U8&ab_channel=freeCodeCamp.org 1월 14일: https://youtu.be/VPvVD8t02U8?t=2360 15일...",
    "content": "# FreeCodeCamp\n\n1. https://www.youtube.com/watch?v=VPvVD8t02U8&ab_channel=freeCodeCamp.org\n\t- 1월\n\t\t- 14일: https://youtu.be/VPvVD8t02U8?t=2360\n\t\t- 15일: https://youtu.be/VPvVD8t02U8?t=4755",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 1,
    "wordCount": 14,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "typescript-5-0-rc-발표에서-데코레이터-부분-요약",
    "slug": "typescript-5-0-rc-balpyoeseo-dekoreiteo-bubun-yoyag",
    "path": "languages/typescript",
    "fullPath": "languages/typescript/typescript-5-0-rc-balpyoeseo-dekoreiteo-bubun-yoyag",
    "title": "Typescript 5.0 RC 발표에서 데코레이터 부분 요약",
    "excerpt": "Typescript 5.0 RC 발표에서 데코레이터 부분 요약 설치 방법 Decorators 데코레이터는 ECMAScript에 곧 추가되는 기능으로, 클래스와 멤버를 재사용 가능...",
    "content": "# Typescript 5.0 RC 발표에서 데코레이터 부분 요약\n\n## 설치 방법\n\n```shell\nnpm install typescript@rc\n```\n\n## Decorators\n\n데코레이터는 ECMAScript에 곧 추가되는 기능으로, 클래스와 멤버를 재사용 가능한 방식으로 사용자화 할 수 있도록 해줍니다.\n\n다음 코드를 고려해봅시다.\n\n```typescript\nclass Person {\n    name: string;\n\n    constructor(name: string) {\n        this.name = name;\n    }\n\n    greet() {\n        console.log(`Hello, my name is ${this.name}`);\n    }\n}\n\nconst p = new Person(\"Ray\");\np.greet();\n```\n\n`greet`은 매우 간단하게 작성되었으나, 좀 더 복잡한 경우를 상상해봅시다. 비동기 논리 흐름이나 재귀호출, 또는 예기치 못한 부작용 등 여러가지가 있을 수 있습니다. 어떤 것을 상상하든 간에, 우리는 한번\n디버깅 로그를 찍어봅시다.\n\n```typescript\nclass Person {\n    name: string;\n\n    constructor(name: string) {\n        this.name = name;\n    }\n\n    greet() {\n        console.log(\"LOG: Entering method.\");\n        console.log(`Hello, my name is ${this.name}`);\n        console.log(\"LOG: Exiting method.\");\n    }\n}\n```\n\n이러한 패턴은 꽤나 일반적입니다. 사실 모든 메소드에 적용해도 좋을만 하죠!\n여기서 데코레이터가 등장합니다. 우리는 `loggedMethod`라는 함수를 다음과 같이 작성해봅니다.\n\n```typescript\nfunction loggedMethod(originalMethod: any, _context: any) {\n    function replacementMethod(this: any, ...args: any[]) {\n        console.log(\"LOG: Entering method.\");\n        const result = originalMethod.call(this, args);\n        console.log(\"LOG: Exiting method.\");\n        return result;\n    }\n\n    return replacementMethod;\n}\n```\n\n\"대체 왜 `any`로 떡칠한거야, `any`script야?\"\n\n인내심을 가져보세요. 당장은 우리가 이 함수의 동작을 보는 것에 집중하기 위해 다른 것을 단순화 했습니다.\n`loggedMethod`가 원본 메소드를 매개변수로 받고, 원본 메소드의 동작 앞 뒤로 로그를 찍은 뒤, 원본 메소드의 결과값을 반환하는 것을 눈치 채셨나요?\n\n이제 우리는 `loggedmethod`로 `greet`메소드를 `decorate`할 수 있습니다.\n\n```typescript\nclass Person {\n    name: string;\n\n    constructor(name: string) {\n        this.name = name;\n    }\n\n    @loggedMethod\n    greet() {\n        console.log(`Hello, my name is ${this.name}.`);\n    }\n}\n\nconst p = new Person(\"Ray\");\np.greet();\n\n// Output:\n//\n//   LOG: Entering method.\n//   Hello, my name is Ray.\n//   LOG: Exiting method.\n```\n\n우리는 `loggedMethod`를 단순히 `greet`위에 `@`를 붙여서 올려놓았습니다. 이렇게 하니 매개변수로는 *target*과 *context* 개체가 넘어옵니다.\n`loggedMethod`가 새로운 함수를 반환하기에 원래 정의된 `greet`는 반환되는 새로운 함수로 대체됩니다.\n\n언급하지는 않았지만 `loggedMethod`에는 \"context object\"라는 두번째 매개변수가 있습니다. 이것은 decorated된 메소드가 어떻게 선언되었는지에 대한 유용한 정보를 가지고 있습니다. 정보에는\n그것이 `#private`이나 `static` 멤버인지, 또는 메소드의 이름은 무엇인지 등이 있죠. 이를 활용해 `decorated`된 메소드 이름을 출력해 보겠습니다.\n\n```typescript\nfunction loggedMethod(originalMethod: any, context: ClassMethodDecoratorContext) {\n    const methodName = String(context.name);\n\n    function replacementMethod(this: any, ...args: any[]) {\n        console.log(`LOG: Entering method '${methodName}'.`)\n        const result = originalMethod.call(this, ...args);\n        console.log(`LOG: Exiting method '${methodName}'.`)\n        return result;\n    }\n\n    return replacementMethod;\n}\n```\n\n드디어 `loggedMethod`에서 `any`를 하나 지웠습니다. 타입스크립트는 `ClassMethodDecoratorContext`라는 타입을 제공하는데, 이것은 데코레이터가 붙은 메소드의 context\nobject를 유형화합니다.\n\n메타데이터와 별개로, 메소드를 위한 context object는 `addInitializer`라는 유용한 함수를 제공합니다. 이는 생성자가 호출되거나 스태틱 메소드 호출시 클래스가 초기화 될 때 연결하는\n방법입니다.)\n\n예를 들어, 자바스크립트에서는 다음과 같은 방식이 일반적입니다.\n\n```typescript\nclass Person {\n    name: string;\n\n    constructor(name: string) {\n        this.name = name;\n        this.greet = this.greet.bind(this);\n    }\n\n    greet() {\n        console.log(`Hello, my name is ${this.name}`);\n    }\n}\n```\n\n또는 `greet`를 화살표 함수로 선언이고 속성으로 선언했을 수도 있습니다.\n\n```typescript\nclass Person {\n    name: string;\n\n    constructor(name: string) {\n        this.name = name;\n    }\n\n    greet = () => {\n        console.log(`Hello, my name is ${this.name}.`);\n    }\n}\n```\n\n이 코드는 `greet`이 독립 실행형 함수로 호출되거나 콜백으로 전달되는 경우 *this*가 다시 바인딩 되지 않도록 작성되었습니다.\n\n```typescript\nconst greet = new Person(\"Ray\").greet;\n// We don't want this to fail!\ngreet();\n```\n\n우리는 `addInitializer`로 생성자에 `bind`하도록 하는 데코레이터를 작성할 수 있습니다.\n\n```typescript\nfunction bound(originalMethod: any, context: ClassMethodDecoratorContext) {\n    const methodName = context.name;\n    if (context.private) {\n        throw new Error(`'bound' cannot decorate private properties like ${methodName as string}.`);\n    }\n    context.addInitializer(function () {\n        this[methodName] = this[methodName].bind(this);\n    });\n}\n```\n\n`bound`는 아무것도 반환하지 않고 오버라이딩 하지도 않으므로 이 로직은 초기화시에만 실행될 겁니다.\n\n```typescript\nclass Person {\n    name: string;\n\n    constructor(name: string) {\n        this.name = name;\n    }\n\n    @bound\n    @loggedMethod\n    greet() {\n        console.log(`Hello, my name is ${this.name}.`);\n    }\n}\n\nconst p = new Person(\"Ray\");\nconst greet = p.greet;\n\n// Works!\ngreet();\n```\n\n데코레이터가 두개 이상일 땐 역순으로 실행됩니다. 그러모르 위 경우에선 `loggedMethod`가 `greet`을 감싸고 새 함수를 반환하며, 그 새 함수를 bound가 감싸게 되겠네요. 지금 경우에선 문제가\n안되지만 특정 순서가 중요한 구조에서는 문제가 되므로 주의해야 합니다.\n\n여기에 약간의 기술을 더하면 데코레이터를 반환하는 함수를 만들 수도 있습니다.\n\n```typescript\nfunction loggedMethod(headMessage = \"LOG:\") {\n    return function actualDecorator(originalMethod: any, context: ClassMethodDecoratorContext) {\n        const methodName = String(context.name);\n\n        function replacementMethod(this: any, ...args: any[]) {\n            console.log(`${headMessage} Entering method '${methodName}'.`)\n            const result = originalMethod.call(this, ...args);\n            console.log(`${headMessage} Exiting method '${methodName}'.`)\n            return result;\n        }\n\n        return replacementMethod;\n    }\n}\n```\n\n이때 우리는 반드시 `loggedMethod`를 메소드 전에 호출해야 하고, 필요시 파라미터도 넘겨줘야 합니다.\n\n```typescript\nclass Person {\n    name: string;\n\n    constructor(name: string) {\n        this.name = name;\n    }\n\n    @loggedMethod(\"\")\n    greet() {\n        console.log(`Hello, my name is ${this.name}.`);\n    }\n}\n\nconst p = new Person(\"Ray\");\np.greet();\n\n// Output:\n//\n//    Entering method 'greet'.\n//   Hello, my name is Ray.\n//    Exiting method 'greet'.\n```\n\n데코레이터는 메소드 뿐만 아니라 프로퍼티, 필드, 게터, 세터, 자동접근자(`auto-accessor`)까지도 사용할 수 있습니다. 심지어는 클래스 스스로도 서브클래싱이나 등록으로 데코레이팅 될 수 있습니다.\n데코레이터를 더 깊게 공부하고 싶다면 [Axel Rauschmayer’s extensive summary.](https://2ality.com/2022/10/javascript-decorators.html)을 읽어\n보세요.\n포함된 변경사항에 대해 더 많은 정보를 알고 싶다면 [원본 풀리퀘스트](https://github.com/microsoft/TypeScript/pull/50820)를 확인해 보세요.",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 4,
    "wordCount": 788,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "mocha의-node-env는",
    "slug": "mochayi-node-envneun",
    "path": "languages/typescript",
    "fullPath": "languages/typescript/mochayi-node-envneun",
    "title": "Mocha의 NODE_ENV는?",
    "excerpt": "Mocha의 NODE_ENV는? 참조 https://github.com/mochajs/mocha/issues/185 23년 1월 24일 기준 확인해본 결과 `\"mocha\": \"^10.2.0\" 에서 undefined이다....",
    "content": "# Mocha의 NODE_ENV는?\n\n> 참조 https://github.com/mochajs/mocha/issues/185\n\n23년 1월 24일 기준 확인해본 결과 \n`\"mocha\": \"^10.2.0\" 에서 undefined이다.",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 1,
    "wordCount": 18,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "enum-대신-사용할-수-있는-as-const",
    "slug": "enum-daesin-sayonghal-su-issneun-as-const",
    "path": "languages/typescript",
    "fullPath": "languages/typescript/enum-daesin-sayonghal-su-issneun-as-const",
    "title": "Enum 대신 사용할 수 있는 `as const`",
    "excerpt": "Enum 대신 사용할 수 있는 자세한 내용은 우아한형제들 기술 블로그 참고 부탁드립니다. 링크 ```typescript / const NodeEnv...",
    "content": "# Enum 대신 사용할 수 있는 `as const`\n\n> 자세한 내용은 우아한형제들 기술 블로그 참고 부탁드립니다. [링크](https://techblog.woowahan.com/9804/#toc-1)\n\n```typescript\n/**\n * const NodeEnvMap: {  \n *   readonly Local: \"local\";  \n *   readonly Dev: \"dev\";  \n *   readonly Prod: \"prod\";  \n *   readonly Test: \"test\";  \n * }\n */\nexport const NodeEnvMap = {\n\tLocal: 'local',\n\tDev: 'dev',\n\tProd: 'prod',\n\tTest: 'test',\n} as const;\n  \n// type NodeEnvMapType = \"local\" | \"dev\" | \"prod\" | \"test\"\nexport type NodeEnvMapType = typeof NodeEnvMap[keyof typeof NodeEnvMap];\n```\n\n`as const`를 안해주면 아래와 같이 `string`!\n\n```typescript\n/**\n* const NodeEnvMap: {\n*   Local: string;\n*   Dev: string;\n*   Prod: string;\n*   Test: string;\n* }\n*/\nexport const NodeEnvMap = {\n\tLocal: 'local',\n\tDev: 'dev',\n\tProd: 'prod',\n\tTest: 'test',\n} \n```",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 1,
    "wordCount": 122,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "rust에서-os-cpu-갯수-찾기",
    "slug": "rusteseo-os-cpu-gaessu-cajgi",
    "path": "languages/rust",
    "fullPath": "languages/rust/rusteseo-os-cpu-gaessu-cajgi",
    "title": "Rust에서 OS CPU 갯수 찾기",
    "excerpt": "참고 Rust에서 OS CPU 갯수 찾기 태초의 방식 (deprecated) ```rs extern crate num_cpus; let num = num_cpus::get(...",
    "content": "> 참고\n\n# Rust에서 OS CPU 갯수 찾기\n\n## 태초의 방식 (deprecated)\n\n```ini\n[dependencies]\nnum_cpus = \"1.0\"\n```\n\n```rs\nextern crate num_cpus;\nlet num = num_cpus::get();\n```\n\n## 그 다음 방식 (deprecated)\n\n```rs\nfn main() {\n    println!(\"{}\", std::os::num_cpus());\n}\n```\n\n## 현재 방식\n\n```rs\n// rustc 1.67.0 (fc594f156 2023-01-24)\nstd::thread::available_parallelism().unwrap().get()\n```",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 1,
    "wordCount": 52,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "비트-연산-활용",
    "slug": "biteu-yeonsan-hwalyong",
    "path": "languages/others",
    "fullPath": "languages/others/biteu-yeonsan-hwalyong",
    "title": "비트 연산 활용",
    "excerpt": "비트 연산 활용 종류 비트 연산자 설명 &amp;</...",
    "content": "# 비트 연산 활용\n\n## 종류\n\n<table class=\"tb-2\" >\n\t<thead>\n\t\t<tr class=\"bg\">\n\t\t\t<th>비트 연산자</th>\n\t\t\t<th>설명</th>\n\t\t</tr>\n\t</thead>\n\t<tbody>\n\t\t<tr>\n\t\t\t<td>&amp;</td>\n\t\t\t<td>대응되는 비트가 모두 1이면 1을 반환함. (비트 AND 연산)</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>|</td>\n\t\t\t<td>대응되는 비트 중에서 하나라도 1이면 1을 반환함. (비트 OR 연산)</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>^</td>\n\t\t\t<td>대응되는 비트가 서로 다르면 1을 반환함. (비트 XOR 연산)</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>~</td>\n\t\t\t<td>비트를 1이면 0으로, 0이면 1로 반전시킴. (비트 NOT 연산, 1의 보수)</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>&lt;&lt;</td>\n\t\t\t<td>명시된 수만큼 비트들을 전부 왼쪽으로 이동시킴. (left shift 연산)</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>&gt;&gt;</td>\n\t\t\t<td>부호를 유지하면서 지정한 수만큼 비트를 전부 오른쪽으로 이동시킴. (right shift 연산)</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>&gt;&gt;&gt;</td>\n\t\t\t<td>지정한 수만큼 비트를 전부 오른쪽으로 이동시키며, 새로운 비트는 전부 0이 됨.</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n## 종류 별 예시\n\n![](http://www.tcpschool.com/lectures/img_php_bitwise_and.png)\n![](http://www.tcpschool.com/lectures/img_php_bitwise_or.png)\n![](http://www.tcpschool.com/lectures/img_php_bitwise_xor.png)\n![](http://www.tcpschool.com/lectures/img_php_bitwise_not.png)\n\n## 비트마스크\n\n<table>\n<thead>\n<tr>\n<td>\n    연산\n</td>\n<td>\n    사용 예시\n</td>\n</tr>\n</thead>\n<tbody>\n<tr>\n</tr>\n<tr>\n<td>\n    i번째 요소 조회하기\n</td>\n<td >\n\n```\n// 10 & (1 << 2)\n// 1010 & 0100\n// => 0000\n// 결과값의 idx=3 요소는 i번째 요소의 존재여부를 나타낸다 \nn & (1 << i);\n```\n\n</td>\n</tr>\n<tr>\n<td>\n    변경(삽입)\n</td>\n<td>\n\n```\n// 10 | (1 << 2)\n// 1010 | 0100\n// => 1110\n// 결과값의 idx=2 요소를 1로 만들었다\nn | (1 << i)\n```\n\n</td>\n</tr>\n<tr>\n<td>\n    삭제\n</td>\n<td>\n\n```\n// 15 & ~(1 << 2) \n// 1111 & ~0100\n// 1111 & 1011\n// => 1011\n// 결과값의 idx=2 요소를 0으로 만들었다\nn & ~(1 << i)\n```\n\n</td>\n</tr>\n<tr>\n<td>\n공집합\n</td>\n<td>\n\n```\nint result = 0;\n```\n\n</td>\n</tr>\n<tr>\n<td>\n꽉 찬 집합\n</td>\n<td>\n\n```\n// A개의 원소를 가진 집합의 종류\n// 점화식으로는 (2**n) - 1\nint result = ((1 << A) - 1);\n```\n\n</td>\n</tr>\n<tr>\n<td>\n최소 원소 찾기\n</td>\n<td>\n\n```\nint firstBit = b & -b;\n```\n</td>\n</tr>\n<tr>\n<td>\n최소 원소 지우기\n</td>\n<td>\n\n```\nint removed = origin & (origin-1);\n```\n</td>\n</tr>\n<tr>\n<td>\n부분 집합 순회\n</td>\n<td>\n\n```\n집합 A의 부분집합 순회\nfor (int i = A;; i = ((i - 1) & A)) {\n    ...\n}\n```\n</td>\n</tr>\n</tbody>\n</table>\n\n## 참고 문서\n\n- [비트마스크](https://hongjuzzang.github.io/bitmask/bit_mask/#-%EB%B9%84%ED%8A%B8%EB%A7%88%EC%8A%A4%ED%81%AC)",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 2,
    "wordCount": 359,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "c-overview",
    "slug": "c-overview",
    "path": "languages/others",
    "fullPath": "languages/others/c-overview",
    "title": "C# Overview",
    "excerpt": "C Overview Summary of the data types in C with example code snippets Value types bool: represents a Boolean value (true or false) ```cs b...",
    "content": "# C# Overview\n\nSummary of the data types in C# with example code snippets\n\n## Value types\n\n- bool: represents a Boolean value (true or false)\n\n```cs\nbool isCorrect = true;\n```\n\n- char: represents a single Unicode character\n\n```cs\nchar letter = 'a';\n```\n\n- byte: represents an 8-bit unsigned integer\n\n```cs\nbyte b = 255;\n```\n\n- short: represents a 16-bit signed integer\n\n```cs\nshort s = -32768;\n```\n\n- int: represents a 32-bit signed integer\n\n```cs\nint i = 42;\n```\n\n- long: represents a 64-bit signed integer\n\n```cs\nlong l = 1000000000L;\n```\n\n- float: represents a single-precision floating-point number\n\n```cs\nfloat f = 3.1415927f;\n```\n\n- double: represents a double-precision floating-point number\n\n```cs\ndouble d = 3.141592653589793;\n```\n\n- decimal: represents a decimal number with up to 28 significant digits\n\n```cs\ndecimal price = 9.99M;\n```\n\n## Reference types\n\n- string: represents a sequence of Unicode characters\n\n```cs\nstring greeting = \"Hello, world!\";\n```\n\n- object: represents an instance of any type\n\n```cs\nobject obj = new object();\n```\n\ndynamic: represents a type that is determined at runtime\n\n```cs\ndynamic dynamicVar = \"hello\";\nConsole.WriteLine(dynamicVar.GetType()); // System.String\ndynamicVar = 42;\nConsole.WriteLine(dynamicVar.GetType()); // System.Int32\n```\n\n- array: represents a collection of elements of the same type\n\n```cs\nint[] numbers = { 1, 2, 3, 4, 5 };\n```\n\nclass: represents a blueprint for creating objects\n\n```cs\npublic class Person\n{\npublic string Name { get; set; }\npublic int Age { get; set; }\n}\n\nPerson person = new Person { Name = \"Alice\", Age = 30 };\n```\n\n- interface: represents a contract for implementing functionality\n\n```csharp\npublic interface IShape\n{\ndouble GetArea();\n}\n\npublic class Rectangle : IShape\n{\npublic double Width { get; set; }\npublic double Height { get; set; }\n\n    public double GetArea()\n    {\n        return Width * Height;\n    }\n\n}\n\nIShape shape = new Rectangle { Width = 10, Height = 20 };\ndouble area = shape.GetArea();\n```",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 2,
    "wordCount": 327,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "dart-programming-language",
    "slug": "dart-programming-language",
    "path": "languages/dart",
    "fullPath": "languages/dart/dart-programming-language",
    "title": "Dart Programming Language",
    "excerpt": "Dart Programming Language Hello world Variables The Var keywor...",
    "content": "# Dart Programming Language\n\n## Hello world\n\n```dart\nvoid main() {\n  print('hello world');\n}\n\ndart run main.dart\n```\n\n## Variables\n\n### The Var keyword\n\n```dart\nvoid main() {\n  // Compiler automatically infers type of value\n  var name = 'seogyugim';\n\n  // Declare obviously type of value\n  String strname = 'seogyugim';\n}\n```\n\n### Dynamic Type\n\n```dart\nvoid main() {\n  dynamic name;\n  if (name is String) {\n    // Compiler already knows type of name\n    name.isEmpty;\n  }\n\n  // And dart support optional chaining\n  name?.isEmpty;\n}\n```\n\n### Null Safety\n\n```dart\nbool isEmpty(String s) => s.length == 0;\n\nvoid main() {\n  // It'll throw NoSuchMethodError\n  isEmpty(null);\n\n  // It's not okay\n  String name1 = 'seogyugim';\n  // Because name2 must be not null\n  if (name1 != null) {\n    nico.isNotEmpty;\n  }\n\n  // It's not okay\n  String? name2 = 'seogyugim';\n  name = null;\n  // Because name could be a null\n  name.isNotEmpty\n  if (name2 != null) {\n    nico.isNotEmpty;\n  }\n\n  // It's okay\n  String? name = 'seogyugim';\n  name = null;\n  name?.isNotEmpty;\n}\n```\n\n### Final\n\n```dart\nvoid main() {\n  // As same as val of kotlin, const of javascript\n  final name = 'seogyugim';\n}\n```\n\n### Late Variables\n\n```dart\nvoid main() {\n  // We can create variable without data with late keyword\n  late final String name;\n  late var name2;\n\n  // It will throw Error because it is not definitely assigned\n  print(name);\n}\n```\n\n### Constant Variables\n\n```dart\nvoid main() {\n  // compile-time constant\n  const name = 'seogyugim';\n  // Error\n  name = ''\n\n  // OK\n  const API_KEY = '123123';\n  // Error, because compiler don't know when compile-time.\n  const apiRes = fetchApi();\n  // OK\n  final apiRes = fetchApi();\n}\n```\n\n## Data Types\n\n### Basics\n\n```dart\nvoid main() {\n  String name = 'seogyugim';\n  bool isExist = true;\n  int age = 30;\n  double money = 0.01;\n\n\t// father class of int and double\n\t// abstract class int extends num { ...\n  num x = 12;\n}\n```\n\n### Lists\n\n```dart\nvoid main() {\n\t// Type:  List<int>\n\tvar numbers = [1, 2, 3, 4];\n\n\t// abstract class List<E> implements ...\n\tList<int> nums = [1, 2, 3, 4];\n\tnumbs.first;\n\tnumbs.last;\n\tnumbs.add(3);\n\tnumbs.contains(9);\n\n\tvar giveMeFive = true;\n\tvar nums = [\n\t\t1,\n\t\t2,\n\t\t3,\n\t\t// Collection If\n\t\tif (giveMeFive) 5,\n\t];\n}\n```\n\n### String Interpolation\n\n```dart\nvoid main() {\n\tvar age = 10;\n\tvar hello = \"Hello everyone! my name is $name, and I\\'m ${age + 1} Nice to meet you!\";\n\tprint(hello);\n}\n```\n\n### Collection For\n\n```dart\nvoid main() {\n\tvar oldFriends = [\"nico\", \"lynn\"];\n\tvar newFriends = [\n\t\t\"seogyugim\",\n\t\t\"kyoungseo\",\n\t\tfor (var f in oldFriends) \"Hi $f\",\n\t];\n}\n```\n\n### Maps\n\n```dart\nvoid main() {\n\t// Object in Dart is as same as 'any' type in Typescript\n\tvar p = {\n\t\t\"name\": 'seogyugim',\n\t\t\"xp\": 100,\n\t\t\"po\": 100,\n\t};\n\tMap<int, bool> existanceTable = {\n\t\t1: true,\n\t\t2: false,\n\t\t3: true,\n\t};\n}\n```\n\n### Sets\n\n```dart\nvoid main() {\n\tvar numbers = {1, 2, 3, 4};\n\tSet<int> nums = {1, 2, 3, 4};\n}\n```\n\n## Functions\n\n### How to define\n\n```dart\nvoid sayHello(String name) {\n\tprint(\"Hello $name, nice to meet you!\");\n}\n\nvoid retHello(String name) => \"Hello $name, nice to meet you!\";\n\nvoid main() {\n\tsayHello('seogyugim');\n\tprint(rethello('seogyugim'));\n}\n```\n\n### Named Parameters\n\n```dart\nString hello(\n\tString name,\n\tint age,\n\tString country,\n) {\n\treturn \"$name, $age, $country\";\n}\n\nString namedDefaultHello({\n\tString name = 'anonymous',\n\tint age = 50,\n\tString country = 'Korea',\n}) {\n\treturn \"$name, $age, $country\";\n}\n\nString namedRequiredHello({\n\trequired String name,\n\trequired int age,\n\trequired String country,\n}) {\n\treturn \"$name, $age, $country\";\n}\n\nvoid main() {\n\tprint(hello(\n\t\t'seogyugim',\n\t\t30,\n\t\t'Korea',\n\t));\n\n\tprint(namedDefaultHello());\n\n\tprint(namedRequiredHello(\n\t\tname: 'seogyugim',\n\t\tage: 30,\n\t\tcountry: 'Korea',\n\t));\n}\n```\n\n### Optional Positional Parameters\n\n```dart\nString sayHello(String name, int age, [String? country = \"Hello\"]) {\n\treturn \"$name, $age, $country\";\n}\n\nvoid main(List<String> args) {\n\tprint(sayHello(\"Hello\",31,));\n}\n```\n\n### Question Question Operator\n\n```dart\nString getName([String? name]) => name?.toUpperCase() ?? \"Kim Seogyu\";\n\nvoid main(List<String> args) {\n\tString name = getName();\n\tString? name2;\n\tname2 ??= \"Example\";\n\tprint(name);\n\tprint(name2);\n}\n```\n\n### Typedef\n\n```dart\ntypedef ListOfInts = List<int>;\n\nListOfInts reverseListOfNumbers(ListOfInts list) {\n\tvar reversed = list.reversed;\n\treturn reversed.toList();\n}\n\nvoid main() {\n\treverseListOfNumbers([1,2,3]);\n}\n```\n\n## Classes\n\n### Constructors\n\n### Named Constructor Parameters\n\n### Named Constructors\n\n### Cascade Notations\n\n### Enums\n\n### Abstract Classes\n\n### Inheritance\n\n### Mixins",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 4,
    "wordCount": 709,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "minio의-힐링-healing-메커니즘",
    "slug": "minioyi-hilring-healing-mekeonijeum",
    "path": "distributed-systems/minio",
    "fullPath": "distributed-systems/minio/minioyi-hilring-healing-mekeonijeum",
    "title": "MinIO의 힐링(Healing) 메커니즘",
    "excerpt": "MinIO의 힐링(Healing) 메커니즘 MinIO의 힐링 메커니즘은 분산 스토리지 환경에서 데이터 내구성을 보장하기 위한 핵심 기능입니다. 이 메커니즘은 디스크 장애, 손상된 메타데이터, 불완전한 쓰기 등을 감지하고 자동으로 복구합니다. 힐링 프...",
    "content": "# MinIO의 힐링(Healing) 메커니즘\n\nMinIO의 힐링 메커니즘은 분산 스토리지 환경에서 데이터 내구성을 보장하기 위한 핵심 기능입니다. 이 메커니즘은 디스크 장애, 손상된 메타데이터, 불완전한 쓰기 등을 감지하고 자동으로 복구합니다.\n\n## 1. 힐링 프로세스 개요\n\n힐링은 다음과 같은 단계로 진행됩니다:\n\n```go\nfunc (er *erasureObjects) healObject(ctx context.Context, bucket, object, versionID string, opts madmin.HealOpts) (result madmin.HealResultItem, err error) {\n    // 1. 객체 메타데이터 수집\n    // 2. 객체 손상 여부 확인\n    // 3. 필요시 데이터 복구\n    // 4. 복구된 데이터 재배포\n}\n```\n\n## 2. 손상 감지 메커니즘\n\n### 디스크 상태 모니터링\n\nMinIO는 지속적으로 디스크 상태를 확인합니다:\n\n```go\nfunc diskErrToDriveState(err error) (state string) {\n    if err == nil {\n        return madmin.DriveStateOk\n    }\n    switch {\n    case errors.Is(err, errDiskNotFound):\n        return madmin.DriveStateOffline\n    case errors.Is(err, errCorruptedFormat):\n        return madmin.DriveStateCorrupt\n    // ... 기타 상태 확인\n    }\n    return madmin.DriveStateUnknown\n}\n```\n\n### 객체 무결성 확인\n\n`checkObjectWithAllParts` 함수는 객체의 모든 부분이 올바르게 존재하는지 확인합니다:\n\n```go\nfunc checkObjectWithAllParts(ctx context.Context, onlineDisks []StorageAPI, partsMetadata []FileInfo,\n    errs []error, latestMeta FileInfo, filterByETag bool, bucket, object string,\n    scanMode madmin.HealScanMode) (dataErrsByDisk map[int][]int, dataErrsByPart map[int][]int) {\n    // 각 디스크에서 객체 부분 확인\n    // 누락되거나 손상된 부분 식별\n    // 디스크별, 부분별 오류 매핑\n}\n```\n\n## 3. 힐링 결정 로직\n\nMinIO는 다음 조건에 따라 힐링이 필요한지 결정합니다:\n\n```go\nfunc shouldHealObjectOnDisk(erErr error, partsErrs []int, meta FileInfo, latestMeta FileInfo) (bool, bool, error) {\n    switch {\n    case erErr != nil:\n        // 디스크 오류 발생 시 힐링 필요\n        return true, false, nil\n    case !meta.IsValid():\n        // 메타데이터가 유효하지 않은 경우 힐링 필요\n        return true, false, nil\n    case meta.XLV1:\n        // 구 버전 형식의 경우 업그레이드 필요\n        return true, false, nil\n    case meta.ModTime.Before(latestMeta.ModTime):\n        // 메타데이터가 최신이 아닌 경우 힐링 필요\n        return true, false, nil\n    // ... 기타 조건\n    }\n    \n    // 데이터 부분 손상 확인\n    for _, err := range partsErrs {\n        if err != 0 {\n            return true, false, nil\n        }\n    }\n    \n    return false, false, nil\n}\n```\n\n## 4. 데이터 복구 과정\n\n### 쿼럼 기반 데이터 복구\n\nMinIO는 충분한 수의 정상 디스크가 있을 때 손상된 데이터를 복구합니다:\n\n```go\nfunc (e Erasure) Heal(ctx context.Context, writers []io.Writer, readers []io.ReaderAt, totalLength int64, prefer []bool) (derr error) {\n    // 병렬로 데이터 블록 읽기\n    // 리드-솔로몬 알고리즘으로 누락/손상된 블록 복구\n    // 복구된 데이터를 해당 디스크에 쓰기\n}\n```\n\n### 메타데이터 복구\n\n객체 메타데이터 복구는 별도로 처리됩니다:\n\n```go\nfunc writeAllMetadata(ctx context.Context, disks []StorageAPI, origbucket, bucket, prefix string, files []FileInfo, quorum int) ([]StorageAPI, error) {\n    // 모든 디스크에 메타데이터 쓰기 시도\n    // 쿼럼 충족 확인\n}\n```\n\n## 5. 자동 힐링 스캐너\n\nMinIO는 백그라운드에서 스캐너를 실행하여 손상된 객체를 식별합니다:\n\n```go\nfunc (er erasureObjects) nsScanner(ctx context.Context, buckets []BucketInfo, wantCycle uint32, updates chan<- dataUsageCache, healScanMode madmin.HealScanMode) error {\n    // 네임스페이스 스캔\n    // 객체 상태 확인\n    // 필요시 힐링 큐에 추가\n}\n```\n\n## 6. 댕글링(Dangling) 객체 처리\n\n댕글링 객체는 메타데이터는 있지만 실제 데이터가 없거나 불완전한 객체입니다:\n\n```go\nfunc isObjectDangling(metaArr []FileInfo, errs []error, dataErrsByPart map[int][]int) (validMeta FileInfo, ok bool) {\n    // 메타데이터와 실제 데이터 상태 비교\n    // 불일치 발견 시 댕글링 객체로 판단\n}\n```\n\nMinIO는 댕글링 객체를 감지하면 자동으로 삭제하거나 복구합니다:\n\n```go\nfunc (er erasureObjects) deleteIfDangling(ctx context.Context, bucket, object string, metaArr []FileInfo, errs []error, dataErrsByPart map[int][]int, opts ObjectOptions) (FileInfo, error) {\n    // 댕글링 객체 감지\n    // 복구 가능성 평가\n    // 복구 불가능하면 안전하게 제거\n}\n```\n\n## 7. 성능 최적화\n\n### 병렬 힐링\n\n여러 객체와 디스크를 동시에 힐링하여 성능을 최적화합니다:\n\n```go\nfunc (z *erasureServerPools) HealObjects(ctx context.Context, bucket, prefix string, opts madmin.HealOpts, healObjectFn HealObjectFn) error {\n    // 병렬로 객체 스캔\n    // 동시에 여러 객체 힐링\n}\n```\n\n### 힐링 추적 및 메트릭\n\n```go\nfunc healTrace(funcName healingMetric, startTime time.Time, bucket, object string, opts *madmin.HealOpts, err error, result *madmin.HealResultItem) {\n    // 힐링 작업 추적\n    // 성능 및 결과 메트릭 수집\n}\n```\n\n## 결론\n\nMinIO의 힐링 메커니즘은 분산 환경에서 데이터 일관성과 내구성을 보장하는 핵심 기능입니다. 디스크 오류, 데이터 손상, 메타데이터 불일치 등 다양한 장애 상황을 감지하고, 리드-솔로몬 이레이저 코딩을 통해 자동으로 복구함으로써 데이터 손실 없이 시스템이 지속적으로 작동하도록 합니다.",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 4,
    "wordCount": 631,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "minio의-이레이저-코딩-구현",
    "slug": "minioyi-ireijeo-koding-guhyeon",
    "path": "distributed-systems/minio",
    "fullPath": "distributed-systems/minio/minioyi-ireijeo-koding-guhyeon",
    "title": "MinIO의 이레이저 코딩 구현",
    "excerpt": "MinIO의 이레이저 코딩 구현 MinIO는 분산 객체 스토리지 시스템으로, 데이터 내구성과 가용성을 위해 이레이저 코딩(Erasure Coding)을 구현했습니다. 이레이저 코딩은 데이터를 여러 조각으로 나누고 패리티 조각을 추가하여 일부 디스크 손실에도 데이...",
    "content": "# MinIO의 이레이저 코딩 구현\n\nMinIO는 분산 객체 스토리지 시스템으로, 데이터 내구성과 가용성을 위해 이레이저 코딩(Erasure Coding)을 구현했습니다. 이레이저 코딩은 데이터를 여러 조각으로 나누고 패리티 조각을 추가하여 일부 디스크 손실에도 데이터를 복구할 수 있게 합니다.\n\n## 핵심 구조\n\n### 1. 구조체 계층\n\n- **Erasure**: 실제 인코딩/디코딩을 수행하는 기본 구조체 (`erasure-coding.go`)\n  ```go\n  type Erasure struct {\n    encoder                  func() reedsolomon.Encoder\n    dataBlocks, parityBlocks int\n    blockSize                int64\n  }\n  ```\n\n- **erasureObjects**: 객체 스토리지 작업을 처리하는 구조체 (`erasure.go`)\n  ```go\n  type erasureObjects struct {\n    setDriveCount      int\n    defaultParityCount int\n    setIndex           int\n    poolIndex          int\n    getDisks           func() []StorageAPI\n    // ...기타 필드\n  }\n  ```\n\n- **erasureSets**: 여러 erasureObjects 세트를 관리 (`erasure-sets.go`)\n\n- **erasureServerPools**: 여러 erasureSets 풀을 관리하는 최상위 계층 (`erasure-server-pool.go`)\n\n### 2. 코딩 메커니즘\n\nMinIO는 Reed-Solomon 알고리즘을 사용하여 이레이저 코딩을 구현합니다:\n\n```go\nfunc NewErasure(ctx context.Context, dataBlocks, parityBlocks int, blockSize int64) (e Erasure, err error) {\n  e = Erasure{\n    dataBlocks:   dataBlocks,\n    parityBlocks: parityBlocks,\n    blockSize:    blockSize,\n  }\n  e.encoder = func() reedsolomon.Encoder {\n    // Reed-Solomon 인코더 초기화\n    return encoder\n  }\n  return e, nil\n}\n```\n\n## 데이터 흐름\n\n### 1. 데이터 인코딩 (쓰기)\n\n`erasure-encode.go`의 `Encode` 메서드는 데이터를 다음과 같이 처리합니다:\n\n1. 객체 데이터를 청크로 분할\n2. 각 청크를 Reed-Solomon 알고리즘으로 인코딩하여 데이터 블록과 패리티 블록 생성\n3. 데이터와 패리티 블록을 여러 디스크에 분산 저장\n\n```go\nfunc (e *Erasure) Encode(ctx context.Context, src io.Reader, writers []io.Writer, buf []byte, quorum int) (total int64, err error) {\n  // 데이터 읽기 및 인코딩\n  blocks, err := e.EncodeData(ctx, buf[:n])\n  // 인코딩된 블록을 여러 디스크에 쓰기\n  err = writer.Write(ctx, blocks)\n}\n```\n\n### 2. 데이터 디코딩 (읽기)\n\n`erasure-decode.go`의 `Decode` 메서드는 다음과 같이 데이터를 복원합니다:\n\n1. 여러 디스크에서 데이터와 패리티 블록 읽기\n2. 일부 블록이 손상되거나 누락되었을 경우 Reed-Solomon 알고리즘으로 복구\n3. 원본 데이터 재구성\n\n```go\nfunc (e Erasure) Decode(ctx context.Context, writer io.Writer, readers []io.ReaderAt, offset, length, totalLength int64, prefer []bool) (written int64, err error) {\n  // 병렬 읽기로 데이터 블록 수집\n  // 필요시 데이터 복구\n  // 원본 데이터 재구성하여 writer에 쓰기\n}\n```\n\n## 내구성 메커니즘\n\n### 1. 쿼럼 기반 작업\n\nMinIO는 쿼럼 기반 접근 방식을 사용하여 읽기/쓰기 작업의 내구성을 보장합니다:\n\n- **읽기 쿼럼(Read Quorum)**: 데이터 블록 수보다 크거나 같은 디스크에서 읽기 성공 필요\n  ```go\n  func (er erasureObjects) defaultRQuorum() int {\n    return er.setDriveCount - er.defaultParityCount\n  }\n  ```\n\n- **쓰기 쿼럼(Write Quorum)**: 데이터 블록 + 패리티 블록 수에서 패리티 블록 수를 뺀 것\n  ```go\n  func (er erasureObjects) defaultWQuorum() int {\n    return er.setDriveCount - er.defaultParityCount\n  }\n  ```\n\n### 2. 힐링(Healing) 메커니즘\n\nMinIO는 자동으로 손상된 데이터를 감지하고 복구하는 힐링 메커니즘을 제공합니다:\n\n```go\nfunc (er *erasureObjects) healObject(ctx context.Context, bucket, object, versionID string, opts madmin.HealOpts) (result madmin.HealResultItem, err error) {\n  // 객체 상태 확인\n  // 손상된 부분 감지\n  // Reed-Solomon 알고리즘 사용하여 복구\n  // 복구된 데이터를 다시 분산 저장\n}\n```\n\n## 고급 기능\n\n### 1. 멀티파트 업로드\n\n대용량 객체를 효율적으로 업로드하기 위한 멀티파트 업로드 지원:\n\n```go\nfunc (er erasureObjects) PutObjectPart(ctx context.Context, bucket, object, uploadID string, partID int, r *PutObjReader, opts ObjectOptions) (pi PartInfo, err error) {\n  // 파트 데이터를 이레이저 코딩으로 인코딩\n  // 인코딩된 조각을 디스크에 저장\n}\n```\n\n### 2. 디스크 풀 리밸런싱 및 디커미셔닝\n\n- **리밸런싱**: 디스크 간 데이터 재분배\n- **디커미셔닝**: 풀에서 디스크 안전하게 제거\n\n## 성능 최적화\n\n1. **병렬 I/O 작업**: 동시에 여러 디스크에서 읽기/쓰기 수행\n2. **버퍼 풀링**: 메모리 사용 최적화\n3. **비트맵 기반 디스크 상태 추적**: 빠른 디스크 상태 확인\n\n## 결론\n\nMinIO의 이레이저 코딩 구현은 Reed-Solomon 알고리즘을 기반으로 하며, 계층적 구조(serverPools > sets > objects)를 통해 확장성을 제공합니다. 데이터 블록과 패리티 블록의 분산 저장, 쿼럼 기반 작업, 자동 힐링 기능으로 높은 내구성과 가용성을 보장합니다.",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 3,
    "wordCount": 569,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "minio의-손상-감지-알고리즘",
    "slug": "minioyi-sonsang-gamji-algorijeum",
    "path": "distributed-systems/minio",
    "fullPath": "distributed-systems/minio/minioyi-sonsang-gamji-algorijeum",
    "title": "MinIO의 손상 감지 알고리즘",
    "excerpt": "MinIO의 손상 감지 알고리즘 MinIO는 분산 시스템에서 데이터 손상을 감지하기 위해 여러 계층의 검증 메커니즘을 구현하고 있습니다. 이 알고리즘들은 메타데이터부터 실제 데이터 블록까지 다양한 수준에서 작동합니다. 메타데이터 검증 File...",
    "content": "# MinIO의 손상 감지 알고리즘\n\nMinIO는 분산 시스템에서 데이터 손상을 감지하기 위해 여러 계층의 검증 메커니즘을 구현하고 있습니다. 이 알고리즘들은 메타데이터부터 실제 데이터 블록까지 다양한 수준에서 작동합니다.\n\n## 1. 메타데이터 검증\n\n### FileInfo 유효성 검증\n\n```go\nfunc (fi FileInfo) IsValid() bool {\n    if fi.Erasure.DataBlocks == 0 || fi.Erasure.ParityBlocks == 0 {\n        return false\n    }\n    if len(fi.Erasure.Distribution) != (fi.Erasure.DataBlocks + fi.Erasure.ParityBlocks) {\n        return false\n    }\n    for _, checksum := range fi.Parts {\n        if checksum.ETag == \"\" {\n            return false\n        }\n    }\n    return true\n}\n```\n\n이 함수는 객체의 메타데이터가 유효한지 검사합니다:\n- 데이터 블록과 패리티 블록 수가 올바른지\n- 분산 패턴이 전체 블록 수와 일치하는지\n- 모든 부분(파트)이 체크섬을 가지고 있는지\n\n### 버전 일관성 검사\n\n```go\nfunc findFileInfoInQuorum(ctx context.Context, metaArr []FileInfo, modTime time.Time, etag string, quorum int) (FileInfo, error) {\n    // 메타데이터 배열에서 쿼럼을 만족하는 일관된 버전 찾기\n    // 시간 기반 그룹화 및 버전 비교\n}\n```\n\n이 함수는 여러 디스크에서 수집한 메타데이터를 비교하여 쿼럼을 만족하는 정확한 버전을 찾습니다.\n\n## 2. 데이터 블록 검증\n\n### 체크섬 검증\n\nMinIO는 각 데이터 부분에 대해 ETag(MD5 체크섬)를 저장하고 이를 사용하여 데이터 무결성을 검증합니다:\n\n```go\nfunc (e ErasureInfo) GetChecksumInfo(partNumber int) (ckSum ChecksumInfo) {\n    // 지정된 파트 번호에 대한 체크섬 정보 검색\n}\n```\n\n데이터를 읽을 때, 계산된 체크섬과 저장된 체크섬을 비교하여 손상 여부를 감지합니다.\n\n### 비트롯 검증\n\n비트롯(Bitrot)은 시간이 지남에 따라 발생하는 데이터 손상을 의미합니다. MinIO는 이를 감지하기 위해 추가적인 해시(예: SHA-256, HighwayHash)를 사용합니다:\n\n```go\n// BitrotVerifier 인터페이스는 비트롯 감지를 위한 검증 메커니즘을 제공\ntype BitrotVerifier interface {\n    // 데이터 검증을 위한 메서드\n    Verify(buf []byte) error\n}\n```\n\n## 3. 객체 부분 검증\n\n실제 데이터 블록의 존재와 무결성을 검증하는 과정:\n\n```go\nfunc checkObjectWithAllParts(ctx context.Context, onlineDisks []StorageAPI, partsMetadata []FileInfo,\n    errs []error, latestMeta FileInfo, filterByETag bool, bucket, object string,\n    scanMode madmin.HealScanMode) (dataErrsByDisk map[int][]int, dataErrsByPart map[int][]int) {\n    \n    // 결과 맵 초기화\n    dataErrsByDisk = make(map[int][]int)\n    dataErrsByPart = make(map[int][]int)\n    \n    // 각 파트에 대한 상태 확인\n    for partIdx, partInfo := range latestMeta.Parts {\n        // 각 디스크에서 파트 데이터 확인\n        for diskIdx, disk := range onlineDisks {\n            if disk == nil {\n                // 디스크 오프라인\n                continue\n            }\n            \n            // 파트 데이터 상태 확인\n            partPath := filepath.Join(bucket, object, partInfo.ETag)\n            err := disk.CheckParts(ctx, partPath)\n            \n            if err != nil {\n                // 오류 기록\n                dataErrsByDisk[diskIdx] = append(dataErrsByDisk[diskIdx], partIdx)\n                dataErrsByPart[partIdx] = append(dataErrsByPart[partIdx], diskIdx)\n            }\n        }\n    }\n    \n    return dataErrsByDisk, dataErrsByPart\n}\n```\n\n이 함수는:\n1. 각 디스크에서 객체의 모든 부분을 확인\n2. 누락되거나 손상된 부분을 식별\n3. 디스크별, 부분별로 오류를 맵핑하여 상세한 손상 정보 제공\n\n## 4. 쿼럼 기반 손상 감지\n\nMinIO는 쿼럼 메커니즘을 사용하여 다수결 원칙으로 손상을 감지합니다:\n\n```go\nfunc reduceReadQuorumErrs(ctx context.Context, errs []error, ignoredErrs []error, readQuorum int) (maxErr error) {\n    // 오류 유형별 카운팅\n    errCount := make(map[error]int)\n    for _, err := range errs {\n        if err != nil {\n            errCount[err]++\n        }\n    }\n    \n    // 읽기 쿼럼이 충족되는지 확인\n    if len(errs) - len(errCount) >= readQuorum {\n        return nil // 쿼럼 충족\n    }\n    \n    // 가장 많이 발생한 오류 반환\n    maxCount := 0\n    for err, count := range errCount {\n        if count > maxCount {\n            maxCount = count\n            maxErr = err\n        }\n    }\n    \n    return maxErr\n}\n```\n\n이 접근 방식은:\n1. 필요한 최소 쿼럼 수의 디스크가 동일한 데이터를 가질 때 해당 데이터가 정확하다고 판단\n2. 쿼럼에 미달하는 경우 손상으로 간주하고 복구 시도\n\n## 5. 댕글링 객체 감지\n\n일관성 없는 상태의 객체를 감지하는 알고리즘:\n\n```go\nfunc isObjectDangling(metaArr []FileInfo, errs []error, dataErrsByPart map[int][]int) (validMeta FileInfo, ok bool) {\n    // 유효한 메타데이터 찾기\n    for _, meta := range metaArr {\n        if meta.IsValid() {\n            validMeta = meta\n            break\n        }\n    }\n    \n    if !validMeta.IsValid() {\n        return FileInfo{}, false // 유효한 메타데이터 없음\n    }\n    \n    // 데이터 파트의 상태 확인\n    for partIdx, errDisks := range dataErrsByPart {\n        // 손상된 디스크 수 계산\n        notFoundCount, nonActionableCount := danglingPartErrsCount(errDisks)\n        \n        // 임계값 초과 시 댕글링으로 간주\n        if notFoundCount > (len(metaArr) / 2) {\n            return validMeta, true\n        }\n    }\n    \n    return FileInfo{}, false\n}\n```\n\n이 함수는:\n1. 유효한 메타데이터 존재 여부 확인\n2. 실제 데이터 파트의 상태와 메타데이터 일치 여부 확인\n3. 대다수의 디스크에서 데이터가 누락된 경우 댕글링 객체로 판단\n\n## 6. 디스크 상태 감지\n\n디스크 자체의 상태를 모니터링하는 알고리즘:\n\n```go\nfunc diskErrToDriveState(err error) (state string) {\n    if err == nil {\n        return madmin.DriveStateOk\n    }\n    \n    switch {\n    case errors.Is(err, errDiskNotFound):\n        return madmin.DriveStateOffline\n    case errors.Is(err, errCorruptedFormat):\n        return madmin.DriveStateCorrupt\n    case errors.Is(err, errUnformattedDisk):\n        return madmin.DriveStateUnformatted\n    case errors.Is(err, errDiskAccessDenied):\n        return madmin.DriveStatePermission\n    case errors.Is(err, errFaultyDisk):\n        return madmin.DriveStateFaulty\n    case errors.Is(err, errDiskFull):\n        return madmin.DriveStateFull\n    }\n    \n    return madmin.DriveStateUnknown\n}\n```\n\n이 함수는 디스크 접근 시 발생하는 오류 유형을 분석하여 디스크 상태를 판단합니다.\n\n## 결론\n\nMinIO의 손상 감지 알고리즘은 여러 계층에서 작동합니다:\n\n1. **메타데이터 수준**: 구조 유효성, 버전 일관성 검증\n2. **데이터 블록 수준**: 체크섬, 비트롯 검증\n3. **객체 부분 수준**: 각 부분의 존재 및 무결성 확인\n4. **쿼럼 기반 검증**: 다수결 원칙으로 손상 여부 판단\n5. **댕글링 객체 감지**: 메타데이터와 실제 데이터 간 일관성 확인\n6. **디스크 상태 모니터링**: 디스크 자체의 건강 상태 평가\n\n이러한 다층적 접근 방식으로 MinIO는 분산 환경에서 발생할 수 있는 다양한 유형의 데이터 손상을 효과적으로 감지하고 복구할 수 있습니다.",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 5,
    "wordCount": 802,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "주요-구현-내용",
    "slug": "juyo-guhyeon-naeyong",
    "path": "distributed-systems/erasure-coding",
    "fullPath": "distributed-systems/erasure-coding/juyo-guhyeon-naeyong",
    "title": "주요 구현 내용",
    "excerpt": "Ceph erasure-code 주요 구현 내용 핵심 인터페이스 (ErasureCodeInterface) 목적: 모든 이레이저 코드 구현의 표준화된 API 제공 주요 메서드: : 프로파일에 따라 코드 초기...",
    "content": "## Ceph erasure-code 주요 구현 내용\n\n### 1. 핵심 인터페이스 (ErasureCodeInterface)\n- **목적**: 모든 이레이저 코드 구현의 표준화된 API 제공\n- **주요 메서드**:\n  - `init()`: 프로파일에 따라 코드 초기화\n  - `encode()`: 데이터를 청크로 인코딩\n  - `decode()`: 청크에서 원본 데이터 복구\n  - `minimum_to_decode_with_cost()`: 최소 비용으로 복구 가능한 청크 세트 결정\n\n### 2. 기본 구현 (ErasureCode)\n- **역할**: 공통 기능을 구현하는 추상 클래스\n- **기능**:\n  - CRUSH 규칙 생성\n  - 청크 매핑 관리\n  - 디코딩을 위한 최소 청크 세트 계산\n  - 기본적인 인코딩/디코딩 워크플로우\n\n### 3. 플러그인 시스템 (ErasureCodePlugin)\n- **구조**: 동적 로딩 가능한 라이브러리 구조\n- **관리**: `ErasureCodePluginRegistry`가 플러그인 로딩, 초기화, 관리\n- **확장성**: 새로운 알고리즘 쉽게 추가 가능\n\n### 4. 주요 알고리즘 구현\n\n#### Jerasure\n- **특징**: 다양한 이레이저 코드 알고리즘 구현(Reed-Solomon, Cauchy 등)\n- **최적화**: SSE, NEON 등 하드웨어 가속 지원\n- **하위 라이브러리**: \n  - `jerasure`: 코어 이레이저 코딩 기능\n  - `gf-complete`: 유한체(Galois Field) 연산 최적화\n\n#### LRC (Local Reconstruction Codes)\n- **목적**: 지역적 복구를 통한 성능 향상\n- **동작**: \n  - 전역 패리티와 지역 패리티 모두 생성\n  - 단일 디스크 오류는 로컬 패리티만으로 빠르게 복구\n  - 심각한 오류는 전역 패리티로 복구\n\n#### SHEC (Shingled Erasure Code)\n- **특징**: 복구 대역폭 최적화\n- **구현**: 중첩된(shingled) 패리티 구조로 더 효율적인 복구\n\n#### ISA (Intel Storage Acceleration)\n- **특징**: 인텔 ISA-L 라이브러리 사용\n- **최적화**: AVX, AVX2 명령어 활용한 고성능 구현\n- **조건부 컴파일**: 하드웨어 지원 여부에 따라 컴파일 타임에 결정\n\n#### CLAY (Coupled-Layer)\n- **특징**: 최소 네트워크 사용으로 최적 복구\n- **구현**: 계층적 인코딩 구조\n\n### 5. 구현 세부사항\n- **청크 정렬**: SIMD 연산을 위한 메모리 정렬 (SIMD_ALIGN = 64바이트)\n- **프로파일 관리**: 키-값 형태로 코딩 파라미터 관리\n- **시스템 통합**: CRUSH 맵과 통합하여 데이터 배치 관리\n- **성능 최적화**: \n  - 하위 청크(sub-chunks) 지원으로 세밀한 데이터 배치\n  - 비용 기반 청크 선택 알고리즘\n\n### 6. 빌드 시스템 (CMakeLists.txt)\n- **플러그인 구성**: 각 알고리즘은 별도 라이브러리로 빌드\n- **조건부 컴파일**: 하드웨어 기능(SIMD, AVX 등)에 따른 최적화 버전 선택\n- **종속성 관리**: 외부 라이브러리 통합",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 2,
    "wordCount": 324,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "용어-정리",
    "slug": "yongeo-jeongri",
    "path": "distributed-systems/erasure-coding",
    "fullPath": "distributed-systems/erasure-coding/yongeo-jeongri",
    "title": "용어 정리",
    "excerpt": "이레이저 코딩 용어 정리 기본 개념: 이레이저 코딩(Erasure Coding): 데이터 중 일부가 손실되더라도 복구할 수 있게 해주는 기술 청크(Chunk): 데이터를 분할한 단위, 각 청크는 별도의 저장소에 분산 저장됨 -...",
    "content": "## 이레이저 코딩 용어 정리\n\n**기본 개념:**\n- **이레이저 코딩(Erasure Coding)**: 데이터 중 일부가 손실되더라도 복구할 수 있게 해주는 기술\n- **청크(Chunk)**: 데이터를 분할한 단위, 각 청크는 별도의 저장소에 분산 저장됨\n- **데이터 청크(Data Chunk)**: 원본 데이터를 저장하는 청크\n- **코딩 청크/패리티 청크(Coding/Parity Chunk)**: 데이터 복구에 사용되는 추가 정보를 담은 청크\n\n**코딩 매개변수:**\n- **K**: 데이터 청크의 수\n- **M**: 코딩/패리티 청크의 수\n- **K+M**: 총 청크 수로, 시스템이 최대 M개의 청크 손실까지 견딜 수 있음\n\n**알고리즘:**\n- **Reed-Solomon**: 널리 사용되는 이레이저 코딩 알고리즘, 어떤 K개의 청크로도 원본 데이터 복구 가능\n- **LRC(Local Reconstruction Codes)**: 일부 데이터는 로컬 패리티로 빠르게 복구하도록 최적화된 코드\n- **SHEC(Shingled Erasure Code)**: 복구 성능을 개선한 코드\n- **CLAY(Coupled-Layer)**: 복구 시 네트워크 사용량을 최소화하는 최적 복구 코드\n\n**Ceph 관련 용어:**\n- **플러그인(Plugin)**: 다양한 이레이저 코딩 알고리즘을 구현한 모듈\n- **CRUSH**: Ceph의 데이터 배치 알고리즘으로, 데이터를 물리적 장치에 분산 배치\n- **CRUSH 규칙(Rule)**: 데이터 배치 정책을 정의\n- **실패 도메인(Failure Domain)**: 함께 실패할 수 있는 구성 요소 집합(예: 랙, 호스트)\n\n**성능 관련 용어:**\n- **인코딩(Encoding)**: 원본 데이터를 데이터 청크와 코딩 청크로 변환하는 과정\n- **디코딩(Decoding)**: 사용 가능한 청크에서 원본 데이터를 복구하는 과정\n- **스트라이프(Stripe)**: 함께 인코딩되는 데이터 집합\n- **최소 복구 집합(Minimum Recovery Set)**: 데이터 복구에 필요한 최소 청크 집합",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 2,
    "wordCount": 205,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "리드-솔로몬-코드의-수학적-원리",
    "slug": "rideu-solromon-kodeuyi-suhagjeog-weonri",
    "path": "distributed-systems/erasure-coding",
    "fullPath": "distributed-systems/erasure-coding/rideu-solromon-kodeuyi-suhagjeog-weonri",
    "title": "리드-솔로몬 코드의 수학적 원리",
    "excerpt": "리드-솔로몬 코드의 수학적 원리 개요 리드-솔로몬(Reed-Solomon) 코드는 데이터 무결성을 보장하고 오류 정정을 가능하게 하는 강력한 오류 수정 코드(Error Correction Code, ECC)이다. 본 문서에서는 리드-솔로몬 코드의 핵심...",
    "content": "# 리드-솔로몬 코드의 수학적 원리\n\n## 1. 개요\n리드-솔로몬(Reed-Solomon) 코드는 데이터 무결성을 보장하고 오류 정정을 가능하게 하는 강력한 오류 수정 코드(Error Correction Code, ECC)이다. 본 문서에서는 리드-솔로몬 코드의 핵심 원리인 다항식 표현과 갈루아 필드(Galois Field, GF)를 활용한 연산 과정을 설명한다.\n\n---\n\n## 2. 다항식을 이용한 데이터 표현\n리드-솔로몬 코드는 데이터를 다항식(polynomial)의 계수로 변환하여 저장한다. 이는 일부 데이터가 손실되더라도 남아 있는 데이터로 원본 다항식을 복구할 수 있도록 하기 위함이다.\n\n### 2.1 다항식 표현\n주어진 데이터 $d_0, d_1, \\dots, d_{k-1}$ 를 계수로 하는 다항식 $P(x)$ 를 정의할 수 있다.\n\n$$\nP(x) = d_0 + d_1 x + d_2 x^2 + \\dots + d_{k-1} x^{k-1}\n$$\n\n이 다항식을 통해 특정한 $x$ 값에서 평가(evaluation)한 값이 데이터 조각이 된다.\n\n### 2.2 데이터 샘플링\n데이터 샘플링 과정에서는 특정한 $x$ 값에서 다항식을 평가하여 데이터를 생성한다. 일반적으로, $x$ 값은 서로 다른 정수 또는 유한체 값으로 설정된다.\n\n샘플링한 데이터 포인트는 다음과 같이 표현될 수 있다:\n\n$$\n(x_0, P(x_0)), (x_1, P(x_1)), \\dots, (x_{k-1}, P(x_{k-1)})\n$$\n\n여기서 각 $P(x_i)$ 값이 원본 데이터의 조각이 된다.\n\n---\n\n## 3. 갈루아 필드(Galois Field, GF)\n리드-솔로몬 코드에서는 정수 또는 실수 연산이 아니라 **유한체(Galois Field, GF)** 위에서 연산을 수행한다. 유한체를 사용하면 데이터 크기를 일정하게 유지하면서도 오류 정정을 효과적으로 수행할 수 있다.\n\n### 3.1 $GF(2^m)$ 연산\n리드-솔로몬 코드에서 일반적으로 사용하는 유한체는 $GF(2^m)$ 이다. 예를 들어, $GF(2^8)$ 는 256개의 원소(0부터 255까지의 숫자)로 구성되며, 8비트 연산을 수행할 수 있다. $GF(2^m)$ 에서는 덧셈과 곱셈 연산이 모듈러 연산을 기반으로 수행된다.\n\n- **덧셈**: $GF(2^m)$에서는 비트 단위 XOR 연산을 수행한다.\n- **곱셈**: 다항식 곱셈을 수행한 후 특정한 **원시 다항식(primitive polynomial)** 로 나눈다.\n\n이러한 연산을 사용하면, 유한체 내에서 항상 일정한 크기의 숫자를 유지하면서도 오류 정정을 수행할 수 있다.\n\n---\n\n## 4. 패리티 데이터 생성\n리드-솔로몬 코드에서는 원본 데이터 $k$ 개를 기반으로 $r$ 개의 패리티 데이터를 생성하여 총 $n = k + r$ 개의 데이터 조각을 저장한다.\n\n### 4.1 패리티 생성 방식\n새로운 패리티 데이터를 만들기 위해 기존 데이터 포인트를 바탕으로 새로운 $x$ 위치에서 다항식을 평가한다.\n\n1. $k$ 개의 원본 데이터 포인트를 이용하여 다항식 $P(x)$ 를 생성한다.\n2. 새로운 위치 $x_k, x_{k+1}, \\dots, x_{k+r-1}$ 에서 다항식을 평가하여 패리티 데이터를 생성한다.\n3. 생성된 패리티 데이터를 원본 데이터와 함께 저장한다.\n\n패리티 데이터는 다음과 같이 나타낼 수 있다:\n\n$$\nP(x_k), P(x_{k+1}), \\dots, P(x_{k+r-1})\n$$\n\n이를 통해 일부 데이터가 손실되더라도 다항식 복원을 통해 원본 데이터를 재구성할 수 있다.\n\n---\n\n## 5. 손실 데이터 복구\n데이터 일부가 손실되었을 때, 리드-솔로몬 코드에서는 **라그랑주 보간법(Lagrange Interpolation)** 을 이용하여 원래 다항식을 복구할 수 있다.\n\n### 5.1 라그랑주 보간법을 이용한 복구\n남아 있는 $k$ 개 이상의 데이터 포인트를 이용하여 원래 다항식을 재구성할 수 있다. 라그랑주 보간법을 사용하면 다음과 같이 원본 다항식을 복구할 수 있다.\n\n$$\nP(x) = \\sum_{i=0}^{k-1} P(x_i) \\cdot l_i(x)\n$$\n\n여기서 $l_i(x)$ 는 라그랑주 기본 다항식으로 정의된다:\n\n$$\nl_i(x) = \\prod_{j \\neq i} \\frac{x - x_j}{x_i - x_j}\n$$\n\n이 보간법을 통해 손실된 데이터 포인트를 복구할 수 있다. 즉, $k$ 개 이상의 데이터 조각이 남아 있다면 손실된 데이터도 복구가 가능하다.\n\n---\n\n## 6. 결론\n리드-솔로몬 코드는 다항식 표현과 갈루아 필드 연산을 기반으로 데이터 무결성을 보장하는 오류 정정 기법이다. 이를 통해 다음과 같은 장점이 제공된다:\n\n1. **데이터 손실 복구 가능**: 일부 데이터가 손실되더라도 남은 데이터를 이용하여 원래 데이터를 복원할 수 있음.\n2. **유연한 저장 시스템 지원**: RAID 6, 클라우드 스토리지, 위성 통신 등 다양한 환경에서 사용됨.\n3. **수학적으로 강력한 보장**: 갈루아 필드 연산을 사용하여 데이터를 효율적으로 보호하고 정정 가능.\n\n리드-솔로몬 코드는 단순한 오류 검출을 넘어 **데이터 복구까지 가능한 강력한 알고리즘**이며, 현대의 데이터 저장 및 통신 시스템에서 중요한 역할을 하고 있다.",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 3,
    "wordCount": 558,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "데이터-원본을-전체적으로-리드솔로몬-인코딩-후-샤드-분배-vs-2-스트라이핑-후-개별-블록-단위로-리드솔로몬-인코딩-후-샤드-분배-비교",
    "slug": "deiteo-weonboneul-jeoncejeogeuro-rideusolromon-inkoding-hu-syadeu-bunbae-vs-2-seuteuraiping-hu-gaebyeol-beulrog-danwiro-rideusolromon-inkoding-hu-syadeu-bunbae-bigyo",
    "path": "distributed-systems/erasure-coding",
    "fullPath": "distributed-systems/erasure-coding/deiteo-weonboneul-jeoncejeogeuro-rideusolromon-inkoding-hu-syadeu-bunbae-vs-2-seuteuraiping-hu-gaebyeol-beulrog-danwiro-rideusolromon-inkoding-hu-syadeu-bunbae-bigyo",
    "title": "데이터 원본을 전체적으로 리드솔로몬 인코딩 후 샤드 분배 vs. 2. 스트라이핑 후 개별 블록 단위로 리드솔로몬 인코딩 후 샤드 분배 비교",
    "excerpt": "--- 🔹 1. 데이터 원본을 리드솔로몬 인코딩 후 노드마다 샤드를 나누는 방식 🛠️ 개요 • 원본 데이터를 한 번에 큰 단위로 리드솔로몬(Erasure Coding, EC) 인코딩을 수행한 뒤, 생성된 데이터 블록(원본)과 패리티...",
    "content": "---\n\n**🔹 1. 데이터 원본을 리드솔로몬 인코딩 후 노드마다 샤드를 나누는 방식**\n\n  \n\n**🛠️ 개요**\n\n• 원본 데이터를 한 번에 큰 단위로 리드솔로몬(Erasure Coding, EC) 인코딩을 수행한 뒤, 생성된 **데이터 블록(원본)과 패리티 블록(복구용)을 여러 노드에 분배**하는 방식입니다.\n\n• 예를 들어, **(6,3) Reed-Solomon 코드**를 사용하면, 원본 데이터를 6개로 나누고, 3개의 패리티 블록을 추가 생성하여 **총 9개 블록을 9개 노드에 분배**합니다.\n\n  \n\n**✅ 장점**\n\n1. **쓰기 성능이 상대적으로 좋음**\n\n• 원본 데이터를 한 번에 인코딩 후 분배하기 때문에, **추가적인 스트라이핑 연산이 필요 없음**.\n\n• 네트워크 전송량이 예측 가능하고 일정함.\n\n2. **복구 효율성이 높음 (특히 전체 노드 장애 시)**\n\n• 데이터 블록과 패리티 블록이 일정한 방식으로 저장되므로, **특정 노드 손실 시 패리티 블록을 이용해 빠르게 재구성 가능**.\n\n3. **CPU 오버헤드가 비교적 낮음**\n\n• 리드솔로몬 인코딩을 한 번만 수행하면 되므로, CPU 연산량이 줄어듦.\n\n  \n\n**❌ 단점**\n\n1. **데이터가 노드에 균등하게 저장되지 않을 수 있음**\n\n• 하나의 원본 데이터를 여러 노드에 나누어 저장하기 때문에, **특정 노드가 자주 사용될 가능성**이 있음.\n\n• 네트워크 트래픽이 특정 노드에 집중될 가능성이 있음.\n\n2. **조각난 블록만 읽고 싶어도 전체 데이터의 일부를 복원해야 할 수도 있음**\n\n• 작은 단위 데이터 접근 시에도, 원본 데이터가 인코딩된 상태이므로 **원본 블록을 직접 읽는 것이 어려울 수 있음**.\n\n---\n\n**🔹 2. 데이터를 스트라이핑한 후 개별 블록 단위로 리드솔로몬 인코딩 후 샤드 분배**\n\n  \n\n**🛠️ 개요**\n\n• 원본 데이터를 일정 크기로 **스트라이핑(Striping)** 한 뒤, 각 블록 단위로 리드솔로몬 인코딩을 적용하여 샤드를 생성하고 분배하는 방식입니다.\n\n• 예를 들어, 1GB 파일을 64MB 단위로 나누어 저장할 경우, 각각의 64MB 블록을 개별적으로 리드솔로몬 인코딩하여 분산 저장.\n\n  \n\n**✅ 장점**\n\n1. **작은 단위 데이터 접근이 효율적**\n\n• 특정 블록만 필요할 경우, 해당 블록만 읽고 패리티 블록을 활용하여 복구 가능.\n\n• **Hadoop HDFS의 Erasure Coding 방식**이나 **MinIO의 Parity Striping** 방식에서 사용됨.\n\n2. **노드 간 부하가 균등하게 분산됨**\n\n• 데이터가 작은 단위로 쪼개져 분산되므로, **특정 노드에 트래픽이 집중되는 문제를 줄일 수 있음**.\n\n3. **병렬 I/O 성능 향상**\n\n• 여러 개의 작은 블록이 동시에 다른 노드에서 읽히므로, **대규모 분산 스토리지에서 높은 병렬성을 가질 수 있음**.\n\n  \n\n**❌ 단점**\n\n1. **쓰기 성능이 낮을 수 있음**\n\n• 데이터 단위마다 개별적으로 인코딩을 수행해야 하므로, CPU 연산량 증가 및 추가적인 네트워크 비용 발생.\n\n• 네트워크에서 더 많은 작은 패킷이 이동해야 하므로, 지연(latency)이 증가할 가능성이 있음.\n\n2. **복구 시 오버헤드 증가**\n\n• 블록 단위로 분산되었기 때문에, 특정 노드에서 복구해야 할 블록이 많으면 복구 작업이 병목이 될 수 있음.\n\n---\n\n**🔹 최종 비교**\n\n|**비교 항목**|**1. 원본 데이터 단위로 리드솔로몬 인코딩 후 샤드 분배**|**2. 스트라이핑 후 개별 블록 단위로 리드솔로몬 인코딩**|\n|---|---|---|\n|**쓰기 성능**|상대적으로 빠름 (한 번만 인코딩)|상대적으로 느림 (블록마다 개별 인코딩 필요)|\n|**읽기 성능**|전체 데이터의 일부를 복구해야 할 수도 있음|특정 블록만 읽는 것이 가능|\n|**복구 효율성**|전체 원본을 유지하기 쉬움|개별 블록 복구 시 오버헤드 증가 가능|\n|**노드 부하**|일부 노드에 집중될 가능성이 있음|노드 간 부하가 균등하게 분배됨|\n|**병렬 처리**|병렬성이 상대적으로 낮음|높은 병렬성 가능|\n\n  \n\n---\n\n**🔹 결론: 어떤 방식이 더 적합할까?**\n\n• **대용량 데이터 저장 & 읽기/쓰기 성능이 중요한 경우** → **1번 방식이 유리**\n\n• Ceph RADOS Erasure Coding과 유사한 방식.\n\n• 클러스터 전체의 안정성이 필요하고, 특정 파일을 전체적으로 다루는 경우 적합.\n\n• **데이터 조각 단위로 접근이 많고, 병렬성이 중요한 경우** → **2번 방식이 유리**\n\n• Hadoop HDFS의 EC, MinIO의 스트라이핑 방식과 유사.\n\n• 개별적인 작은 파일이나 블록 단위의 병렬 처리가 중요한 경우 적합.\n\n  \n\n**즉, “1번은 전체 데이터 중심의 안정성을 강조하고, 2번은 개별 블록 접근성과 병렬성을 강조하는 방식”**이라고 볼 수 있습니다. 🚀\n\n  \n\n혹시 더 구체적으로 비교할 부분이 있다면 알려주세요! 😊",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 3,
    "wordCount": 543,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "succinct-proofs-of-random-access-spora-번역",
    "slug": "succinct-proofs-of-random-access-spora-beonyeog",
    "path": "distributed-systems/data-availability",
    "fullPath": "distributed-systems/data-availability/succinct-proofs-of-random-access-spora-beonyeog",
    "title": "Succinct Proofs of Random Access (SPoRA) 번역",
    "excerpt": "--- 개요 (Abstract) 이 문서는 Arweave 네트워크의 새로운 합의 메커니즘을 설명한다. 이 메커니즘은 최신 블록위브(blockweave) 상태에서 유추된 과거 데이터 청크를 찾는 경쟁 방식에 기반을 둔다. --- 동기...",
    "content": "---\n\n**1. 개요 (Abstract)**\n\n이 문서는 Arweave 네트워크의 새로운 합의 메커니즘을 설명한다. 이 메커니즘은 **최신 블록위브(blockweave) 상태에서 유추된 과거 데이터 청크를 찾는 경쟁 방식**에 기반을 둔다.\n\n---\n\n**2. 동기 (Motivation)**\n\n현재 Arweave 네트워크에서 사용되는 합의 알고리즘은 **기존 작업 증명(Proof of Work, PoW)** 방식과 유사하지만, 추가적으로 최신 블록위브 상태에서 결정된 **과거 데이터 청크(최대 256KiB)** 를 포함해야 한다. 이 방식은 **네트워크가 과거 데이터를 유지하도록 장려**하는 효과는 있지만, 채굴자가 데이터를 얼마나 빨리 액세스할 수 있어야 하는지에 대한 **제한이 거의 없는 문제**가 있다.\n\n• **문제점 1:**\n\t• 채굴자가 원격 스토리지 풀(remote storage pool)을 활용하여 빠르게 데이터를 검색하는 방식이 가능하다.\n\t• 원격 저장소와 컴퓨팅 풀을 조합하면 **1Gbps 인터넷 링크를 통해 초당 수백만 개의 PoW 입력값을 계산하여 제공**할 수도 있다.\n\t• 실제로 Arweave 네트워크에서는 **공개 노드(public node) 수가 감소하는 동시에, 네트워크 해시파워(hashpower)는 증가**하고 있다.\n\t• 이는 일부 채굴자들이 **공동 저장 및 계산 풀(storage & computation pool)** 을 형성하고 있음을 시사한다.\n\n• **문제점 2:**\n\t• PoW 기반 네트워크는 **에너지 소비량이 매우 크다.**\n\t• 탄소 배출량이 많아 환경에 부정적인 영향을 미칠 수 있다.\n\t• 친환경적인 합의 알고리즘을 도입하는 것은 **Arweave 플랫폼의 장기적인 지속 가능성을 위해 필수적**이다.\n\n---\n\n**SPoRA의 목표**\n\n새로운 합의 알고리즘(SPoRA)은 다음 두 가지 주요 목표를 달성하고자 한다.\n\n1. **데이터를 필요할 때만 불러오는 방식(온디맨드 데이터 검색)을 억제하고, 채굴자들이 데이터를 채굴 기계에 더 가깝게 저장하도록 유도한다.**\n\t• 즉, 데이터를 로컬에 저장하지 않고 네트워크에서 불러오는 채굴자는 불리해지도록 설계한다.\n\n2. **네트워크의 에너지 소비를 줄인다.**\n\t• 기존 PoW의 높은 연산 비용과 전력 소모를 낮춰 보다 효율적인 합의 과정을 만든다.\n\n---\n\n**3. 참조 구현 (Reference Implementation)**\n\n해당 합의 알고리즘의 참조 구현(Reference Implementation)은 아래 링크에서 확인할 수 있다.\n\n🔗 [**ArweaveTeam GitHub 링크**](https://github.com/ArweaveTeam/arweave/pull/269)\n\n---\n\n**4. SPoRA 알고리즘 명세 (Specification)**\n\n**4.1 사전 요구 사항 (Prerequisites)**\n\n**1. 인덱싱된 데이터셋 (Indexed Dataset)**\n\nSPoRA의 핵심은 **과거 데이터 청크를 지속적으로 검색하는 것**이다. 모든 데이터 청크는 **전역 오프셋(Global Offset)** 으로 식별되며, 네트워크 전체에서 모든 바이트가 **동일한 인센티브를 받도록 설계**되어야 한다. 따라서, **블록위브 전체를 인덱싱하여, 특정 청크를 빠르게 검색할 수 있도록 해야 한다.** **Arweave Erlang 클라이언트**는 **버전 2.1부터** 이러한 인덱스를 유지하도록 설계되었다.\n\n---\n\n**2. 느린 해시(Slow Hash)**\n\nSPoRA는 **채굴자가 지속적으로 저장소에 접근하도록 강제**하는 방식으로 동작해야 한다. 즉, **채굴자가 특정 데이터를 빠르게 선택할 수 없도록 만들어야 하며**, 이는 아래 두 가지 이유 때문입니다.\n\n• **위협 1:**\n\t• 채굴자가 데이터 저장 비용을 아끼고, 대신 **빠른 연산으로 PoW를 수행하려는 가능성**이 있다.\n\t• 데이터 저장 없이 빠른 계산만으로 동일한 보상을 받는다면, 저장 인센티브가 사라진다.\n• **위협 2:**\n\t• 현재의 컴퓨팅 기술은 매우 발전하여, 데이터 검색을 하지 않더라도 높은 효율로 연산을 수행할 수 있다.\n\t• 이는 기존 PoW 방식보다도 더 빠르게 채굴이 이루어질 수 있음을 의미한다.\n\n이를 해결하기 위해, Arweave는 **버전 1.7부터** [**RandomX**](https://44jxru4mdgbtd66dlzjlc3huktqmmzufomg5p24jl66zyut562yq.arweave.net/5xN404wZgzH7w15SsWz0VODGZoVzDdfriV-9nFJ99rE)**를 사용**한다. RandomX는 **일반 CPU에 최적화된 PoW 알고리즘**으로, **전문 하드웨어의 채굴 우위를 줄이는 역할**을 한다.\n\n---\n\n**4.2 알고리즘 설명 (Algorithm Description)**\n\n  **채굴자(Miner)의 과정**\n1. 랜덤 논스(nonce)를 생성하고, 현재 블록 상태, 후보 블록, nonce를 포함하는 머클 트리 해시를 생성한다.\n2. 이 해시 값을 기반으로 **특정 Recall Byte(검색해야 할 바이트 위치)** 를 결정한다.\n3. 로컬 저장소에서 해당 바이트가 포함된 **데이터 청크를 검색**한다.\n\t• 데이터를 찾지 못했다면 1번 단계부터 다시 시작한다.\n4. 찾은 데이터 청크와 이전 블록 해시를 조합하여 **빠른 해시(Fast Hash)를 계산**한다.\n5. 계산된 해시 값이 **현재 난이도보다 크다면**, 해당 블록을 네트워크에 전파한다.\n\t• 블록에는 **nonce와 해당 데이터 청크**가 포함된다.\n\n이 과정에서 사용된 **해당 데이터 청크와 머클 증명(Merkle Proofs)** 를 **Succinct Proof of Random Access (SPoRA)** 라고 한다.\n\n이는 새로운 합의 알고리즘의 이름이기도 하다.\n\n---\n\n**검증자(Verifier)의 과정**\n\n• 검증자는 **채굴자가 수행한 과정**을 한 번 실행하여 블록의 유효성을 검증한다.\n• 블록 내의 **nonce와 데이터 청크가 올바른지 확인**하면 된다.\n\n---\n\n**4.3 검색 공간 제한 (Search Space Constraints)**\n\nSPoRA는 **검색 공간(Search Space)을 적절히 설정하여 데이터 저장을 장려**해야 한다.\n\n1. 검색 공간이 **충분히 커야 하는 이유**:\n\t• 채굴자가 온디맨드 방식으로 **전체 검색 공간을 다운로드하는 것이 불가능하도록 하기 위해서**.\n\t• 네트워크 대역폭이 증가함에 따라, 데이터 요청만으로 PoW를 수행하는 것이 점점 쉬워지므로 이를 방지해야 한다.\n\n2. 검색 공간이 **너무 크면 안 되는 이유**:\n\t• 데이터 저장량이 적은 채굴자도 경쟁할 수 있도록 하려면 검색 공간이 너무 크면 안 된다.\n\t• 따라서 SPoRA는 **검색 공간을 블록위브의 10%로 설정**한다.\n\t• 이 경우, 일부 채굴자가 특정 부분을 집중적으로 저장하면 **약 1.2배의 채굴 효율을 얻게 됨**.\n\n---\n\n**5. 관련 연구 (Related Work)**\n\nSPoRA는 **Permacoin: Repurposing Bitcoin Work for Data Preservation** 논문에서 영감을 받았다. Arweave는 이를 **신뢰할 수 있는 중앙화된 데이터 대신, 분산 네트워크 전체에서 데이터를 유지하는 방식**으로 개선했다. SPoRA는 **연산으로 데이터 부족을 보완하는 것이 불가능하도록 설계**되었으며,\n네트워크가 데이터를 고르게 복제하도록 인센티브를 제공한다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 4,
    "wordCount": 707,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "2024-data-replication-design-spectrum-요약",
    "slug": "2024-data-replication-design-spectrum-yoyag",
    "path": "distributed-systems/data-availability",
    "fullPath": "distributed-systems/data-availability/2024-data-replication-design-spectrum-yoyag",
    "title": "“2024 Data Replication Design Spectrum” 요약",
    "excerpt": "“2024 Data Replication Design Spectrum” 요약 이 글에서는 데이터 복제(Data Replication) 알고리즘의 다양한 설계 방식을 소개하며, 특히 레플리카(replica) 장애를 처리하는 방식에 초점을 맞추고 있...",
    "content": "**“2024 Data Replication Design Spectrum” 요약**\n\n이 글에서는 **데이터 복제(Data Replication) 알고리즘의 다양한 설계 방식**을 소개하며, 특히 **레플리카(replica) 장애를 처리하는 방식**에 초점을 맞추고 있음. 복제 알고리즘들은 **장애 관리 방식**에 따라 분류되며, **리소스 효율성, 가용성, 지연시간(레이턴시)** 등의 측면에서 서로 다른 트레이드오프를 가지게 됨.\n\n**🔹 1. 장애 처리 방식: Failure Masking vs. Failure Detection**\n\n**✅ Failure Masking (장애 마스킹)**\n\n• 일부 레플리카가 장애가 나더라도 **즉각적인 개입 없이 운영 가능**한 방식.\n• **쿼럼 기반(Quorum-based) 리더 없는 복제**가 대표적인 예시.\n• **특징:**\n\t• 다수결(majority) 기반의 동작 → 과반수 이상이 살아있다면 서비스 지속 가능.\n\t• 장애 탐지를 위한 별도 작업 없이 계속 운영 가능하지만, 성능 저하 가능성 존재.\n\n  \n\n**✅ Failure Detection (장애 감지)**\n\n• 장애 발생 시, **명시적으로 감지하고 재구성(reconfiguration)이 필요한 방식**.\n• 레플리카의 상태를 추적하고, 장애가 확인되면 새로운 복제 구조를 설정해야 함.\n• **특징:**\n\t• 장애 감지를 위한 추가적인 오버헤드 존재.\n\t• 장애가 발생하면 즉시 대응이 필요하므로, 복구 과정이 필요함.\n\n**🔹 2. 하이브리드 방식: 리더 기반 복제 (Leader-Based Replication)**\n\n• 리더(Leader)를 두고, 리더가 모든 복제를 관리하는 방식.\n• 대표적인 알고리즘: **Raft, Paxos**\n• **Failure Masking과 Failure Detection의 중간 형태**\n→ 리더가 장애가 나면 새로운 리더를 선출해야 하지만, 운영 중에는 복제를 쉽게 관리할 수 있음.\n\n• **특징:**\n\t• 장애 시 리더를 선출하는 과정에서 지연이 발생할 수 있음.\n\t• 트랜잭션 일관성을 보장하기에 적합.\n\n**🔹 3. 복제 알고리즘 비교 (트레이드오프)**\n\n| **방식**                         | **리소스 효율성** | **가용성(Availability)** | **지연시간(Latency)** |\n| ------------------------------ | ----------- | --------------------- | ----------------- |\n| **Failure Masking (쿼럼 기반)**    | 보통          | 높음                    | 낮음                |\n| **Failure Detection (재구성 필요)** | 낮음          | 중간                    | 높음                |\n| **리더 기반 복제 (Raft 등)**          | 높음          | 중간                    | 중간                |\n\n각 방식은 **특정한 시스템 요구사항에 따라 적합성이 달라지며, 완벽한 방식은 없음**.\n\n**🔹 4. 주요 데이터베이스 시스템의 적용 방식**\n\n  다양한 데이터베이스들이 각각의 목적에 맞는 복제 방식을 선택하고 있어.\n\n• **리더 기반 복제:** MongoDB, Redis Cluster 등\n• **쿼럼 기반 복제:** Cassandra, Riak KV 등\n• **재구성 기반 복제:** Elasticsearch, InfluxDB 등\n\n**🔹 5. 결론: 완벽한 방식은 없음**\n\n• **모든 복제 알고리즘은 트레이드오프가 존재**하며, 시스템이 요구하는 **일관성(Consistency), 가용성(Availability), 성능(Performance)** 을 고려해 선택해야 함.\n• 예를 들어,\n\t• **높은 가용성**이 필요하면 Failure Masking 방식이 유리.\n\t• **리더 기반으로 강한 일관성**을 원하면 Raft 같은 리더 기반 복제가 적합.\n\t• **재구성이 용이한 시스템**이 필요하면 Failure Detection 기반의 접근이 효과적.\n\n  \n\n🔗 원문: [Transactional Blog](https://transactional.blog/blog/2024-data-replication-design-spectrum?utm_source=chatgpt.com)",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 2,
    "wordCount": 378,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "crush-controlled-replication-under-scalable-hashing",
    "slug": "crush-controlled-replication-under-scalable-hashing",
    "path": "distributed-systems/ceph",
    "fullPath": "distributed-systems/ceph/crush-controlled-replication-under-scalable-hashing",
    "title": "CRUSH (Controlled Replication Under Scalable Hashing)",
    "excerpt": "CRUSH (Controlled Replication Under Scalable Hashing) 기본 개념 CRUSH는 Ceph의 핵심 데이터 배치 알고리즘으로, 데이터 객체를 클러스터의 물리적 저장 장치에 분산 배치하는 방법을 결정합니다. 주요 특...",
    "content": "# CRUSH (Controlled Replication Under Scalable Hashing)\n\n## 기본 개념\nCRUSH는 Ceph의 핵심 데이터 배치 알고리즘으로, 데이터 객체를 클러스터의 물리적 저장 장치에 분산 배치하는 방법을 결정합니다.\n\n## 주요 특징\n1. **결정적 배치**: 동일한 입력에 대해 항상 같은 결과 반환 (중앙 조정 없음)\n2. **확장성**: 수천~수만 개의 장치 지원 가능\n3. **자가 관리**: 클러스터 변화에 자동 적응\n4. **장애 도메인 인식**: 하드웨어 장애 시나리오 고려한 배치\n\n## CRUSH 작동 방식\n\n### 1. 계층 구조(CRUSH 맵)\n- **장치(Device)**: 실제 물리적 OSD(Object Storage Daemon)\n- **버킷(Bucket)**: 장치나 다른 버킷을 포함하는 논리적 그룹\n  - **호스트(Host)**: 한 서버의 OSD 그룹\n  - **랙(Rack)**: 여러 호스트 그룹\n  - **로우(Row)**: 여러 랙 그룹\n  - **룸(Room)**: 여러 로우 그룹\n  - **데이터센터(DC)**: 여러 룸 그룹\n  - **루트(Root)**: 최상위 버킷\n\n### 2. 배치 규칙(CRUSH Rule)\n- **목적**: 어떤 방식으로 데이터를 배치할지 정의\n- **구성 요소**:\n  - **규칙 세트(Rule Set)**: 규칙 모음\n  - **규칙 단계(Rule Step)**: 각 규칙의 작업 단위\n  - **실패 도메인(Failure Domain)**: 함께 실패할 수 있는 구성 요소 단위(예: 호스트, 랙)\n  - **타입 지정자(Type Specifier)**: 배치 시 사용할 계층 지정\n\n### 3. 알고리즘 프로세스\n1. **해싱**: 객체 ID를 해시하여 의사 난수 시드 생성\n2. **규칙 적용**: CRUSH 규칙에 따라 배치 위치 결정\n3. **계층 탐색**: 지정된 실패 도메인에서 적절한 장치 선택\n4. **배치 확정**: 선택된 장치에 데이터 배치\n\n## 이레이저 코딩과 CRUSH 통합\n\n### 1. 청크 배치\n- 각 데이터 청크(K)와 코딩 청크(M)는 CRUSH 알고리즘에 의해 서로 다른 장치에 배치\n- 실패 도메인을 고려하여 같은 실패 지점에 여러 청크 배치 방지\n\n### 2. 이레이저 코드별 CRUSH 규칙\n- `ErasureCode::create_rule()`: 각 이레이저 코드 구현은 자신만의 CRUSH 규칙 생성\n- **규칙 매개변수**:\n  - `rule_root`: 최상위 버킷 지정 (기본값: \"default\")\n  - `rule_failure_domain`: 실패 도메인 지정 (기본값: \"host\")\n  - `rule_device_class`: 장치 클래스 제한 (예: SSD만 사용)\n\n### 3. 구현 세부사항\n```cpp\nint ErasureCode::create_rule(const std::string &name,\n                            CrushWrapper &crush,\n                            std::ostream *ss) const {\n  // 최소 필요 장치 수 계산\n  int min_rep = get_chunk_count();\n  // 지정된 실패 도메인에 해당하는 타입 ID 조회\n  int type = crush.get_type_id(rule_failure_domain);\n  // 루트 버킷 ID 조회\n  int rootid = crush.get_item_id(rule_root);\n  // 실제 CRUSH 규칙 생성\n  int rno = crush.add_simple_rule(name, rule_root, rule_failure_domain,\n                                  \"firstn\", pg_pool_t::TYPE_ERASURE,\n                                  min_rep, ss);\n  return rno;\n}\n```\n\n## 실패 복구 시나리오\n\n### 1. 청크 손실 상황\n- 특정 OSD 실패로 일부 청크 손실\n- CRUSH 맵 참조하여 손실된 청크의 위치 파악\n\n### 2. 복구 프로세스\n- `minimum_to_decode_with_cost()`: 최소 비용으로 복구 가능한 청크 세트 계산\n- 남아있는 청크 위치 파악 (CRUSH 맵 이용)\n- 해당 청크들로부터 손실된 청크 복구\n- 새로운 장치에 복구된 청크 재배치 (CRUSH 알고리즘 사용)\n\n## CRUSH의 장점\n1. **확장성**: 중앙 메타데이터 테이블 없이 배치 계산\n2. **복원력**: 클러스터 변화에 동적 적응\n3. **튜닝 가능성**: 다양한 워크로드에 최적화 가능\n4. **하드웨어 인식**: 실제 물리적 토폴로지 반영 가능",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 3,
    "wordCount": 441,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "ceph-erasure-coding-메타데이터-관리",
    "slug": "ceph-erasure-coding-metadeiteo-gwanri",
    "path": "distributed-systems/ceph",
    "fullPath": "distributed-systems/ceph/ceph-erasure-coding-metadeiteo-gwanri",
    "title": "Ceph Erasure Coding 메타데이터 관리",
    "excerpt": "Ceph Erasure Coding 메타데이터 관리 메타데이터 종류 코딩 프로파일 정보: K, M 값 (데이터 청크 수, 코딩 청크 수) 사용된 이레이저 코딩 알고리즘 유형 특수 파라미터 (예: jerasure...",
    "content": "# Ceph Erasure Coding 메타데이터 관리\n\n## 1. 메타데이터 종류\n1. **코딩 프로파일 정보**:\n   - K, M 값 (데이터 청크 수, 코딩 청크 수)\n   - 사용된 이레이저 코딩 알고리즘 유형\n   - 특수 파라미터 (예: jerasure 기법, LRC 로컬 그룹 크기)\n\n2. **청크 매핑 정보**:\n   - 각 청크의 논리적 인덱스와 물리적 OSD 매핑\n   - `chunk_mapping` 벡터에 저장\n\n3. **객체 레이아웃 정보**:\n   - 청크 크기\n   - 스트라이프 크기\n   - 객체 크기 및 패딩 정보\n\n4. **CRUSH 규칙 메타데이터**:\n   - 실패 도메인 설정\n   - 규칙 ID 및 이름\n   - 디바이스 클래스 제한 정보\n\n## 2. 메타데이터 저장 방식\n\n### 풀(Pool) 수준 메타데이터\n1. **풀 속성**:\n   - `ceph osd pool set {pool-name} erasure_code_profile {profile-name}`\n   - 클러스터 모니터 데이터베이스에 저장\n   - CRUSH 규칙과 연결\n\n2. **프로파일 저장**:\n   ```cpp\n   const ErasureCodeProfile &get_profile() const {\n     return _profile;\n   }\n   ```\n   - 클러스터 모니터의 키-값 저장소에 보관\n   - 각 풀마다 하나의 프로파일 사용\n\n### 객체 수준 메타데이터\n1. **OMAP(Object Map) 활용**:\n   - 객체 헤더에 메타데이터 저장\n   - xattr(확장 속성)으로 청크 정보 저장\n\n2. **객체 속성**:\n   - 객체 크기, 스트라이프 정보\n   - 타임스탬프, 사용자 정의 메타데이터\n\n### PG(Placement Group) 수준 메타데이터\n1. **PG 로그**:\n   - 모든 쓰기 작업 기록\n   - 복구에 필요한 작업 순서 보존\n\n2. **OSDMap**:\n   - 현재 클러스터 상태 반영\n   - 각 PG의 CRUSH 매핑 정보 포함\n\n## 3. 청크 매핑 관리\n\n1. **논리적 매핑**:\n   ```cpp\n   const std::vector<int> &get_chunk_mapping() const;\n   ```\n   - 청크 인덱스(0~K+M-1)와 실제 OSD 매핑\n   - 인코딩/디코딩 시 참조\n\n2. **매핑 초기화**:\n   ```cpp\n   int to_mapping(const ErasureCodeProfile &profile, std::ostream *ss);\n   ```\n   - 프로파일에서 매핑 정보 추출\n   - 필요시 기본 순차 매핑 생성\n\n3. **매핑 활용**:\n   ```cpp\n   int chunk_index(unsigned int i) const;\n   ```\n   - 청크 ID를 실제 저장 위치로 변환\n   - 데이터 조회 시 필요한 위치 계산\n\n## 4. 프로파일 관리\n\n1. **프로파일 구성**:\n   ```cpp\n   typedef std::map<std::string,std::string> ErasureCodeProfile;\n   ```\n   - 키-값 쌍 형태로 설정 저장\n   - 예: `{\"k\":\"4\", \"m\":\"2\", \"technique\":\"reed_sol_van\"}`\n\n2. **프로파일 파싱**:\n   ```cpp\n   int parse(const ErasureCodeProfile &profile, std::ostream *ss);\n   ```\n   - 문자열 형태의 설정을 내부 값으로 변환\n   - 타입 변환 헬퍼 메서드 제공:\n     ```cpp\n     static int to_int(const std::string &name, ErasureCodeProfile &profile, ...);\n     static int to_bool(const std::string &name, ErasureCodeProfile &profile, ...);\n     ```\n\n3. **프로파일 검증**:\n   ```cpp\n   int sanity_check_k_m(int k, int m, std::ostream *ss);\n   ```\n   - K, M 값의 유효성 검사\n   - 최소/최대 값 제한 적용\n\n## 5. 메타데이터 복구 전략\n\n1. **클러스터 맵 동기화**:\n   - 모니터 노드에서 주기적으로 OSDMap 동기화\n   - 변경 사항을 모든 노드에 전파\n\n2. **메타데이터 중복 저장**:\n   - 중요 메타데이터는 여러 모니터 노드에 복제\n   - Paxos 알고리즘으로 일관성 보장\n\n3. **PG 로그 활용**:\n   - 작업 순서대로 기록된 로그로 메타데이터 복구\n   - PG 스크러빙으로 메타데이터 무결성 검증\n\n4. **오류 복구 시나리오**:\n   - OSD 실패: 다른 OSD에서 메타데이터 복구\n   - 모니터 실패: 다른 모니터에서 메타데이터 복제\n   - 전체 메타데이터 손실: 백업 또는 CRUSH 재계산\n\n## 6. 성능 최적화\n\n1. **메타데이터 캐싱**:\n   - 자주 사용되는 프로파일과 매핑 정보 메모리 캐싱\n   - OSD 및 클라이언트 측 캐시 활용\n\n2. **효율적인 조회**:\n   - 인덱스 기반 빠른 청크 위치 조회\n   - 병렬 메타데이터 조회 지원\n\n3. **압축 저장**:\n   - 메타데이터 압축으로 저장 공간 및 네트워크 대역폭 절약\n   - 작은 객체 메타데이터 통합 저장\n\n4. **지연 업데이트**:\n   - 비중요 메타데이터 변경은 지연 기록으로 성능 향상\n   - 일괄 처리(batching)로 디스크 I/O 최소화",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 3,
    "wordCount": 521,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "ceph-erasure-coding-데이터-조회-흐름",
    "slug": "ceph-erasure-coding-deiteo-johoe-heureum",
    "path": "distributed-systems/ceph",
    "fullPath": "distributed-systems/ceph/ceph-erasure-coding-deiteo-johoe-heureum",
    "title": "Ceph Erasure Coding 데이터 조회 흐름",
    "excerpt": "Ceph Erasure Coding 데이터 조회 흐름 클라이언트 요청 단계 객체 접근 요청: 클라이언트가 특정 객체 ID로 데이터 요청 CRUSH 계산: 클라이언트는 CRUSH 알고리즘을 사용해 객체의 청크들이 저장된 OSD...",
    "content": "# Ceph Erasure Coding 데이터 조회 흐름\n\n## 1. 클라이언트 요청 단계\n1. **객체 접근 요청**: 클라이언트가 특정 객체 ID로 데이터 요청\n2. **CRUSH 계산**: 클라이언트는 CRUSH 알고리즘을 사용해 객체의 청크들이 저장된 OSD 위치 계산\n3. **PG(Placement Group) 결정**: 객체가 속한 배치 그룹 식별\n\n## 2. 데이터 청크 수집 단계\n1. **가용 청크 확인**: \n   - 모든 데이터 청크(K개)가 가용한 경우: 직접 데이터 청크만 읽음\n   - 일부 데이터 청크 누락: 복구를 위한 최소 청크 세트 결정\n\n2. **최적 청크 선택**:\n   ```cpp\n   minimum_to_decode_with_cost(want_to_read, available, &minimum);\n   ```\n   - `want_to_read`: 필요한 청크 ID 집합\n   - `available`: 가용한 청크와 접근 비용 맵\n   - `minimum`: 최소 비용으로 복구 가능한 청크 집합\n\n3. **청크 병렬 요청**: 필요한 모든 청크를 병렬로 요청 (데이터 청크 + 필요한 코딩 청크)\n\n## 3. 데이터 복원 단계\n1. **모든 데이터 청크 가용 시**: \n   - 단순히 필요한 데이터 청크를 연결하여 원본 데이터 구성\n   - 예: K=4인 경우, 4개 데이터 청크 연결\n\n2. **일부 데이터 청크 누락 시**:\n   - `decode()` 메서드 호출로 복원 시작\n   ```cpp\n   decode(want_to_read, chunks, &decoded, chunk_size);\n   ```\n\n3. **복호화 과정**:\n   - 이레이저 코딩 알고리즘 사용하여 누락된 청크 복원\n   - 각 구현별 복호화 방식 차이:\n     - **Jerasure**: Reed-Solomon 기반 행렬 연산으로 복원\n     - **LRC**: 로컬/글로벌 패리티 활용 복원\n     - **ISA**: Intel ISA-L 최적화 라이브러리 사용\n     - **CLAY**: 계층적 복원 방식\n\n4. **하위 청크(Sub-chunk) 처리**:\n   - 일부 구현은 청크를 더 작은 하위 청크로 분할\n   - 필요한 하위 청크만 복원하여 효율성 증가\n\n## 4. 응답 처리 단계\n1. **데이터 재구성**:\n   - 복원된 청크들에서 요청된 데이터 부분 추출\n   - 청크 오프셋 계산: `byte_offset = B % chunk_size`\n   - 청크 인덱스 계산: `chunk_index = B / chunk_size`\n\n2. **버퍼 생성 및 반환**:\n   - 복원된 데이터를 단일 버퍼로 연결\n   - 패딩 제거 (마지막 청크에 추가된 패딩)\n   ```cpp\n   decode_concat(want_to_read, chunks, &decoded);\n   ```\n\n3. **클라이언트 응답**:\n   - 재구성된 원본 데이터를 클라이언트에 반환\n\n## 5. 청크 캐싱 및 최적화\n1. **읽기 캐싱**: 자주 접근하는 청크는 메모리에 캐싱\n2. **부분 읽기**: 필요한 부분만 복원 (전체 객체가 필요 없는 경우)\n3. **지연 복구**: 읽기 요청이 없는 손실 청크는 즉시 복구하지 않고 지연\n\n## 성능 고려사항\n1. **복구 비용**: M(코딩 청크 수)이 클수록 저장 효율성 증가, 복구 비용 증가\n2. **네트워크 트래픽**: 복구 시 필요한 데이터 전송량 (특히 CLAY 알고리즘에서 최적화)\n3. **디코딩 계산 비용**: 알고리즘별 CPU 사용량과 지연 시간 차이",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 2,
    "wordCount": 370,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "ceph-erasure-coding-데이터-저장-흐름",
    "slug": "ceph-erasure-coding-deiteo-jeojang-heureum",
    "path": "distributed-systems/ceph",
    "fullPath": "distributed-systems/ceph/ceph-erasure-coding-deiteo-jeojang-heureum",
    "title": "Ceph Erasure Coding 데이터 저장 흐름",
    "excerpt": "Ceph Erasure Coding 데이터 저장 흐름 클라이언트 쓰기 요청 단계 객체 쓰기 요청: 클라이언트가 특정 풀에 데이터 쓰기 요청 PG(Placement Group) 결정: 객체 ID를 해시하여 속할 PG 계산 3....",
    "content": "# Ceph Erasure Coding 데이터 저장 흐름\n\n## 1. 클라이언트 쓰기 요청 단계\n1. **객체 쓰기 요청**: 클라이언트가 특정 풀에 데이터 쓰기 요청\n2. **PG(Placement Group) 결정**: 객체 ID를 해시하여 속할 PG 계산\n3. **주 OSD 선택**: 해당 PG의 주(Primary) OSD로 쓰기 요청 전달\n\n## 2. 데이터 인코딩 단계\n1. **청크 크기 계산**:\n   - 객체 크기를 데이터 청크 수(K)로 나누어 각 청크 크기 결정\n   - 필요시 마지막 청크 패딩 추가\n\n2. **인코딩 요청**:\n   ```cpp\n   encode(want_to_encode, in, &encoded);\n   ```\n   - `want_to_encode`: 인코딩할 청크 ID 집합 (일반적으로 모든 K+M 청크)\n   - `in`: 원본 데이터 버퍼\n   - `encoded`: 인코딩된 청크들을 담을 맵\n\n3. **데이터 분할**:\n   - 원본 데이터를 K개의 데이터 청크로 분할\n   - 예: 12KB 데이터, K=4인 경우 각 3KB 청크로 분할\n\n4. **코딩 청크 생성**:\n   - 선택된 이레이저 코딩 알고리즘 실행\n   - 데이터 청크로부터 M개의 코딩 청크 계산\n   - 구현별 계산 방식:\n     - **Jerasure**: Reed-Solomon 행렬 연산\n     - **LRC**: 로컬/글로벌 패리티 계산\n     - **ISA**: 인텔 최적화 라이브러리 사용\n     - **CLAY**: 계층적 인코딩 방식\n\n## 3. 청크 배치 과정\n1. **CRUSH 계산**:\n   - 각 청크의 저장 위치 결정을 위해 CRUSH 알고리즘 실행\n   - 실패 도메인 고려 (예: 다른 호스트에 청크 배치)\n\n2. **배치 규칙 적용**:\n   ```cpp\n   int rule_id = crush.get_rule_id(rule_name);\n   crush.do_rule(rule_id, x, out, placement_count, weights);\n   ```\n   - 생성된 K+M개 청크를 서로 다른 OSD에 배치\n   - 청크 매핑 정보 저장 (각 청크가 어떤 OSD에 있는지)\n\n3. **청크 인덱스 관리**:\n   - `chunk_mapping` 벡터에 청크 인덱스와 실제 OSD 매핑 저장\n   - 이후 데이터 조회 시 이 매핑 정보 사용\n\n## 4. 청크 저장 과정\n1. **병렬 쓰기 작업**:\n   - 각 청크를 해당 OSD에 병렬로 쓰기 요청\n   - 데이터 청크(K개)와 코딩 청크(M개) 모두 저장\n\n2. **원자적 쓰기 보장**:\n   - 모든 청크가 성공적으로 쓰여질 때까지 대기\n   - 일부 실패 시 롤백 메커니즘 활성화\n\n3. **메타데이터 업데이트**:\n   - 객체 속성, 크기, 청크 위치 등 메타데이터 업데이트\n   - OMAP(Object Map)에 추가 속성 저장 가능\n\n## 5. 완료 및 확인 단계\n1. **쿼럼 확인**:\n   - 필요한 최소 수의 OSD가 쓰기 완료 확인\n   - 일반적으로 (K+M)/2 + 1 개의 확인 필요\n\n2. **클라이언트 응답**:\n   - 쓰기 완료 확인 메시지를 클라이언트에 반환\n\n3. **백그라운드 복제**:\n   - 일부 OSD 쓰기 실패 시 백그라운드에서 복제 시도\n   - 자가 복구 메커니즘 시작\n\n## 6. 최적화 기법\n1. **청크 버퍼링**: 작은 쓰기 작업을 버퍼링하여 일괄 처리\n2. **스트라이핑**: 대용량 객체를 여러 스트라이프로 나누어 저장\n3. **비동기 쓰기**: 성능 향상을 위한 비동기 쓰기 작업\n4. **로컬 패리티**: LRC 코드에서 로컬 패리티로 쓰기 성능 최적화\n\n## 7. 저장 효율성\n- **저장 효율**: `(K/(K+M)) * 100%`\n- 예: K=8, M=4 구성에서 저장 효율은 66.7%\n- 일반 복제(replication) 대비 저장 공간 절약 (3x 복제는 33.3% 효율)",
    "docType": "original",
    "category": "Distributed Systems",
    "tags": [],
    "readingTime": 3,
    "wordCount": 427,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "redis-기반-분산-락-가이드",
    "slug": "redis-giban-bunsan-rag-gaideu",
    "path": "database/redis",
    "fullPath": "database/redis/redis-giban-bunsan-rag-gaideu",
    "title": "Redis 기반 분산 락 가이드",
    "excerpt": "분산 시스템에서 Redis를 활용한 분산 락 구현 방법과 Redlock 알고리즘을 알아봅니다.",
    "content": "# Redis 기반 분산 락 가이드\n\n## 개요\n\n분산 시스템에서 여러 노드나 프로세스가 공유 자원에 동시에 접근하는 것을 제어하기 위해 **분산 락(Distributed Lock)**이 필요합니다. Redis는 빠르고 간단한 방식으로 분산 락을 구현할 수 있는 인메모리 저장소로 자주 사용됩니다.\n\n## 기본 개념\n\n- **분산 락**은 여러 프로세스 간 자원 접근을 조율하는 도구\n- Redis는 단일 키의 원자적 조작이 가능하므로 분산 락에 적합\n- 락은 일정 시간 동안만 유효해야 하며, 적절한 TTL 설정이 중요\n\n---\n\n## 기본 구현 방식 (SET NX PX)\n\n### 락 획득\n\n```bash\nSET lock_key unique_value NX PX 3000\n```\n\n| 옵션 | 설명 |\n|-----|------|\n| `NX` | 키가 존재하지 않을 때만 설정 |\n| `PX 3000` | TTL을 3초(3000ms)로 설정 |\n| `unique_value` | 락 주체를 식별하기 위한 UUID |\n\n### 락 해제 (Lua 스크립트)\n\n```lua\n-- 자신이 획득한 락만 해제\nif redis.call(\"GET\", KEYS[1]) == ARGV[1] then\n  return redis.call(\"DEL\", KEYS[1])\nelse\n  return 0\nend\n```\n\n> GET과 DEL을 **원자적**으로 처리하여 다른 프로세스의 락을 실수로 해제하는 것을 방지합니다.\n\n### 주의사항\n\n- 반드시 TTL(만료 시간)을 설정할 것\n- 락을 획득한 주체만 해제할 것\n- Redis 장애 시 락 상태 유실 가능\n\n---\n\n## Redlock 알고리즘 (고가용성)\n\n**Redlock**은 Redis 창시자 Salvatore Sanfilippo가 제안한 고가용성 분산 락 알고리즘입니다.\n\n### 동작 원리\n\n1. 현재 시간을 기록\n2. N개의 Redis 인스턴스에 동시에 락 요청 (`SET NX PX`)\n3. 과반수(N/2 + 1) 이상 성공 시 락 획득\n4. 전체 소요 시간 < TTL일 경우에만 유효\n5. 실패 시 모든 인스턴스에 락 해제\n\n### 장단점\n\n| 장점 | 단점 |\n|-----|------|\n| 단일 노드 장애에 강함 | 구현이 복잡함 |\n| 락 일관성 유지 | 네트워크 지연에 민감 |\n| | 완전한 안전성 보장 불가 (논쟁 있음) |\n\n---\n\n## 사용 권장/비권장\n\n### ✅ 추천 사용처\n\n- 크론잡 중복 실행 방지\n- 공유 리소스 접근 제어\n- 분산 환경 사전 동기화\n\n### ❌ 비권장 사용처\n\n- 강력한 트랜잭션이 필요한 금융 거래\n- 네트워크/시계 오류에 민감한 시스템\n\n---\n\n## 참고 자료\n\n- [Redis 공식 문서: Distributed Locks](https://redis.io/docs/manual/patterns/distributed-locks/)\n- [Redlock Algorithm](https://redis.io/docs/interact/locking/)\n- [Martin Kleppmann의 Redlock 비판](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)",
    "docType": "original",
    "category": "Database",
    "tags": [
      "Redis",
      "Distributed Systems",
      "Concurrency"
    ],
    "readingTime": 2,
    "wordCount": 329,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "aws-elasticache-for-redis-oss-샤딩과-마스터-failover-정리",
    "slug": "aws-elasticache-for-redis-oss-syadinggwa-maseuteo-failover-jeongri",
    "path": "database/redis",
    "fullPath": "database/redis/aws-elasticache-for-redis-oss-syadinggwa-maseuteo-failover-jeongri",
    "title": "AWS ElastiCache for Redis (OSS) - 샤딩과 마스터 Failover 정리",
    "excerpt": "AWS ElastiCache for Redis (OSS) - 샤딩과 마스터 Failover 정리 📌 핵심 개념 요약 Redis Cluster 모드에서는 데이터를 샤딩하여 여러 마스터...",
    "content": "# AWS ElastiCache for Redis (OSS) - 샤딩과 마스터 Failover 정리\n\n![[Pasted image 20250328100819.png]]\n\n## 📌 핵심 개념 요약\n\n- Redis Cluster 모드에서는 데이터를 샤딩하여 여러 마스터 노드에 분산 저장할 수 있다.\n- 그러나 **하나의 키는 반드시 하나의 마스터 노드만이 관리**한다.\n- 이 구조에서 **마스터 노드의 장애(Failover)** 발생 시, 리플리카를 자동 승격시켜 서비스를 지속할 수 있도록 한다.\n\n---\n\n## 🧱 샤딩 구조\n\n### 🔹 해시 슬롯 기반 샤딩\n\n- Redis Cluster는 키를 **0 ~ 16383 해시 슬롯** 중 하나에 매핑한다.\n- 각 해시 슬롯은 **하나의 샤드(= 마스터 노드)** 가 담당한다.\n- 샤드 수가 늘어나면 슬롯이 분산되며, 각 샤드는 자신이 맡은 슬롯 범위의 키만 관리한다.\n\n### 🔹 키 관리\n\n- 하나의 키는 하나의 해시 슬롯에 매핑되므로,\n- **동일한 키에 대해 동시에 여러 마스터가 접근하는 일은 없음**.\n\n---\n\n## 🔁 마스터 노드 Failover 처리\n\n### 🔹 리플리카 구성\n\n- ElastiCache는 **각 마스터 노드에 대해 하나 이상의 리플리카 노드(replica)를 구성**할 수 있도록 지원한다.\n- 리플리카는 마스터의 데이터를 비동기 복제한다.\n\n### 🔹 Failover 시나리오\n\n1. 마스터 노드에 장애 발생\n2. ElastiCache 감시 시스템이 자동 감지\n3. 해당 샤드의 리플리카 노드 중 하나를 **자동으로 마스터로 승격(promote)**\n4. 클러스터 메타데이터가 갱신됨\n5. 클라이언트는 재접속 시 **MOVED 리다이렉션 응답**을 통해 새 마스터에 연결됨\n\n### 🔹 구성 예시\n\n샤드 1: 마스터 A <–> 리플리카 A’\n\n샤드 2: 마스터 B <–> 리플리카 B’\n\n샤드 3: 마스터 C <–> 리플리카 C’\n\n- 마스터 B가 죽으면 → 리플리카 B'가 새 마스터로 승격\n\n---\n\n## ⚠️ 주의사항\n\n- Redis의 복제는 **비동기(asynchronous)** 이므로, 장애 발생 시 **일부 데이터 손실 가능성**이 존재한다.\n- 강력한 데이터 정합성이 요구되는 경우, 사용 시점 및 구조를 신중하게 설계해야 한다.\n- **리플리카가 없으면 Failover가 불가능**하므로, 최소한 샤드당 1개의 리플리카 구성이 권장된다.\n\n---\n\n## ✅ 모범 구성\n\n- **Multi-AZ 배포**로 장애 도메인 분리\n- 각 샤드에 **1개 이상의 리플리카 구성**\n- 클라이언트 라이브러리는 `Cluster-aware` 모드 사용 (예: `lettuce`, `Jedis`, `ioredis` 등)\n\n---\n\n## 📚 참고 자료\n\n- [AWS 공식 문서 - ElastiCache에서 클러스터 관리](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/dg/Clusters.html)\n-",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 2,
    "wordCount": 316,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "which-is-best-isolation-level-for-a-common-situation",
    "slug": "which-is-best-isolation-level-for-a-common-situation",
    "path": "database/mysql",
    "fullPath": "database/mysql/which-is-best-isolation-level-for-a-common-situation",
    "title": "Which is best isolation level for a common situation",
    "excerpt": "Which is best isolation level for a common situation MySQL은 데이터베이스 엔진이 동시 트랜잭션을 처리하는 방법을 정의하는 여러 분리 수준을 지원합니다. 일반적인 상황에 가장 적합한 옵션은 응용프로그램의 특정 요구사항에...",
    "content": "# Which is best isolation level for a common situation\n\nMySQL은 데이터베이스 엔진이 동시 트랜잭션을 처리하는 방법을 정의하는 여러 분리 수준을 지원합니다. 일반적인 상황에 가장 적합한 옵션은 응용프로그램의 특정 요구사항에 따라 달라집니다.\n\n일반적으로 REPEATABLE READ 분리 수준은 일관성과 성능 사이에서 균형을 맞추기 때문에 대부분의 응용 프로그램에 적합한 기본 옵션입니다. 그러나 응용프로그램에 더 높은 수준의 일관성이 필요한 경우에는 직렬화를 사용하는 것을 고려할 수 있습니다. 일관성보다 성능을 우선시해야 하는 경우 READ COMMITED 또는 READ UNCOMMITED를 사용하는 것을 고려할 수 있지만 잠재적인 위험과 절충점을 알고 있어야 합니다.\n\n## ISOLATION LEVELS\n\n- READ UNCOMMITTED: 이 격리 수준은 더티 읽기를 허용하며, 이는 트랜잭션이 다른 트랜잭션에 의해 커밋되지 않은 변경 사항을 읽을 수 있음을 의미합니다. 데이터가 일관되지 않을 수 있으므로 대부분의 응용 프로그램에는 권장되지 않습니다.\n\n- READ COMMITTED: 이 격리 수준을 통해 트랜잭션은 커밋된 데이터만 읽을 수 있으므로 더티 읽기를 방지할 수 있습니다. 그러나 다른 트랜잭션이 읽기 간에 변경 사항을 커밋할 수 있기 때문에 계속해서 반복할 수 없는 읽기 및 팬텀 읽기가 발생할 수 있습니다.\n\n- REPEATABLE READ: 이 격리 수준을 사용하면 다른 트랜잭션이 변경되더라도 트랜잭션이 데이터베이스의 일관된 스냅샷을 볼 수 있습니다. 반복할 수 없는 읽기 및 팬텀 읽기를 방지하지만 새 데이터를 트랜잭션에 삽입할 수 있는 작은 창을 허용합니다.\n\n- SERIALIZABLE: 이 분리 수준은 트랜잭션이 완료될 때까지 트랜잭션이 액세스하는 모든 행을 잠궈 최고 수준의 분리를 제공합니다. 이렇게 하면 모든 형태의 동시성 관련 이상 징후를 방지할 수 있지만 동시성 및 성능이 저하될 수도 있습니다.\n\n## REPEATABLE READ의 한계점\n\nMySQL의 REPEATABLE READ 격리 수준은 강력한 수준의 일관성을 제공하지만 애플리케이션의 성능과 기능에 영향을 미칠 수 있는 몇 가지 제한 사항도 있습니다. 다음은 반복 가능한 읽기 분리 수준의 몇 가지 제한 사항입니다:\n\n1. 동시성이 감소: 반복 가능 읽기 분리 수준은 트랜잭션이 완료될 때까지 트랜잭션이 액세스하는 모든 행을 잠급니다. 이로 인해 다른 트랜잭션은 잠긴 행이 해제될 때까지 기다려야 하므로 동시성이 저하될 수 있습니다.\n\n2. 리소스 사용량 증가: 더 많은 잠금을 획득하고 해제해야 하기 때문에 REPEATABLE READ 격리 수준의 잠금 동작은 리소스 사용 증가로 이어질 수도 있습니다.\n\n3. 일관되지 않은 읽기: REPEATABLE READ 분리 수준은 트랜잭션이 데이터베이스의 일관된 스냅샷을 볼 수 있도록 보장하지만, 격리 레벨에서는 여전히 Phantom Read라고 알려진 작은 불일치 창이 허용됩니다. 이 문제는 다른 트랜잭션이 동일한 트랜잭션 내의 첫 번째 쿼리 실행과 두 번째 쿼리 실행 사이에 첫 번째 트랜잭션에 의해 실행된 쿼리의 기준과 일치하는 새 데이터를 삽입할 때 발생할 수 있습니다.\n   예를 들어 다음 두 가지 쿼리를 실행하는 트랜잭션을 생각해 보십시오:\n\n   ```sql\n   SELECT * FROM orders WHERE status = 'processing';\n   -- Some time passes, during which another transaction inserts a new order with status 'processing'\n   SELECT * FROM orders WHERE status = 'processing';\n   ```\n\n   트랜잭션이 REPEATABLE READ에서 실행 중인 경우, 새 주문이 그 사이에 삽입된 경우에도 두 번 모두 동일한 주문 집합을 읽습니다. 데이터베이스의 실제 상태를 반영하지 않을 수 있기 때문에 트랜잭션에서 읽은 데이터에 불일치가 발생할 수 있습니다.\n\n   이 문제를 완화하려면 응용프로그램의 일관성을 보장하기 위해 잠금 또는 낙관적 동시성 제어와 같은 추가 메커니즘을 구현해야 할 수 있습니다. 또한 특정 실행 순서에 의존하지 않도록 쿼리 및 응용 프로그램 로직을 신중하게 설계하거나, 강력한 일관성이 필요한 경우 SERIALIZABLE와 같은 다른 분리 수준을 사용하는 것을 고려해야 할 수도 있습니다.\n\n4. 교착 상태(Deadlocks): 반복 가능한 읽기 격리 수준은 둘 이상의 트랜잭션이 잠긴 리소스를 해제하기 위해 서로 대기하는 교착 상태로 이어질 수도 있습니다.\n\n   이러한 제한을 완화하려면, 교착 상태의 가능성을 최소화하고 필요한 잠금 양을 줄이기 위해 응용프로그램 및 데이터베이스 스키마를 신중하게 설계해야 할 수 있습니다. 또한 응용프로그램의 특정 요구사항 및 성능 특성에 따라 READ COMMITTED 또는 SERIALIZABLE와 같은 다른 분리 수준을 사용하는 것을 고려해야 할 수도 있습니다.",
    "docType": "original",
    "category": "Database",
    "tags": [],
    "readingTime": 3,
    "wordCount": 562,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "mysql-트랜잭션-쿼리-예시",
    "slug": "mysql-teuraenjaegsyeon-kweori-yesi",
    "path": "database/mysql",
    "fullPath": "database/mysql/mysql-teuraenjaegsyeon-kweori-yesi",
    "title": "MySQL 트랜잭션 쿼리 예시 ",
    "excerpt": "MySQL 트랜잭션 쿼리 예시 ```mysql START TRANSACTION; SAVEPOINT A; INSERT INTO user(username, password, salt) VALUES ('testuser', 'testpassword',...",
    "content": "# MySQL 트랜잭션 쿼리 예시 \n\n```mysql\nSTART TRANSACTION;  \n  \nSAVEPOINT A;  \nINSERT INTO user(username, password, salt)  \nVALUES ('testuser', 'testpassword', 'testsalt');  \n  \nSAVEPOINT B;  \nINSERT INTO user(username, password, salt)  \nVALUES ('testuser1', 'testpassword1', 'testsalt1');  \n  \n# B 쿼리 이전, 즉 A - B 사이의 WRITE만 유효  \nROLLBACK TO SAVEPOINT B;  \n  \n# 전체 취소  \n# ROLLBACK;  \n  \n# 전체 적용  \n# COMMIT;\n```",
    "docType": "original",
    "category": "Database",
    "tags": [],
    "readingTime": 1,
    "wordCount": 58,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "upsert-vs-unique-key-constraint",
    "slug": "upsert-vs-unique-key-constraint",
    "path": "database/concepts",
    "fullPath": "database/concepts/upsert-vs-unique-key-constraint",
    "title": "대량 데이터 처리 시 Upsert 패턴 활용법",
    "excerpt": "대량 데이터 인덱싱 작업에서 INSERT와 Upsert 패턴을 비교하고, 효율적인 배치 처리 방법을 알아봅니다.",
    "content": "# 대량 데이터 처리 시 Upsert 패턴 활용법\n\n## Upsert란?\n\nUpsert는 \"Update + Insert\"의 합성어로, 레코드가 존재하면 업데이트하고 없으면 삽입하는 원자적 연산입니다.\n\n### DB별 Upsert 문법\n\n**PostgreSQL**\n\n```sql\nINSERT INTO users (id, name, email)\nVALUES (1, 'Kim', 'kim@example.com')\nON CONFLICT (id) DO UPDATE SET\n  name = EXCLUDED.name,\n  email = EXCLUDED.email;\n```\n\n**MySQL**\n\n```sql\nINSERT INTO users (id, name, email)\nVALUES (1, 'Kim', 'kim@example.com')\nON DUPLICATE KEY UPDATE\n  name = VALUES(name),\n  email = VALUES(email);\n```\n\n## 왜 Upsert가 더 효율적인가?\n\n### 기존 방식의 문제점\n\n```sql\n-- 비효율적인 방식: SELECT 후 INSERT/UPDATE\nSELECT * FROM users WHERE id = 1;\n-- 결과에 따라\nINSERT INTO users ... -- 또는\nUPDATE users SET ... WHERE id = 1;\n```\n\n이 방식은:\n\n1. **2번의 쿼리 실행** (SELECT + INSERT/UPDATE)\n2. **Race Condition 위험** (SELECT와 INSERT 사이에 다른 트랜잭션이 삽입할 수 있음)\n3. **트랜잭션 오버헤드** 증가\n\n### Upsert의 장점\n\n1. **단일 원자적 연산**: DB 엔진이 최적화된 방식으로 처리\n2. **Race Condition 방지**: 동시성 문제 해결\n3. **네트워크 라운드트립 감소**: 한 번의 쿼리로 처리\n\n## 배치 Upsert 패턴\n\n대량 데이터 처리 시 배치 Upsert가 가장 효율적입니다:\n\n**PostgreSQL 배치 Upsert**\n\n```sql\nINSERT INTO transactions (tx_id, amount, status)\nVALUES \n  ('tx_001', 100, 'pending'),\n  ('tx_002', 200, 'confirmed'),\n  ('tx_003', 150, 'pending')\nON CONFLICT (tx_id) DO UPDATE SET\n  amount = EXCLUDED.amount,\n  status = EXCLUDED.status,\n  updated_at = NOW();\n```\n\n## 주의사항\n\n- **인덱스 필수**: Upsert는 고유 제약 조건(UNIQUE) 또는 PK가 있어야 동작\n- **대용량 컬럼**: TEXT/BLOB 등 큰 컬럼이 많으면 UPDATE 비용이 높아질 수 있음\n- **트리거 주의**: INSERT/UPDATE 트리거가 모두 실행될 수 있음\n\n## 결론\n\n대량 데이터 인덱싱 작업에서는 **배치 Upsert 패턴**을 사용하면:\n\n- 쿼리 수 감소\n- 트랜잭션 오버헤드 감소\n- 동시성 문제 해결\n\n로 인해 전체적인 데이터베이스 부하를 크게 줄일 수 있습니다.",
    "docType": "original",
    "category": "Database",
    "tags": [
      "PostgreSQL",
      "MySQL",
      "Database",
      "Performance"
    ],
    "readingTime": 2,
    "wordCount": 283,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "acid",
    "slug": "acid",
    "path": "database/concepts",
    "fullPath": "database/concepts/acid",
    "title": "ACID",
    "excerpt": "ACID 정의 Atomic 트랜잭션의 연산은 모두 정상적으로 실패하거나 모두 실패해야 한다. Consistent 트랜잭션이 성공한 후에 데이터베이스의 제약조건을 포함한 일관성이 지켜져야 한다. Isolation 현재 진행중인...",
    "content": "# ACID\n\n## 정의\n\n- Atomic\n\n  트랜잭션의 연산은 모두 정상적으로 실패하거나 모두 실패해야 한다.\n\n- Consistent\n\n  트랜잭션이 성공한 후에 데이터베이스의 제약조건을 포함한 일관성이 지켜져야 한다.\n\n- Isolation\n\n  현재 진행중인 트랜잭션이 있다면 다른 트랜잭션이 이 트랜잭션에 접근할 수 없다. 각 트랜잭션은 독립적으로 수행되어야 한다.\n\n- Durability\n\n  트랜잭션이 성공되었다면 데이터베이스는 이 결과를 영구적으로 반영해야 한다. 하나라도 손실이 있으면 안된다.\n\n## 더 나아가서\n\nRedis와 함께 데이터베이스 트랜잭션 및 분산 잠금을 사용하는 것은 백엔드에서 동시성 처리의 원자성과 일관성을 보장하는 좋은 방법입니다. 응용프로그램의 특정 요구에 따라 이러한 기술을 적용할 수 있는 추가 방법이 있습니다.\n\n빅테크에서 원자성과 일관성을 보장하는 한 가지 추가적인 방법은 여러 데이터베이스 또는 서비스에 분산 트랜잭션을 사용하는 것입니다. 예를 들어 각 서비스에 자체 데이터베이스가 있는 마이크로서비스 아키텍처가 있는 경우 분산 트랜잭션을 사용하여 특정 트랜잭션과 관련된 모든 서비스가 함께 커밋되거나 롤백되도록 할 수 있습니다.\n\n분산 트랜잭션을 지원하기 위해 2PC(Two-Phase Commit) 프로토콜, X/Open XA 프로토콜, Saga 패턴 등 다양한 도구와 기술을 사용할 수 있습니다. 이러한 기술을 통해 트랜잭션이 완전히 커밋되거나 관련된 모든 서비스에 걸쳐 완전히 롤백되어 시스템이 일관되게 유지됩니다.\n\n그러나 분산 트랜잭션은 구현하기가 복잡하고 성능 오버헤드가 발생할 수 있습니다. 따라서 절충안을 신중하게 고려하고 사용 사례에 필요한지 여부를 결정하는 것이 중요합니다.\n\n분산 트랜잭션 외에도 Big Tech에서 원자성과 일관성을 보장하기 위한 다른 모범 사례로는 데이터 유효성 검사 구현, 최적의 잠금 기술 사용, 정기적인 데이터 백업 및 재해 복구 계획 수행 등이 있습니다. 이러한 모범 사례는 예기치 않은 오류나 오류가 발생한 경우에도 데이터를 일관성 있게 유지하고 사용할 수 있도록 보장하는 데 도움이 됩니다.\n\nUsing database transactions and distributed locks with Redis is a good way to ensure atomicity and consistency in concurrency processing at the backend. There are additional ways to apply these techniques depending on the specific needs of your application.\n\nOne additional way to ensure atomicity and consistency in Big Tech is to use distributed transactions across multiple databases or services. For example, if you have a microservices architecture where each service has its own database, you can use distributed transactions to ensure that all the services involved in a particular transaction either commit or rollback together.\n\nThere are various tools and technologies available to support distributed transactions, such as Two-Phase Commit (2PC) protocol, X/Open XA protocol, and the Saga pattern. These technologies ensure that transactions are either fully committed or fully rolled back across all services involved, ensuring that the system remains consistent.\n\nHowever, it's important to note that distributed transactions can be complex to implement and can introduce performance overhead. Therefore, it's important to carefully consider the trade-offs and determine if they are necessary for your use case.\n\nIn addition to distributed transactions, other best practices to ensure atomicity and consistency in Big Tech include implementing data validation checks, using optimistic locking techniques, and performing regular data backups and disaster recovery planning. These best practices help to ensure that data remains consistent and available even in the face of unexpected failures or errors.\n\n## Ref\n\n- [ACID](https://ko.wikipedia.org/wiki/ACID)",
    "docType": "original",
    "category": "Database",
    "tags": [],
    "readingTime": 3,
    "wordCount": 474,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "2023년",
    "slug": "2023nyeon",
    "path": "daily-notes/2023",
    "fullPath": "daily-notes/2023/2023nyeon",
    "title": "2023년",
    "excerpt": "2023년 느낀점 실무와는 별개로 문제해결력을 키워야겠다는 생각이 들었다. 자바스크립트 실력과 별개로 마크업 지식이 전무해서 사이드 프로젝트 시에 프론트 개발이 불가능해서 아쉬웠다. Typescript로 백엔드를 개발하는 것이 손이 많이 간...",
    "content": "# 2023년\n\n## 느낀점\n\n1. 실무와는 별개로 문제해결력을 키워야겠다는 생각이 들었다.\n2. 자바스크립트 실력과 별개로 마크업 지식이 전무해서 사이드 프로젝트 시에 프론트 개발이 불가능해서 아쉬웠다.\n3. Typescript로 백엔드를 개발하는 것이 손이 많이 간다고 느꼈다.\n\n## 목표\n\n1. Java + Spring + JPA 숙련도를 올려서 회사 신규 프로젝트를 진행한다.\n2. 투박하지만 원하는 모양새의 웹사이트를 개발할 수 있을 정도의 마크업 실력을 키워서 1인 개발이 가능하게 된다.\n3. 다양한 자료구조와 알고리즘 학습을 통해 실무에서의 문제해결력을 키운다\n4. 이렇게 하고 나서는 무엇이 부족하다고 느낄지 알아본다\n\n## 인프런\n\n- 완료목표시점: 2023년 7월 말\n\n| 기간              | 제목                                       | 완료  | 총 교육 시간  |\n|-----------------|------------------------------------------|-----|----------|\n| 2022.02~2022.02 | 스프링 입문 - 코드로 배우는 스프링 부트, 웹 MVC, DB 접근 기술 | O   | 5시간 21분  |\n| 2022.02~2023.03 | 스프링 핵심 원리 - 기본편                          | O   | 12시간 5분  |\n| 2021.12~2023.03 | 모든 개발자를 위한 HTTP 웹 기본 지식                  | O   | 5시간 40분  |\n| 2023.03~2023.03 | 스프링 MVC 1편 - 백엔드 웹 개발 핵심 기술              | 진행중 | 15시간 22분 |\n|                 | 스프링 MVC 2편 - 백엔드 웹 개발 활용 기술              | X   ||\n|                 | 스프링 DB 1편 - 데이터 접근 핵심 원리                 | X   ||\n|                 | 스프링 DB 1편 - 데이터 접근 활용 기술                 | X   ||\n|                 | 스프링 핵심 원리 - 고급편                          | X   ||\n|                 | 스프링 부트 - 핵심 원리와 활용                       | X   ||\n|                 | 자바 ORM 표준 JPA 프로그래밍 - 기본편                | X   ||\n|                 | 실전! 스프링 부트와 JPA 활용1 - 웹 애플리케이션 개발        | X   ||\n|                 | 실전! 스프링 부트와 JPA 활용2 - API 개발과 성능 최적화     | X   ||\n|                 | 실전! 스프링 데이터 JPA                          | X   ||\n|                 | 실전! Querydsl                             | X   ||\n|                 | 제대로 파는 HTML CSS - by 얄코                  | X   ||\n\n## 책\n\n| 기간      | 제목                                 | 완료  |\n|---------|------------------------------------|-----|\n| 2023-03 | 구글 엔지니어는 이렇게 일한다                   | O   |\n| 2023-04 | 262가지 문제로 정복하는 코딩 인터뷰 in Java      | X   |\n| 2023-05 | 한 권으로 읽는 컴퓨터 구조와 프로그래밍             | X   |\n| 2023-06 | 알고리즘 문제해결 전략 1권                    | X   |\n| 2023-07 | 알고리즘 문제해결 전략 2권                    | X   |\n| 2023-08 | Test Driven Development By Example | X   |\n| 2023-09 | 단위 테스트                             | X   |\n| 2023-10 | 오브젝트                               | X   |\n| 2023-11 | 객체지향의 사실과 오해                       | X   |\n| 2023-12 | 헤드 퍼스트 디자인 패턴                      | X   |\n\n### 추가로 볼 책들\n\n1. 데이터 중심 애플리케이션 설계\n2. Code Complete\n3. Pro Spring 5\n4. 이펙티브 자바\n5. Real MySQL\n6. 엔터프라이즈 애플리케이션 아키텍쳐 패턴\n7. 클린 코드\n8. 클린 아키텍쳐\n9. 프로그래밍 러스트\n10. 동시성 프로그래밍 *Rust, C, 어셈블리어로 구현하며 배우는 동시성 프로그래밍 A to Z*",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 3,
    "wordCount": 459,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "solana-sol",
    "slug": "solana-sol",
    "path": "blockchain/solana",
    "fullPath": "blockchain/solana/solana-sol",
    "title": "Solana (SOL)",
    "excerpt": "Solana (SOL) 💡 Cheatsheet of SOL for web3 developers. 요약 중앙화를 벗어나지 못함. 재단에서 네트워크를 껐다 켰다 할 수 있음 노드가 엄청 잘 죽음 (올해만 몇 번 중지...",
    "content": "# Solana (SOL)\n\n<aside>\n💡 Cheatsheet of SOL for web3 developers.\n\n</aside>\n\n# 요약\n\n1. 중앙화를 벗어나지 못함. 재단에서 네트워크를 껐다 켰다 할 수 있음\n2. 노드가 엄청 잘 죽음 (올해만 몇 번 중지되었는지..)\n3. 솔라나와 솔라나 프로그램(컨트랙트) 개발언어가 통일되어 있다는게 매우 매력포인트\n4. 재단에서 제공하는 툴들이 너무 환상적임. 아이디어만 있다면 대충 시작할 수 있을 정도\n5. 이것도 mempool이 없음\n\n# How to create and manage address or account?\n\n### Using Private Key\n\n```jsx\nconst account = Keypair.generate()\nconsole.log(JSON.stringify(account.publicKey.toBase58()))\n// output: \"gVazpxjimX3EP4mto53pEi4YSE36KP2nDwyEvLcKjmR\"\n```\n\n### Using Mnemonic\n\n```jsx\nconst mnemonic =\n\t'pill tomorrow foster begin walnut borrow virtual kick shift mutual shoe scatter'\nconst seed = bip39.mnemonicToSeedSync(mnemonic, '') // (mnemonic, password)\n\n// BIP39\nconst keypair = Keypair.fromSeed(seed.slice(0, 32))\n\n// BIP44\nfor (let i = 0; i < 10; i++) {\n\tconst path = `m/44'/501'/${i}'/0'`\n\tconst keypair = Keypair.fromSeed(derivePath(path, seed.toString('hex')).key)\n\tconsole.log(`${path} => ${keypair.publicKey.toBase58()}`)\n}\n\n// Check if a given public key has an associated private key\nconst key = new PublicKey('5oNDL3swdJJF1g9DzJiZ4ynHXgszjAEpUkxVYejchzrY')\nconsole.log(PublicKey.isOnCurve(key.toBytes()))\n```\n\n# How to sign and verify messages with wallets\n\n```jsx\nconst message = \"The quick brown fox jumps over the lazy dog\";\nconst messageBytes = decodeUTF8(message);\n\nconst signature = nacl.sign.detached(messageBytes, keypair.secretKey);\nconst result = nacl.sign.detached.verify(\n  messageBytes,\n  signature,\n  keypair.publicKey.toBytes()\n);\n\nconsole.log(result);\n\n-------------------------------------------------------------------------------\n\n{\n  let recoverTx = Transaction.populate(Message.from(realDataNeedToSign));\n  recoverTx.addSignature(feePayer.publicKey, Buffer.from(feePayerSignature));\n  recoverTx.addSignature(alice.publicKey, Buffer.from(aliceSignature));\n\n  console.log(\n    `txhash: ${await connection.sendRawTransaction(recoverTx.serialize())}`\n  );\n}\n\n-------------------------------------------------------------------------------\n\n{\n  let recoverTx = Transaction.populate(Message.from(realDataNeedToSign), [\n    bs58.encode(feePayerSignature),\n    bs58.encode(aliceSignature),\n  ]);\n  console.log(\n    `txhash: ${await connection.sendRawTransaction(recoverTx.serialize())}`\n  );\n}\n```\n\n# How to query balance of address on blockchain?\n\n# How to query transaction?\n\n# How to add a memo to a tx?\n\n```jsx\nconst transferTransaction = new Transaction().add(\n\tSystemProgram.transfer({\n\t\tfromPubkey: fromKeypair.publicKey,\n\t\ttoPubkey: toKeypair.publicKey,\n\t\tlamports: lamportsToSend,\n\t}),\n)\n\nawait transferTransaction.add(\n\tnew TransactionInstruction({\n\t\tkeys: [\n\t\t\t{ pubkey: fromKeypair.publicKey, isSigner: true, isWritable: true },\n\t\t],\n\t\tdata: Buffer.from('Data to send in transaction', 'utf-8'),\n\t\tprogramId: new PublicKey('MemoSq4gqABAXKb96qnH8TysNcWxMyWCqXgDLGmfcHr'),\n\t}),\n)\n\nawait sendAndConfirmTransaction(connection, transferTransaction, [fromKeypair])\n```\n\n# How to estimate fee?\n\n```jsx\ngetEstimatedFee\nconst recentBlockhash = await connection.getLatestBlockhash()\nconst transaction = new Transaction({\n\trecentBlockhash: recentBlockhash.blockhash,\n}).add(\n\tSystemProgram.transfer({\n\t\tfromPubkey: payer.publicKey,\n\t\ttoPubkey: payee.publicKey,\n\t\tlamports: 10,\n\t}),\n)\n\nconst fees = await transaction.getEstimatedFee(connection)\nconsole.log(`Estimated SOL transfer cost: ${fees} lamports`)\n// Estimated SOL transfer cost: 5000 lamports\n\n// getFeeForMessage\nconst message = new Message(messageParams)\n\nconst fees = await connection.getFeeForMessage(message)\nconsole.log(`Estimated SOL transfer cost: ${fees.value} lamports`)\n// Estimated SOL transfer cost: 5000 lamports\n```\n\n# How to Transfer tokens one to another?\n\n```jsx\n// Send SOL\nconst transferTransaction = new Transaction().add(\n\tSystemProgram.transfer({\n\t\tfromPubkey: fromKeypair.publicKey,\n\t\ttoPubkey: toKeypair.publicKey,\n\t\tlamports: lamportsToSend,\n\t}),\n)\n\nawait sendAndConfirmTransaction(connection, transferTransaction, [fromKeypair])\n\n// Send SPL Token\n// Add token transfer instructions to transaction\nconst transaction = new web3.Transaction().add(\n\tsplToken.Token.createTransferInstruction(\n\t\tsplToken.TOKEN_PROGRAM_ID,\n\t\tfromTokenAccount.address,\n\t\ttoTokenAccount.address,\n\t\tfromWallet.publicKey,\n\t\t[],\n\t\t1,\n\t),\n)\n\n// Sign transaction, broadcast, and confirm\nawait web3.sendAndConfirmTransaction(connection, transaction, [fromWallet])\n```\n\n---\n\n## Build Frontend and deploy contract to Solana devnet\n\nI using rust, anchor to develop smart contract. All I have to do is initializing some struct, and add methods in main program module. It’s quite easy to understand, and I think it’s simillar with creating and using gRPC.\n\n![](/images/solanademo.png)\nScreenshot of Demo project (thx to https://buildspace.so)",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 3,
    "wordCount": 501,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "tezos-xtz",
    "slug": "tezos-xtz",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/tezos-xtz",
    "title": "Tezos (XTZ)",
    "excerpt": "Tezos (XTZ) 💡 Cheatsheet of XTZ for web3 developers. 요약 노드에 좀만 요청보내도 헐떡대다가 죽음 최소 잔고 맞춰줘야 함 라이브러리 편하게 잘되어 있긴 한데 노드 개...",
    "content": "# Tezos (XTZ)\n\n<aside>\n💡 Cheatsheet of XTZ for web3 developers.\n\n</aside>\n\n# 요약\n\n1. 노드에 좀만 요청보내도 헐떡대다가 죽음\n2. 최소 잔고 맞춰줘야 함\n3. 라이브러리 편하게 잘되어 있긴 한데 노드 개발을 Ocaml으로 해놔서 깊은 디버깅시에 제약이 있음\n4. 커뮤니티가 작아서 솔직히 자료 나오는게 뭐 없음",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 48,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "stellar-lumens-xlm",
    "slug": "stellar-lumens-xlm",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/stellar-lumens-xlm",
    "title": "Stellar Lumens (XLM)",
    "excerpt": "Stellar Lumens (XLM) 💡 Cheatsheet of XLM for web3 developers. 요약 리플 v2 protobuf같은 프로토콜인 xdr을 사용하는 특이사항이 있음 트랜잭션...",
    "content": "# Stellar Lumens (XLM)\n\n<aside> 💡 Cheatsheet of XLM for web3 developers.\n\n</aside>\n\n# 요약\n\n1.  리플 v2\n2.  protobuf같은 프로토콜인 xdr을 사용하는 특이사항이 있음\n3.  트랜잭션 전파시에 가스 부족하면 타임아웃 남\n4.  트랜잭션 전파시에 mempool 없어서 재시도 하기 귀찮음\n5.  SDK 통해서 txHash 편하게 계산할 수 있기 때문에 찾아보면 좋음\n6.  주소 로컬에서 만든다고 네트웍에서 조회 안됨. 한번은 tx 생성을 통해서 노출해줘야함",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 65,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "ripple-xrp",
    "slug": "ripple-xrp",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/ripple-xrp",
    "title": "Ripple (XRP)",
    "excerpt": "Ripple (XRP) 💡 Cheatsheet of XRP for web3 developers. 요약 국제 송금망을 타겟으로 한 블록체인 속도를 위해서 탈중앙을 포기한 사례 개발자 도구나 커뮤니티가 훌...",
    "content": "# Ripple (XRP)\n\n<aside> 💡 Cheatsheet of XRP for web3 developers.\n\n</aside>\n\n# 요약\n\n1.  국제 송금망을 타겟으로 한 블록체인\n2.  속도를 위해서 탈중앙을 포기한 사례\n3.  개발자 도구나 커뮤니티가 훌륭함\n4.  리플과 Issuedtoken 갯수에 맞춰서 최소 잔고 들고 있어야함",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 41,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "istanbul-byzantine-fault",
    "slug": "istanbul-byzantine-fault",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/istanbul-byzantine-fault",
    "title": "***Istanbul Byzantine Fault***",
    "excerpt": "Istanbul Byzantine Fault This article refers to link below! [Link](https://steemit.com/kr/@kanghamin/istanbul-byzantine-fault-toleranc...",
    "content": "# ***Istanbul Byzantine Fault***\n\n> This article refers to link below!\n> \n> [Link](https://steemit.com/kr/@kanghamin/istanbul-byzantine-fault-tolerance)\n\n## Consensus process\n\n1.  Pre-Prepare\n2.  Prepare\n3.  Commit\n\n-   Assuming that the bad node is F, System can run if the total number of nodes is 3F+1 or more.\n-   Validator is that derive consensus, and they choose a proposer before generating blocks(before every round).\n\n### Protocol: Propose\n\nFirst, the proposer choose and propose a new block, then announce it with message.\n\n![https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F0a8048d2-f260-4e4c-be50-a88e40aca8a9%2Fimage.png](https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F0a8048d2-f260-4e4c-be50-a88e40aca8a9%2Fimage.png)\n\n### Protocol: Pre-Prepare\n\nSecond, protocol is 'pre-prepare' state with sending 'prepare' message when validators receive a message from proposer. This process makes every validators notice that they're in same state.\n\n![https://velog.velcdn.com/images%2Fasap0208%2Fpost%2Fc3524567-17ce-4cc7-ad10-72bb78e13f9a%2Fimage.png](https://velog.velcdn.com/images%2Fasap0208%2Fpost%2Fc3524567-17ce-4cc7-ad10-72bb78e13f9a%2Fimage.png)\n\n### Protocol: Prepare\n\nThird, when validators get more than 2F+1 of messages, protocol is 'prepare' state and send 'commit' message.\n\n![https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F7973d4cc-6dd8-43d7-9349-db904db584f3%2Fimage.png](https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F7973d4cc-6dd8-43d7-9349-db904db584f3%2Fimage.png)\n\n### Protocol: Commit\n\nThis protocol makes peers notice that proposed blocks are permitted, and connects those to the chain. When they receive more than 2F+1 of messages, protocol should be 'commit' state, then blocks are connected to chain.\n\n![https://velog.velcdn.com/images%2Fasap0208%2Fpost%2Faf462703-0be6-439d-925f-2c14c0dc9412%2Fimage.png](https://velog.velcdn.com/images%2Fasap0208%2Fpost%2Faf462703-0be6-439d-925f-2c14c0dc9412%2Fimage.png)\n\n### Overall process\n\n![https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F7939f561-1b3d-4801-8bda-e3df4b3482cc%2Fimage.png](https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F7939f561-1b3d-4801-8bda-e3df4b3482cc%2Fimage.png)\n\nImage above shows the whole algorithm, when consensus is failed, go to 'Round change' and then restart over again.\n\n## Wrap up\n\nConsensus process is composed of three state, Success insertion of block means finality. Simply put, there's no way to change it at all.Therefore, it cannot be forked and valid block must be on the main blockchain.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 2,
    "wordCount": 232,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "hd-hierachy-deterministic-wallet",
    "slug": "hd-hierachy-deterministic-wallet",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/hd-hierachy-deterministic-wallet",
    "title": "HD(Hierarchical Deterministic) Wallet",
    "excerpt": "HD 지갑의 개념과 BIP-32/39/44 표준, 키 파생 경로 구조를 알아봅니다.",
    "content": "# HD(Hierarchical Deterministic) Wallet\n\n## 개요\n\nHD 지갑은 하나의 **시드(Seed)**로부터 무한한 개수의 개인키/공개키 쌍을 계층적으로 파생할 수 있는 지갑 구조입니다. BIP-32 표준에 정의되어 있으며, 현대 대부분의 암호화폐 지갑이 이 방식을 사용합니다.\n\n## 왜 HD 지갑이 필요한가?\n\n### 기존 지갑의 문제점\n\n- 각 주소마다 별도의 개인키를 생성하고 백업해야 함\n- 새 주소를 만들 때마다 백업 갱신 필요\n- 개인키 관리가 복잡하고 분실 위험 증가\n\n### HD 지갑의 장점\n\n- **단일 시드 백업**: 12~24개 니모닉 단어만 백업하면 모든 키 복구 가능\n- **결정론적 파생**: 동일한 시드에서 항상 동일한 키 시퀀스 생성\n- **계층적 구조**: 용도별로 계정을 분리 관리 가능\n\n---\n\n## 핵심 BIP 표준\n\n### BIP-39: 니모닉 시드 구문\n\n사람이 읽을 수 있는 단어 목록으로 시드를 표현합니다.\n\n```\nabandon ability able about above absent absorb abstract absurd abuse access accident\n```\n\n- 12, 15, 18, 21, 24개 단어 지원\n- 2048개 단어 목록에서 선택\n- 마지막 단어에 체크섬 포함\n\n### BIP-32: 키 파생 구조\n\n시드로부터 마스터 키를 생성하고, 이를 기반으로 자식 키를 파생합니다.\n\n```\nSeed → Master Key → Child Key → Grandchild Key → ...\n```\n\n**키 파생 방식:**\n\n- **일반 파생 (Normal)**: 확장 공개키로 자식 공개키 파생 가능\n- **강화 파생 (Hardened)**: 개인키가 있어야만 자식 키 파생 가능 (보안 강화)\n\n### BIP-44: 경로 규약\n\n다중 코인, 다중 계정을 지원하기 위한 표준화된 경로 구조입니다.\n\n```\nm / purpose' / coin_type' / account' / change / address_index\n```\n\n| 레벨 | 설명 | 예시 |\n|-----|------|------|\n| `purpose'` | BIP 번호 (44 = BIP-44) | 44' |\n| `coin_type'` | 코인 종류 | 0' (BTC), 60' (ETH) |\n| `account'` | 계정 번호 | 0', 1', 2' |\n| `change` | 외부(0) / 내부(1) | 0 |\n| `address_index` | 주소 인덱스 | 0, 1, 2... |\n\n**경로 예시:**\n\n```\nm/44'/0'/0'/0/0   → 첫 번째 비트코인 주소\nm/44'/60'/0'/0/0  → 첫 번째 이더리움 주소\nm/44'/501'/0'/0'  → 첫 번째 솔라나 주소\n```\n\n---\n\n## 보안 고려사항\n\n### 강화 파생을 사용해야 하는 곳\n\n- `purpose`, `coin_type`, `account` 레벨은 반드시 강화 파생(`'`) 사용\n- 일반 파생 키가 노출되면 형제 개인키 추론 가능\n\n### 니모닉 보관\n\n- 오프라인 환경에서 생성\n- 물리적 매체(종이, 금속판)에 백업\n- 디지털 저장 절대 금지\n\n---\n\n## 주요 코인별 경로\n\n| 코인 | BIP-44 경로 | coin_type |\n|-----|------------|-----------|\n| Bitcoin | m/44'/0'/... | 0 |\n| Ethereum | m/44'/60'/... | 60 |\n| Solana | m/44'/501'/... | 501 |\n| Ripple | m/44'/144'/... | 144 |\n| Aptos | m/44'/637'/... | 637 |\n\n---\n\n## 참고 자료\n\n- [BIP-32: Hierarchical Deterministic Wallets](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki)\n- [BIP-39: Mnemonic code for generating deterministic keys](https://github.com/bitcoin/bips/blob/master/bip-0039.mediawiki)\n- [BIP-44: Multi-Account Hierarchy](https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki)\n- [SLIP-44: Registered coin types](https://github.com/satoshilabs/slips/blob/master/slip-0044.md)",
    "docType": "original",
    "category": "Blockchain",
    "tags": [
      "Blockchain",
      "Wallet",
      "BIP-32",
      "BIP-39",
      "BIP-44"
    ],
    "readingTime": 3,
    "wordCount": 428,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "harmony-one",
    "slug": "harmony-one",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/harmony-one",
    "title": "Harmony (ONE)",
    "excerpt": "Harmony (ONE) 💡 Cheatsheet of ONE for web3 developers. 요약 이더리움 복제품 다만 샤딩 적용되어 있는데 현재는 4개 체인 이외 특이사항 딱히 없다...",
    "content": "# Harmony (ONE)\n\n<aside>\n💡 Cheatsheet of ONE for web3 developers.\n\n</aside>\n\n# 요약\n\n1. 이더리움 복제품\n2. 다만 샤딩 적용되어 있는데 현재는 4개 체인\n3. 이외 특이사항 딱히 없다",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 31,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "filecoin-fil",
    "slug": "filecoin-fil",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/filecoin-fil",
    "title": "Filecoin (FIL)",
    "excerpt": "Filecoin (FIL) 💡 애증의 파일코인 요약 트랜잭션 전파시에 타임아웃 나는거 고질병이라고 함 미리 txHash 만드는 방법있음. 아래 라이브러리 잘 찾으면 나옴 [https://docs.zondax.c...",
    "content": "# Filecoin (FIL)\n\n<aside>\n💡 애증의 파일코인\n\n</aside>\n\n# 요약\n\n1. 트랜잭션 전파시에 타임아웃 나는거 고질병이라고 함\n2. 미리 txHash 만드는 방법있음. 아래 라이브러리 잘 찾으면 나옴\n\n[https://docs.zondax.ch/filecoin-signing-tools](https://docs.zondax.ch/filecoin-signing-tools)\n\n1. filecoin vs arweave 검색하면 IPFS 관련해서 재밌는 주제 많음",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 39,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "biance-smart-chain-bnb",
    "slug": "biance-smart-chain-bnb",
    "path": "blockchain/others",
    "fullPath": "blockchain/others/biance-smart-chain-bnb",
    "title": "Biance Smart Chain (BNB)",
    "excerpt": "Biance Smart Chain (BNB) 💡 Cheatsheet of BSC/BNB for web3 developers. 설명 이더리움 복사본. BNB체인과 BSC체인이 따로 있어서 유의 필요...",
    "content": "# Biance Smart Chain (BNB)\n\n<aside>\n💡 Cheatsheet of BSC/BNB for web3 developers.\n\n</aside>\n\n# 설명\n\n1. 이더리움 복사본.\n2. BNB체인과 BSC체인이 따로 있어서 유의 필요",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 27,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "블록체인의-이해",
    "slug": "beulrogceinyi-ihae",
    "path": "blockchain/fundamentals",
    "fullPath": "blockchain/fundamentals/beulrogceinyi-ihae",
    "title": "블록체인의 이해",
    "excerpt": "블록체인의 이해 _보험연구원의 연구보고서 '[권호 : 18-24] 보험 산업의 블록체인 활용'을 읽고 작성한 내용입니다. 개인 공부 목적이라 정리가 미흡한 점 양해 부탁드립니다._ 블록체인의 의미 블록체인이란 P2P(Peer to Peer) 네트...",
    "content": "# 블록체인의 이해\n\n> _보험연구원의 연구보고서 '[권호 : 18-24] 보험 산업의 블록체인 활용'을 읽고 작성한 내용입니다. 개인 공부 목적이라 정리가 미흡한 점 양해 부탁드립니다._\n\n## 1. 블록체인의 의미\n\n블록체인이란 P2P(Peer to Peer) 네트워크를 통해 관리되는 분산 데이터베이스의 한 형태로, 거래 정보를 담은 장부를 중앙서버 한 곳에 저장하는 것이 아니라 블록체인 네트워크에 연결된 여러 컴퓨터에 저장 및 보관하는 기술로 다양한 분야에 활용이 가능한 기술이다.\n\n블록체인은 분산원장 기술이라고도 불리며, 이는 거래 정보를 기록한 원장 데이터를 중앙서버가 아닌 참가자들이 공동으로 기록 및 관리하는 것을 의미한다. 블록체인은 분산처리와 암호화 기술을 동시에 적용하며 높은 보안성을 확보하는 한편 거래과정의 신속성과 투명성을 특징으로 한다.\n\n보안성의 강화로 해커의 공격과 데이터의 왜곡 그리고 기존 중앙집중 서버 방식에서 가장 큰 문제인 디도스 공격을 원천적으로 방어할 수 있다. 그리고 블록체인 플랫폼을 이용하면 제 3자의 거래에 의존하던 여러 과정들을 생략할 수 있어, 그에 따른 비용을 획기적으로 절약할 수 있다. 제 3자가 거래 중심의 보장 및 증명 서비스의 항목들을 블록체인 시스템에 수렴할 수 있다.\n\n보안성이 높고 위변조가 어렵다는 특성 때문에 데이터 원본의 무결성이 요구되는 다양한 공공-민간 영역에 적용되고 있으며, 새로운 신뢰사회 구현의 기반 기술로 주목받고 있는 중이다. 또한, 블록체인 기술은 거래 장부인 데이터뿐 아니라 거래 계약도 중간 신뢰 담당자없이 거래를 할 수 있는데 이것이 바로 앞서 언급한 스마트계약이다.\n\n## 2. 블록체인의 원리\n\n블록체인 기술은 거래정보를 기록한 원장데이터를 중앙 서버가 아닌 네트워크에 참가하는 모든 공동체가 거래를 기록하고 관리하는 P2P거래를 지향하는 탈중앙화를 핵심 개념으로 하는 기술이다. 기존 금융 시스템에서는 금융회사들이 중앙 서버에 거래기록을 보관해온 반면, P2P 방식을 기반으로 하는 블록체인에서는 거래 정보를 블록에 담아 차례대로 연결하고 이를 모든 참여자가 공유한다.\n\n-   거래과정1) A가 B에게 송금희망 등의 거래 요청을 한다.2) 핻당 거래 정보가 담긴 블록이 생성된다.3) 블록이 네트워크 상의 모든 참여자에게 전송되면4) 참여자들은 거래 정보의 유효성을 상호 검증한다.5) 참여자 과반수의 데이터와 일치하는 거래내역은 정상 장부로 확인하는 방식으로 검증이 완료된 블록은 이전 블록에 연결되고, 그 사본이 만들어져 각 사용자의 컴퓨터에 분산 저장된다.6) A가 B에게 송금하여 거래가 완료된다.\n\n이렇게 거래할 때마다 거래 정보가 담긴 블록이 생성되어 계속 연결되면서 모든 참여자의 컴퓨터에 분산 저장되는데, 이를 해킹하여 임의로 수정하거나 위조 또는 변조하려면 전체 참여자의 과반수 이상의 거래 정보를 동시에 수정하여야 하기 때문에 사실상 불가능하다. 따라서 접근을 차단함으로써 거래 정보를 보호 및 관리하는 기존의 금융시스템과는 전혀 달리, 블록체인에서는 모든 거래 정보를 누구나 열람할 수 있도록 공개한 상태에서 은행 같은 공신력있는 제 3자의 보증 없이 당사자 간에 안전하게 거래가 이루어 진다.\n\n## 3. 블록체인의 기술적 개념\n\n### 가. 해시함수\n\n블록체인, 암호화폐 기술의 내용에 매번 등장하는 것 중 하나가 해시함수이다. 해시함수의 해시는 \"어떤 데이터를 고정된 길이의 데이터로 변환\"하는 것을 의미한다. 해시함수를 거치면 원본 데이터를 알아볼 수 없도록 특수한 문자열로 변환이 되는데, 해시함수는 압축이 아니라 단방향 변환이기 때문에 해시값을 이용해서 원본데이터를 복원할 수 없다는 특징을 가지고 있다.\n\n### 1) 해시함수의 유용성\n\n해시함수는 다음과 같은 성격이 있기 때문에 보안에서 유용하게 쓰인다. 원본데이터에 아주 작은 변화만 있어도 완전이 다른 해시값이 만들어지게 된다.즉 해시함수를 이용하게 되면, 원본데이터의 사소한 변화도 쉽게 확인할 수 있게 된다. 또한 해시함수는 눈사태 효과때문에 전자서명, 증명서 등에서 해시값을 많이 활용하고 있다. 본문에 약간의 수정만 가해져도 해시값이 완전히 달라져 위변조 판별이 용이하기 때문이다. 블록체인의 해시함수가 양방향 변환이 가능했더라면 암호화에 쓰일 수가 없었을 것이다.\n\n하지만 해시함수는 단방향 변환이며, 복원이 불가능하기 때문에 블록체인 기술 및 전자서명 등 암호화에 사용될 수 있다. 블록체인에서는 이 해시값을 이용해 해당 블록에 서명하고 이전 블록의 해시값을 다음 블록에 기록함으로써 체인 형태의 연결 리스트를 형성하게 된다. 따라서 특정 블록을 해킹하려면 그 블록에 연결된 다른 블록들도 수정을 해야하기 때문에 데이터의 위변조가 아주 어려운 구조를 가지고 있다.\n\n### 2) 해시함수의 특성\n\n(1) 어떤 길이의 데이터도 입력으로 사용될 수 있다.\n\n(2) 결과는 정해진 길이로 나온다.\n\n(3) 계산 시간이 합리적으로 추정 가능해야 한다.\n\n(4) 결과 값이 중복될 가능성이 거의 없다.\n\n(5) \\*\\*\\*\\*입력 값을 알 수 없다.\n\n(6) 결과 값을 알려주고 입력 값을 찾을 수 있는 특별한 공식이 없다.\n\n![https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F0a7c3c00-b692-429b-be26-d1e25b481912%2Fimage.png](https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F0a7c3c00-b692-429b-be26-d1e25b481912%2Fimage.png)\n\n### 3) 해시함수에 관한 추가 설명\n\n블록체인을 활용한 암호화폐에서 사용되는 암호기술은 해시함수, 전자서명, 공개키 암호화 알고리즘이라 말할 수 있다. 여기서 해시함수는 임의 데이터를 특정 길이의 문자, 숫자로 조합된 해시값으로 변환하는 암호 알고리즘의 일종이다. 해시함수에서 산출되는 해시값은 지문이라고도 하는데, 암호화폐에서 해시값 비교를 통하여 원본의 위변조 여부를 판단하는 무결성 검증에 사용될 수 있다.\n\n블록체인에서 해시함수를 사용하는 3가지 목적을 살펴보면 첫째, 공개키의 해시값을 지갑주소로 활용하여 익명화된 거래를 수행하고, 가상화폐의 전자지갑 주소는 공개키 기반 암호화 알고리즘에서 생성된 공개키의 해시값을 사용한다. 개인정보(정확히는 송신자의 계좌정보) 없이 익명화된 거래를 통해 송금자의 신원을 감추고, 송금할 수 있다.\n\n둘째, 해시함수를 사용하여 2가지의 무결성 검증에 사용하게 된다. 체인으로 연결된 블록헤더의 해시값을 활용하여 해시값 체인으로 연결된 블록의 무결성 검증에 사용된다. 또 다른 무결성 검증은 각 블록의 전체거래를 하나의 해시값(머클루트)으로 저장하고, 필요할 경우에는 언제든, 해당 블록의 머클루트 값으로 블록 내에 포함된 개별거래의 위변조 여부를 검증할 수 있다. 모든 거래 데이터의 해시값을 머클 트리를 이용하여 만들어지는 머클 루트에 저장하고 향후 거래내역의 위변조 여부를 검증할 때, 원본 해시값과 비교를 통하여, 각 거래의 무결성을 검증할 수 있다.또한 머클 루트는 1MB로 크기가 제한되어 있는 비트코인의 각 블록의 크기를 효율적으로 사용할 수 있게 한다. 전체 거래내역을 다 저장할 필요 없이, 머클루트라는 한 개의 해시값만 저장하면, 해당 블블록 내의 모든 거래내역의 진위를 필요할 때 비교할 수 있기 때문이다.\n\n마지막으로 합의 알고리즘에서 PoW방식을 사용할 경우, 해시값을 활용한 채굴문제에 활용한다. 해시값을 활용한 채굴문제에 먼저 맞추는 채굴자에게 채굴권한과 보상을 제공한다. 해시캐시 문제풀이를 통한 작업증명은 채굴이라고도 하는데, 채굴자에 대한 보상을 통해, 채굴을 경장해고, 채굴자가 자율적으로 새로운 블록을 생성하도록 유도할 수 있는 원리를 가지고 있다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 5,
    "wordCount": 836,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "롤업이란",
    "slug": "roleobiran",
    "path": "blockchain/fundamentals",
    "fullPath": "blockchain/fundamentals/roleobiran",
    "title": "롤업이란?",
    "excerpt": "롤업이란? 롤업은 L2에서 트랜잭션을 실행한 뒤, 실행한 트랜잭션 데이터들과 변경된 상태의 요약본을 L1에 저장하는 솔루션 일반적으로 L1에 배패된 롤업 컨트랙트에 스테이트 루트(상태요약본)가 저장되어 있음 롤업의 경우 L1의 상태 변경시 TX실행 결과...",
    "content": "# 롤업이란?\n\n- 롤업은 L2에서 트랜잭션을 실행한 뒤, 실행한 트랜잭션 데이터들과 변경된 상태의 요약본을 L1에 저장하는 솔루션\n- 일반적으로 L1에 배패된 롤업 컨트랙트에 스테이트 루트(상태요약본)가 저장되어 있음\n- 롤업의 경우 L1의 상태 변경시 TX실행 결과 뿐만 아니라 데이터 또한 보관하는 방식을 통해서 누구든 데이터 유효성을 검증할 수 있게 했음\n<img src=\"https://cdn.coindeskkorea.com//news/photo/202207/80513_23505_1657.png\" />\n\n\n\nhttps://www.coindeskkorea.com/news/articleView.html?idxno=80513",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 54,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "단순-해시-검증-의-한계와-데이터-가용성-문제",
    "slug": "dansun-haesi-geomjeung-yi-hangyewa-deiteo-gayongseong-munje",
    "path": "blockchain/fundamentals",
    "fullPath": "blockchain/fundamentals/dansun-haesi-geomjeung-yi-hangyewa-deiteo-gayongseong-munje",
    "title": "\"단순 해시 검증\"의 한계와 데이터 가용성 문제",
    "excerpt": "\"단순 해시 검증\"의 한계와 데이터 가용성 문제 이것은 매우 핵심적인 질문입니다! 단순히 ODS의 해시만 검증하는 방식이 왜 부족한지, Celestia의 데이터 가용성 샘플링이 왜 필요한지 명확히 설명드리겠습니다. 단순 해시 검증의 근본적 문제 1...",
    "content": "# \"단순 해시 검증\"의 한계와 데이터 가용성 문제\n\n이것은 매우 핵심적인 질문입니다! 단순히 ODS의 해시만 검증하는 방식이 왜 부족한지, Celestia의 데이터 가용성 샘플링이 왜 필요한지 명확히 설명드리겠습니다.\n\n## 단순 해시 검증의 근본적 문제\n\n### 1. \"데이터 가용성 문제\"의 본질\n만약 우리가 해시만 검증한다면:\n\n- 블록 생성자는 데이터의 해시만 제출하고 **실제 데이터를 공개하지 않을 수 있습니다**.\n- 검증자들은 해시가 맞다는 것은 확인할 수 있지만, **데이터가 실제로 네트워크에 게시되었는지는 확인할 수 없습니다**.\n\n이것은 \"**데이터 가용성 문제**\"라고 부르며, 특히 롤업이나 확장성 솔루션에서 심각한 보안 위험을 초래합니다.\n\n### 2. \"무데이터 공격\" (Data Withholding Attack)\n이로 인해 가능한 공격 시나리오:\n\n1. 악의적인 블록 생성자가 유효한 데이터에 대한 해시만 포함한 블록 헤더를 제출\n2. 그러나 실제 데이터는 네트워크에 공개하지 않음\n3. 네트워크는 해시만 보고 블록이 유효하다고 판단\n4. 그러나 실제 데이터가 없어 트랜잭션 검증이나 롤업 상태 업데이트 불가능\n5. 블록체인이 멈추거나 심각한 손상 발생\n\n## 데이터 가용성 샘플링(DAS)의 필요성\n\n### 1. 샘플링을 통한 확률적 검증\nCelestia의 DAS는 이 문제를 해결하기 위해:\n\n- 노드들이 블록 데이터의 **무작위 샘플을 직접 요청**해서 확인\n- 만약 모든 샘플이 제공될 수 있다면, 높은 확률로 전체 데이터가 가용함을 의미\n- 단 하나의 샘플이라도 제공되지 않으면, 데이터 가용성 문제 감지\n\n### 2. Reed-Solomon 인코딩의 역할\nEDS 구조와 Reed-Solomon 인코딩은:\n\n- 데이터 일부가 손실되더라도 전체 복구 가능성 제공\n- 동시에 무작위 샘플링의 효과를 극대화 (데이터 누락 탐지 확률 향상)\n\n## 다른 블록체인과의 차이점\n\n### 1. 일반 블록체인의 접근법\nBitcoin이나 Ethereum 같은 전통적인 블록체인에서는:\n\n- **모든 풀노드가 모든 데이터를 다운로드하고 검증**\n- 따라서 데이터 가용성 문제가 덜 심각함 (풀노드는 모든 데이터를 직접 확인)\n\n### 2. Celestia의 혁신적 접근법\nCelestia는 확장성을 위해:\n\n- 모든 노드가 모든 데이터를 다운로드할 필요 없음\n- 대신 샘플링을 통해 데이터 가용성을 확률적으로 검증\n- 이는 라이트 노드에게도 강력한 보안 보장 제공\n\n## 결론: 왜 단순 해시 검증으로는 부족한가\n\n단순 해시 검증은:\n\n1. **데이터가 존재하는지** 검증하지 못함 (단지 해시가 맞다는 것만 검증)\n2. **데이터 가용성 공격**에 취약함\n3. **확장성 솔루션**에서 치명적인 보안 위험 초래\n\nCelestia의 DAS는 이 근본적인 문제를 해결하여, 확장성과 보안성을 동시에 달성할 수 있게 해줍니다. 샘플링을 통해 적은 양의 데이터만으로도 높은 확률로 데이터 가용성을 검증하고, 이를 통해 \"무데이터 공격\"을 방지합니다.\n\n이것이 Celestia가 ODS/ODSQ4 저장 전략과 데이터 가용성 샘플링을 사용하는 근본적인 이유입니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 2,
    "wordCount": 352,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "checksum",
    "slug": "checksum",
    "path": "blockchain/fundamentals",
    "fullPath": "blockchain/fundamentals/checksum",
    "title": "Checksum",
    "excerpt": "Checksum What is checksum ? A checksum is small-sized block of data derived from block of digital data for the purpose of deecting errors tah m...",
    "content": "# Checksum\n\n## What is checksum ?\n\nA checksum is small-sized block of data derived from block of digital data for the purpose of deecting errors tah may have been introduced during its transmission or storage. By themselves, checksums are often used to verify data integrity but are not relied upon to verify data authenticity.\n\n> The procedure which generates this checksum is called a checksum function or checksum algorithm. - Wikipedia\n\n![https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F9c511980-dada-46e7-b0cc-f97143bcc6da%2Fimage.png](https://velog.velcdn.com/images%2Fasap0208%2Fpost%2F9c511980-dada-46e7-b0cc-f97143bcc6da%2Fimage.png)\n\n## Example\n\n0x25 = 370x62 = 980x3F = 630x52 = 82\n\n1.  0x25 + 0x62 + 0x3F + 0x52 = 0x118(280)-> 0001 0001 10002) drop carry nibble-> 0001 10003) 2's complements-> 1110 0111(1's complements) + 1-> 1110 10004) to Hex-> 0xE8 (=Checksum byte)\n\n### Test\n\n1.  0x118(origin) + 0xE8(checksum) = 0x200(5122) to binary-> 0010 0000 00003) drop carry nibble-> 0000 0000",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 135,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "how-base-gas-works",
    "slug": "how-base-gas-works",
    "path": "blockchain/ethereum",
    "fullPath": "blockchain/ethereum/how-base-gas-works",
    "title": "How Base Gas Works",
    "excerpt": "How Base Gas Works Aptos transactions by default charge a base gas fee, regardless of market conditions. For each transaction, this \"base gas\" amou...",
    "content": "# How Base Gas Works\n\nAptos transactions by default charge a base gas fee, regardless of market conditions.\nFor each transaction, this \"base gas\" amount is based on three conditions:\n\n1. Instructions.\n2. Storage.\n3. Payload.\n\nThe more function calls, branching conditional statements, etc. that a transaction requires, the more instruction gas it will cost.\nLikewise, the more reads from and writes into global storage that a transaction requires, the more storage gas it will cost.\nFinally, the more bytes in a transaction payload, the more it will cost.\n\nAs explained in the [optimization principles](#optimization-principles) section, storage gas has by far the largest effect on base gas. For background on the Aptos gas model, see [The Making of the Aptos Gas Schedule](https://aptoslabs.medium.com/the-making-of-the-aptos-gas-schedule-508d5686a350).\n\n## Instruction gas\n\nBasic instruction gas parameters are defined at [`instr.rs`] and include the following instruction types:\n\n### No-operation\n\n| Parameter | Meaning        |\n| --------- | -------------- |\n| `nop`     | A no-operation |\n\n### Control flow\n\n| Parameter  | Meaning                          |\n| ---------- | -------------------------------- |\n| `ret`      | Return                           |\n| `abort`    | Abort                            |\n| `br_true`  | Execute conditional true branch  |\n| `br_false` | Execute conditional false branch |\n| `branch`   | Branch                           |\n\n### Stack\n\n| Parameter           | Meaning                          |\n| ------------------- | -------------------------------- |\n| `pop`               | Pop from stack                   |\n| `ld_u8`             | Load a `u8`                      |\n| `ld_u64`            | Load a `u64`                     |\n| `ld_u128`           | Load a `u128`                    |\n| `ld_true`           | Load a `true`                    |\n| `ld_false`          | Load a `false`                   |\n| `ld_const_base`     | Base cost to load a constant     |\n| `ld_const_per_byte` | Per-byte cost to load a constant |\n\n### Local scope\n\n| Parameter                   | Meaning                  |\n| --------------------------- | ------------------------ |\n| `imm_borrow_loc`            | Immutably borrow         |\n| `mut_borrow_loc`            | Mutably borrow           |\n| `imm_borrow_field`          | Immutably borrow a field |\n| `mut_borrow_field`          | Mutably borrow a field   |\n| `imm_borrow_field_generic`  |                          |\n| `mut_borrow_field_generic`  |                          |\n| `copy_loc_base`             | Base cost to copy        |\n| `copy_loc_per_abs_val_unit` |                          |\n| `move_loc_base`             | Move                     |\n| `st_loc_base`               |                          |\n\n### Calling\n\n| Parameter                 | Meaning                       |\n| ------------------------- | ----------------------------- |\n| `call_base`               | Base cost for a function call |\n| `call_per_arg`            | Cost per function argument    |\n| `call_generic_base`       |                               |\n| `call_generic_per_ty_arg` | Cost per type argument        |\n| `call_generic_per_arg`    |                               |\n\n### Structs\n\n| Parameter                  | Meaning                              |\n| -------------------------- | ------------------------------------ |\n| `pack_base`                | Base cost to pack a `struct`         |\n| `pack_per_field`           | Cost to pack a `struct`, per field   |\n| `pack_generic_base`        |                                      |\n| `pack_generic_per_field`   |                                      |\n| `unpack_base`              | Base cost to unpack a `struct`       |\n| `unpack_per_field`         | Cost to unpack a `struct`, per field |\n| `unpack_generic_base`      |                                      |\n| `unpack_generic_per_field` |                                      |\n\n### References\n\n| Parameter                   | Meaning                            |\n| --------------------------- | ---------------------------------- |\n| `read_ref_base`             | Base cost to read from a reference |\n| `read_ref_per_abs_val_unit` |                                    |\n| `write_ref_base`            | Base cost to write to a reference  |\n| `freeze_ref`                | Freeze a reference                 |\n\n### Casting\n\n| Parameter   | Meaning          |\n| ----------- | ---------------- |\n| `cast_u8`   | Cast to a `u8`   |\n| `cast_u64`  | Cast to a `u64`  |\n| `cast_u128` | Cast to a `u128` |\n\n### Arithmetic\n\n| Parameter | Meaning  |\n| --------- | -------- |\n| `add`     | Add      |\n| `sub`     | Subtract |\n| `mul`     | Multiply |\n| `mod_`    | Modulo   |\n| `div`     | Divide   |\n\n### Bitwise\n\n| Parameter | Meaning                   |\n| --------- | ------------------------- |\n| `bit_or`  | `OR`: <code>&#124;</code> |\n| `bit_and` | `AND`: `&`                |\n| `xor`     | `XOR`: `^`                |\n| `shl`     | Shift left: `<<`          |\n| `shr`     | Shift right: `>>`         |\n\n### Boolean\n\n| Parameter | Meaning                         |\n| --------- | ------------------------------- |\n| `or`      | `OR`: <code>&#124;&#124;</code> |\n| `and`     | `AND`: `&&`                     |\n| `not`     | `NOT`: `!`                      |\n\n### Comparison\n\n| Parameter              | Meaning                        |\n| ---------------------- | ------------------------------ |\n| `lt`                   | Less than: `<`                 |\n| `gt`                   | Greater than: `>`              |\n| `le`                   | Less than or equal to: `<=`    |\n| `ge`                   | Greater than or equal to: `>=` |\n| `eq_base`              | Base equality cost: `==`       |\n| `eq_per_abs_val_unit`  |                                |\n| `neq_base`             | Base not equal cost: `!=`      |\n| `neq_per_abs_val_unit` |                                |\n\n### Global storage\n\n| Parameter                        | Meaning                                               |\n| -------------------------------- | ----------------------------------------------------- |\n| `imm_borrow_global_base`         | Base cost to immutably borrow: `borrow_global<T>()`   |\n| `imm_borrow_global_generic_base` |                                                       |\n| `mut_borrow_global_base`         | Base cost to mutably borrow: `borrow_global_mut<T>()` |\n| `mut_borrow_global_generic_base` |                                                       |\n| `exists_base`                    | Base cost to check existence: `exists<T>()`           |\n| `exists_generic_base`            |                                                       |\n| `move_from_base`                 | Base cost to move from: `move_from<T>()`              |\n| `move_from_generic_base`         |                                                       |\n| `move_to_base`                   | Base cost to move to: `move_to<T>()`                  |\n| `move_to_generic_base`           |                                                       |\n\n### Vectors\n\n| Parameter                      | Meaning                                  |\n| ------------------------------ | ---------------------------------------- |\n| `vec_len_base`                 | Length of a vector                       |\n| `vec_imm_borrow_base`          | Immutably borrow an element              |\n| `vec_mut_borrow_base`          | Mutably borrow an element                |\n| `vec_push_back_base`           | Push back                                |\n| `vec_pop_back_base`            | Pop from the back                        |\n| `vec_swap_base`                | Swap elements                            |\n| `vec_pack_base`                | Base cost to pack a vector               |\n| `vec_pack_per_elem`            | Cost to pack a vector per element        |\n| `vec_unpack_base`              | Base cost to unpack a vector             |\n| `vec_unpack_per_expected_elem` | Base cost to unpack a vector per element |\n\nAdditional storage gas parameters are defined in [`table.rs`], [`move_stdlib.rs`], and other assorted source files in [`aptos-gas/src/`].\n\n## Storage gas\n\nStorage gas is defined in [`storage_gas.move`], which is accompanied by a comprehensive and internally-linked DocGen file at [`storage_gas.md`].\n\nIn short:\n\n1. In [`initialize()`], [`base_8192_exponential_curve()`] is used to generate an exponential curve whereby per-item and per-byte costs increase rapidly as utilization approaches an upper bound.\n2. Parameters are reconfigured each epoch via [`on_reconfig()`], based on item-wise and byte-wise utilization ratios.\n3. Reconfigured parameters are stored in [`StorageGas`], which contains the following fields:\n\n| Field             | Meaning                                     |\n| ----------------- | ------------------------------------------- |\n| `per_item_read`   | Cost to read an item from global storage    |\n| `per_item_create` | Cost to create an item in global storage    |\n| `per_item_write`  | Cost to overwrite an item in global storage |\n| `per_byte_read`   | Cost to read a byte from global storage     |\n| `per_byte_create` | Cost to create a byte in global storage     |\n| `per_byte_write`  | Cost to overwrite a byte in global storage  |\n\nHere, an _item_ is either a resource having the `key` attribute, or an entry in a table, and notably, per-byte costs are assessed on the _entire_ size of an item.\nAs stated in [`storage_gas.md`], for example, if an operation mutates a `u8` field in a resource that has five other `u128` fields, the per-byte gas write cost will account for $(5 * 128) / 8 + 1 = 81$ bytes.\n\n### Vectors\n\nByte-wise fees are similarly assessed on vectors, which consume $\\sum_{i = 0}^{n - 1} e_i + b(n)$ bytes, where:\n\n- $n$ is the number of elements in the vector\n- $e_i$ is the size of element $i$\n- $b(n)$ is a \"base size\" which is a function of $n$\n\nSee the [BCS sequence specification] for more information on vector base size (technically a `ULEB128`), which typically occupies just one byte in practice, such that a vector of 100 `u8` elements accounts for $100 + 1 = 101$ bytes.\nHence per the item-wise read methodology described above, reading the last element of such a vector is treated as a 101-byte read.\n\n## Payload gas\n\nPayload gas is defined in [`transaction/mod.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/transaction/mod.rs), which incorporates storage gas with several payload- and pricing-associated parameters:\n\n| Parameter                       | Meaning                                                                                |\n| ------------------------------- | -------------------------------------------------------------------------------------- |\n| `min_transaction_gas_units`     | Minimum internal gas units for a transaction, charged at the start of execution        |\n| `large_transaction_cutoff`      | Size, in bytes, above which transactions will be charged an additional amount per byte |\n| `intrinsic_gas_per_byte`        | Internal gas units charged per byte for payloads above `large_transaction_cutoff`      |\n| `maximum_number_of_gas_units`   | Upper limit on external gas units for a transaction                                    |\n| `min_price_per_gas_unit`        | Minimum gas price allowed for a transaction                                            |\n| `max_price_per_gas_unit`        | Maximum gas price allowed for a transaction                                            |\n| `max_transaction_size_in_bytes` | Maximum transaction payload size in bytes                                              |\n| `gas_unit_scaling_factor`       | Conversion factor between internal gas units and external gas units                    |\n\nHere, \"internal gas units\" are defined as constants in source files like [`instr.rs`] and [`storage_gas.move`], which are more granular than \"external gas units\" by a factor of `gas_unit_scaling_factor`:\nto convert from internal gas units to external gas units, divide by `gas_unit_scaling_factor`.\nThen, to convert from external gas units to octas, multiply by the \"gas price\", which denotes the number of octas per unit of external gas.\n\n## Optimization principles\n\n### Unit and pricing constants\n\nAs of the time of this writing, `min_price_per_gas_unit` in [`transaction/mod.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/transaction/mod.rs) is defined as [`aptos_global_constants`]`::GAS_UNIT_PRICE` (which is itself defined as 100), with other noteworthy [`transaction/mod.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/transaction/mod.rs) constants as follows:\n\n| Constant                  | Value  |\n| ------------------------- | ------ |\n| `min_price_per_gas_unit`  | 100    |\n| `max_price_per_gas_unit`  | 10,000 |\n| `gas_unit_scaling_factor` | 10,000 |\n\nSee [Payload gas](#payload-gas) for the meaning of these constants.\n\n### Storage gas\n\nAs of the time of this writing, [`initialize()`] sets the following minimum storage gas amounts:\n\n| Data style | Operation | Symbol | Minimum internal gas |\n| ---------- | --------- | ------ | -------------------- |\n| Per item   | Read      | $r_i$  | 300,000              |\n| Per item   | Create    | $c_i$  | 5,000,000            |\n| Per item   | Write     | $w_i$  | 300,000              |\n| Per byte   | Read      | $r_b$  | 300                  |\n| Per byte   | Create    | $c_b$  | 5,000                |\n| Per byte   | Write     | $w_b$  | 5,000                |\n\nMaximum amounts are 100 times the minimum amounts, which means that for a utilization ratio of 40% or less, total gas costs will be on the order of 1 to 1.5 times the minimum amounts (see [`base_8192_exponential_curve()`] for supporting calculations).\nHence, in terms of octas, initial mainnet gas costs can be estimated as follows (divide internal gas by scaling factor, then multiply by minimum gas price):\n\n| Operation       | Operation | Minimum octas |\n| --------------- | --------- | ------------- |\n| Per-item read   | $r_i$     | 3000          |\n| Per-item create | $c_i$     | 50,000        |\n| Per-item write  | $w_i$     | 3000          |\n| Per-byte read   | $r_b$     | 3             |\n| Per-byte create | $c_b$     | 50            |\n| Per-byte write  | $w_b$     | 50            |\n\nHere, the most expensive per-item operation by far is creating a new item (via either `move_to<T>()` or adding to a table), which costs nearly 17 times as much as reading or overwriting an old item: $c_i = 16.\\overline{6} r_i = 16.\\overline{6} w_i$. Additionally:\n\n- Writes cost the same as reads on a per-item basis: $w_i = r_i$\n- On a per-byte basis, however, writes cost the same as creates: $w_b = c_b$\n- Per-byte writes and creates cost nearly 17 times as much as per-byte reads: $w_b = c_b = 16.\\overline{6} r_b$\n- Per-item reads cost 1000 times as much as per-byte reads: $r_i = 1000 r_b$\n- Per-item creates cost 1000 times as much as per-byte creates: $c_i = 1000 c_b$\n- Per-item writes cost 60 times as much as per-byte writes: $w_i = 60 w_b$\n\nHence per-item operations cost 1000 times more than per-byte operations for both reads and creates, but only 60 times more for writes.\n\nThus, in the absence of a legitimate economic incentive to deallocate from global storage (via either `move_from<T>()` or by removing from a table), the most effective storage gas optimization strategy is as follows:\n\n1. Minimize per-item creations\n2. Track unused items and overwrite them, rather than creating new items, when possible\n3. Contain per-item writes to as few items as possible\n4. Read, rather than write, whenever possible\n5. Minimize the number of bytes in all operations, especially writes\n\n### Instruction gas\n\nAs of the time of this writing, all instruction gas operations are multiplied by the `EXECUTION_GAS_MULTIPLIER` defined in [`gas_meter.rs`], which is set to 20.\nHence the following representative operations assume gas costs as follows (divide internal gas by scaling factor, then multiply by minimum gas price):\n\n| Operation                    | Minimum octas |\n| ---------------------------- | ------------- |\n| Table add/borrow/remove box  | 240           |\n| Function call                | 200           |\n| Load constant                | 130           |\n| Globally borrow              | 100           |\n| Read/write reference         | 40            |\n| Load `u128` on stack         | 16            |\n| Table box operation per byte | 2             |\n\n(Note that per-byte table box operation instruction gas does not account for storage gas, which is assessed separately).\n\nFor comparison, reading a 100-byte item costs $r_i + 100 * r_b = 3000 + 100 * 3 = 3300$ octas at minimum, some 16.5 times as much as a function call, and in general, instruction gas costs are largely dominated by storage gas costs.\n\nNotably, however, there is still technically an incentive to reduce the number of function calls in a program, but engineering efforts are more effectively dedicated to writing modular, decomposed code that is geared toward reducing storage gas costs, rather than attempting to write repetitive code blocks with fewer nested functions (in nearly all cases).\n\nIn extreme cases it is possible for instruction gas to far outweigh storage gas, for example if a loopwise mathematical function takes 10,000 iterations to converge; but again this is an extreme case and for most applications storage gas has a larger impact on base gas than does instruction gas.\n\n### Payload gas\n\nAs of the time of this writing, [`transaction/mod.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/transaction/mod.rs) defines the minimum amount of internal gas per transaction as 1,500,000 internal units (15,000 octas at minimum), an amount that increases by 2,000 internal gas units (20 octas minimum) per byte for payloads larger than 600 bytes, with the maximum number of bytes permitted in a transaction set at 65536.\nHence in practice, payload gas is unlikely to be a concern.\n\n<!--- Alphabetized reference links -->\n\n[#4540]: https://github.com/aptos-labs/aptos-core/pull/4540/files\n[`aptos-gas/src/`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/\n[`aptos_global_constants`]: https://github.com/aptos-labs/aptos-core/blob/main/config/global-constants/src/lib.rs\n[`base_8192_exponential_curve()`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#0x1_storage_gas_base_8192_exponential_curve\n[bcs sequence specification]: https://github.com/diem/bcs#fixed-and-variable-length-sequences\n[`gas_meter.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/gas_meter.rs\n[`initialize()`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#0x1_storage_gas_initialize\n[`instr.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/instr.rs\n[`move_stdlib.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/move_stdlib.rs\n[`on_reconfig()`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#@Specification_16_on_reconfig\n[`storage_gas.md`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md\n[`storage_gas.move`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/storage_gas.move\n[`storagegas`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#resource-storagegas\n[`table.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/table.rs\n[`transaction.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas/src/transaction.rs",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 12,
    "wordCount": 2383,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "ethereum-eth",
    "slug": "ethereum-eth",
    "path": "blockchain/ethereum",
    "fullPath": "blockchain/ethereum/ethereum-eth",
    "title": "Ethereum (ETH)",
    "excerpt": "Ethereum (ETH) 💡 이더리움은 월드 와이드 컴퓨터를 꿈꾼다 장점 개발자 커뮤니티 1등인듯, 어지간한 에러나 이슈는 이미 레퍼런스가 모두 있음. 디버깅 매우 편함 그러다보니 web3, ethers.j...",
    "content": "# Ethereum (ETH)\n\n<aside> 💡 이더리움은 월드 와이드 컴퓨터를 꿈꾼다\n\n</aside>\n\n# 장점\n\n1.  개발자 커뮤니티 1등인듯, 어지간한 에러나 이슈는 이미 레퍼런스가 모두 있음. 디버깅 매우 편함\n2.  그러다보니 web3, ethers.js 등의 라이브러리가 매우 잘 개발되어 있고 개발문서도 잘되어 있음\n3.  노드도 안정적임\n4.  이거 하나만 알아도 시장에 나온 블록체인 5할은 다룰 수 있음… (그만큼 복붙체인이 많음)\n\n# 단점\n\n1.  블록타임이 약 12 ~ 13초로 차세대 블록체인에 비해 느림\n2.  EVM은 자산을 일급객체로 다루지 않음, 일종의 지역 변수를 사칙연산한 값임. 그러다보니 EVM을 채택한 블록체인들에서 고질적인 해킹문제가 발생해옴\n3.  불장일때 수수료가 10만원을 넘음.\n4.  비탈릭 부테린의 압도적 마케팅 효과가 없어도 인기가 지속될까에 대한 의문",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 104,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "namespaced-merkle-tree-nmt-란",
    "slug": "namespaced-merkle-tree-nmt-ran",
    "path": "blockchain/celestia",
    "fullPath": "blockchain/celestia/namespaced-merkle-tree-nmt-ran",
    "title": "Namespaced Merkle Tree (NMT)란?",
    "excerpt": "Namespaced Merkle Tree (NMT)란? Namespaced Merkle Tree (NMT)는 Merkle Tree의 변형된 구조로, 네임스페이스(namespace)를 기반으로 하는 인증 가능한 데이터 구조다. Cel...",
    "content": "**Namespaced Merkle Tree (NMT)란?**\n\n  \n\n**Namespaced Merkle Tree (NMT)**는 **Merkle Tree의 변형된 구조**로, **네임스페이스(namespace)를 기반으로 하는 인증 가능한 데이터 구조**다. Celestia에서는 **특정 네임스페이스에 속하는 데이터만 검증 가능**하도록 설계된 이 구조를 사용한다.\n\n---\n\n**1. Merkle Tree와의 차이점**\n\n  \n\nMerkle Tree는 기본적으로 **전체 데이터 블록을 검증하기 위한 해시 트리 구조**다. 하지만 일반적인 Merkle Tree는 특정 데이터가 포함되어 있는지를 **빠르게 증명하는 기능은 제공하지만, 네임스페이스 단위로 검색하거나 검증하는 기능은 제공하지 않는다**.\n\n  \n\n반면 **NMT는 네임스페이스 단위로 증명(Proof)을 지원**하기 때문에 특정 네임스페이스에 속하는 데이터를 빠르게 검증할 수 있다.\n\n---\n\n**2. NMT의 특징**\n\n1. **네임스페이스 기반 Merkle 해싱**\n\n• 각 노드가 특정 네임스페이스 범위를 포함하고 있으며, 부모 노드는 자식 노드들의 네임스페이스 범위를 유지한다.\n\n• 즉, **Merkle 증명에서 네임스페이스별로 데이터 포함 여부를 쉽게 확인할 수 있다.**\n\n1. **Merkle Proof와 네임스페이스 필터링 지원**\n\n• 일반 Merkle Tree의 경우 특정 데이터가 트리에 포함되어 있는지만 증명할 수 있지만,\n\n**NMT는 특정 네임스페이스에 속하는 데이터가 있는지 없는지 증명할 수 있다.**\n\n1. **부분 데이터 접근성 향상**\n\n• 특정 네임스페이스의 데이터만 빠르게 검색하고, 다운로드하는 것이 가능하다.\n\n---\n\n**3. Celestia에서 NMT가 사용되는 이유**\n\n  \n\nCelestia에서는 **네임스페이스를 기반으로 데이터 가용성을 검증**해야 하기 때문에, 기존 Merkle Tree보다 **NMT가 더 적합**하다. Celestia에서 NMT가 사용되는 이유는 다음과 같다.\n\n1. **Blob 트랜잭션 검증**\n\n• Celestia에서는 트랜잭션과 블록 데이터를 Blob 형태로 저장하며, 각 Blob은 특정 네임스페이스에 속한다.\n\n• NMT를 활용하면 특정 네임스페이스의 Blob이 존재하는지 **효율적으로 증명할 수 있다**.\n\n1. **Data Availability Sampling (DAS) 최적화**\n\n• 라이트 노드는 **데이터 가용성을 검증하기 위해 일부 샘플을 요청**해야 한다.\n\n• NMT를 활용하면 특정 네임스페이스의 데이터를 포함하는 샘플을 보다 **효율적으로 검증 가능**하다.\n\n1. **네임스페이스 기반 데이터 검색 최적화**\n\n• Celestia의 모듈형 블록체인 구조에서는 **다양한 애플리케이션이 서로 다른 네임스페이스를 사용**한다.\n\n• 특정 애플리케이션이 필요한 데이터만 검색할 수 있도록, NMT가 효과적으로 동작한다.\n\n---\n\n**4. NMT의 동작 방식**\n\n  \n\n**📌 기본적인 Merkle Tree와 비교**\n\n  \n\n일반적인 Merkle Tree의 경우, 각 리프 노드(데이터 블록)는 해시로 변환되며, 부모 노드는 자식들의 해시를 조합하여 생성된다.\n\n  \n\n하지만 **Namespaced Merkle Tree (NMT)는 네임스페이스 정보를 추가하여 해싱**한다.\n\n  \n\n**📌 NMT의 해싱 규칙**\n\n1. **각 리프 노드**:\n\n• (namespace, data_hash) 형태로 저장됨.\n\n1. **각 내부 노드**:\n\n• namespace_min = min(left.namespace_min, right.namespace_min)\n\n• namespace_max = max(left.namespace_max, right.namespace_max)\n\n• 부모 노드는 자식의 네임스페이스 범위를 유지하면서 해싱됨.\n\n  \n\n**📌 NMT Merkle Proof 생성**\n\n• 특정 네임스페이스에 속하는 데이터를 포함하는지 검증할 때, **네임스페이스 범위 정보를 가진 Merkle Proof**를 사용하면 효율적으로 증명할 수 있다.\n\n• 특정 네임스페이스의 데이터를 포함하지 않는다면, **해당 네임스페이스 범위가 없음(Empty Proof)** 을 증명할 수 있다.\n\n---\n\n**5. 결론**\n\n• Namespaced Merkle Tree(NMT)는 **Merkle Tree의 확장 버전**으로, **네임스페이스별 데이터 검증이 가능**한 구조다.\n\n• Celestia에서는 **모듈형 블록체인에서 데이터 가용성을 효율적으로 검증하고, 특정 네임스페이스의 데이터만 빠르게 검색할 수 있도록 지원**하기 위해 사용된다.\n\n• **DAS (Data Availability Sampling)와 Blob 트랜잭션 검증에도 중요한 역할**을 한다.\n\n  \n\n👉 **즉, Celestia의 확장성과 데이터 가용성을 높이기 위해 NMT는 필수적인 요소다.** 🚀",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 3,
    "wordCount": 437,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "celestia의-데이터-저장-공간-사용량",
    "slug": "celestiayi-deiteo-jeojang-gonggan-sayongryang",
    "path": "blockchain/celestia",
    "fullPath": "blockchain/celestia/celestiayi-deiteo-jeojang-gonggan-sayongryang",
    "title": "Celestia의 데이터 저장 공간 사용량",
    "excerpt": "Celestia의 데이터 저장 공간 사용량 Celestia의 EDS(Extended Data Square) 구조에서 저장 공간 사용은 다음과 같습니다: 전체 EDS 용량 (이론적인 값) 전체 EDS는 원본 데이터의 4배 크기를 차지합니다: -...",
    "content": "# Celestia의 데이터 저장 공간 사용량\n\nCelestia의 EDS(Extended Data Square) 구조에서 저장 공간 사용은 다음과 같습니다:\n\n## 전체 EDS 용량 (이론적인 값)\n\n전체 EDS는 원본 데이터의 **4배** 크기를 차지합니다:\n\n- **Q1 (원본 데이터)**: 원본 데이터의 100%\n- **Q2 (행 패리티)**: 원본 데이터의 100%\n- **Q3 (열 패리티)**: 원본 데이터의 100%\n- **Q4 (행+열 패리티)**: 원본 데이터의 100%\n\n즉, 모든 사분면을 모두 저장한다면 원본 데이터 크기의 4배가 필요합니다.\n\n## 실제 Celestia의 저장 전략\n\n하지만 Celestia에서는 실제로 모든 사분면을 저장하지 않고, 필요에 따라 다음과 같은 저장 전략을 사용합니다:\n\n1. **ODS만 저장** (원본 데이터만):\n   - 원본 데이터의 **1배** 용량 사용\n   - 오래된 블록이나 아카이브 목적의 저장에 사용\n   - 필요시 나머지 사분면(Q2, Q3, Q4)은 계산으로 복구 가능\n\n2. **ODSQ4 저장** (원본 + Q4 사분면):\n   - 원본 데이터의 **2배** 용량 사용\n   - 가용성 윈도우 내의 최근 블록에 사용\n   - 특정 접근 패턴에서 계산 효율성 향상\n\n## 실제 코드에서의 저장 전략\n\n코드에서 이런 저장 전략은 다음과 같이 구현되어 있습니다:\n\n```go\n// 가용성 윈도우 내의 블록은 ODS와 Q4 모두 저장 (원본의 2배)\nif availability.IsWithinWindow(eh.Time(), availability.StorageWindow) {\n    err = store.PutODSQ4(ctx, eh.DAH, eh.Height(), eds)\n} else {\n    // 그 외 블록은 ODS만 저장 (원본의 1배)\n    err = store.PutODS(ctx, eh.DAH, eh.Height(), eds)\n}\n```\n\n## 저장 공간 최적화의 이유\n\n이렇게 저장 공간을 최적화하는 이유는:\n\n1. **디스크 공간 효율성**:\n   - 모든 블록의 모든 사분면을 저장하는 것은 비효율적\n   - 대부분의 경우 원본 데이터만으로도 충분\n\n2. **계산 비용과 저장 비용의 균형**:\n   - Q2와 Q3는 Q1과 Q4로부터 계산 가능 (필요할 때만 계산)\n   - 가장 자주 접근하는 최근 블록에만 Q4도 함께 저장하여 계산 비용 절약\n\n3. **가용성과 검증의 균형**:\n   - 데이터 가용성 검증은 최근 블록에 대해 더 중요\n   - 따라서 최근 블록은 더 많은 공간(ODS+Q4)을 사용하고, 오래된 블록은 공간 효율성(ODS만)을 우선시\n\n결론적으로, Celestia는 원본 데이터의 약 1~2배 정도의 저장 공간을 사용하면서도, 데이터 가용성 검증과 복구 기능을 효율적으로 제공합니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 2,
    "wordCount": 294,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "celestia의-데이터-가용성-증명-data-availability-proof-메커니즘",
    "slug": "celestiayi-deiteo-gayongseong-jeungmyeong-data-availability-proof-mekeonijeum",
    "path": "blockchain/celestia",
    "fullPath": "blockchain/celestia/celestiayi-deiteo-gayongseong-jeungmyeong-data-availability-proof-mekeonijeum",
    "title": "Celestia의 데이터 가용성 증명(Data Availability Proof) 메커니즘",
    "excerpt": "Celestia의 데이터 가용성 증명(Data Availability Proof) 메커니즘 Celestia는 블록체인 확장성 문제를 해결하기 위해 데이터 가용성 증명(Data Availability Proof) 메커니즘을 핵심으로 사용합니다. 이 메커니즘은 모든...",
    "content": "# Celestia의 데이터 가용성 증명(Data Availability Proof) 메커니즘\n\nCelestia는 블록체인 확장성 문제를 해결하기 위해 데이터 가용성 증명(Data Availability Proof) 메커니즘을 핵심으로 사용합니다. 이 메커니즘은 모든 노드가 전체 블록체인 데이터를 저장하지 않고도 데이터가 네트워크에 실제로 게시되었는지 확인할 수 있게 합니다.\n\n## 1. 데이터 가용성 문제\n\n기존 블록체인에서는 모든 노드가 모든 트랜잭션을 검증하고 저장해야 하므로 확장성에 한계가 있습니다. Celestia는 \"데이터 가용성 샘플링(Data Availability Sampling, DAS)\"이라는 기술을 통해 이 문제를 해결합니다.\n\n## 2. 핵심 기술 구성요소\n\n### 2.1 Extended Data Square (EDS)\n\n블록 데이터는 다음과 같은 과정으로 처리됩니다:\n\n1. **데이터 정렬**: 트랜잭션 데이터를 정사각형 형태(Original Data Square, ODS)로 배열합니다.\n2. **2D Reed-Solomon 인코딩**: ODS에 Reed-Solomon 오류 정정 코드를 적용하여 확장된 데이터 사각형(EDS)을 생성합니다.\n3. **사분면 구조**: EDS는 4개의 사분면으로 구성됩니다:\n   - Q1(좌상단): 원본 데이터(ODS)\n   - Q2(우상단): 행 패리티 데이터\n   - Q3(좌하단): 열 패리티 데이터\n   - Q4(우하단): 행+열 패리티 데이터\n\n```go\n// core/eds.go에서\nfunc extendBlock(data *types.Data, appVersion uint64, options ...nmt.Option) (*rsmt2d.ExtendedDataSquare, error) {\n    // 블록 데이터를 EDS로 확장하는 과정\n}\n```\n\n### 2.2 데이터 가용성 샘플링(DAS)\n\n경량 노드는 전체 블록을 다운로드하지 않고 EDS의 임의의 위치에서 소수의 샘플만 요청합니다:\n\n1. **무작위 샘플링**: 노드는 EDS의 무작위 위치에서 여러 개의 샘플(share)을 요청합니다.\n2. **통계적 검증**: 충분한 수의 샘플이 성공적으로 검색되면, 높은 확률로 전체 데이터가 가용하다고 결론지을 수 있습니다.\n3. **이론적 기반**: 데이터의 일부가 누락된 경우, 무작위 샘플링을 통해 높은 확률로 누락된 부분을 감지할 수 있습니다.\n\n### 2.3 Namespaced Merkle Tree (NMT)\n\nCelestia는 데이터를 네임스페이스(namespace)로 구분하여 구조화합니다:\n\n1. **데이터 분류**: 트랜잭션 데이터를 네임스페이스별로 분류합니다.\n2. **효율적인 검증**: 노드는 특정 네임스페이스의 데이터만 선택적으로 검증할 수 있습니다.\n3. **증명 최적화**: NMT는 특정 네임스페이스 데이터에 대한 증명 크기를 최적화합니다.\n\n## 3. 데이터 가용성 증명 프로세스\n\n### 3.1 블록 생성 및 제안\n\n1. 블록 제안자는 트랜잭션을 수집하여 블록을 구성합니다.\n2. 트랜잭션 데이터를 ODS 형태로 정렬합니다.\n3. 2D Reed-Solomon 인코딩을 적용하여 EDS를 생성합니다.\n4. 블록 헤더에 데이터 해시(Merkle root)를 포함시켜 네트워크에 제안합니다.\n\n### 3.2 경량 노드의 검증 과정\n\n1. 경량 노드는 블록 헤더를 받습니다.\n2. EDS의 무작위 위치에서 다수의 샘플을 요청합니다.\n3. 샘플이 Merkle root와 일치하는지 검증합니다.\n4. 충분한 샘플(일반적으로 수백 개)이 성공적으로 검증되면, 전체 데이터가 가용하다고 판단합니다.\n\n```go\n// 경량 노드의 샘플링 요청 처리 과정 (개념적 코드)\nfunc (odsq4 *ODSQ4) Sample(ctx context.Context, coords shwap.SampleCoords) (shwap.Sample, error) {\n    // 요청된 좌표에서 샘플 데이터 검색\n}\n```\n\n### 3.3 데이터 복구 능력\n\nEDS의 Reed-Solomon 속성 덕분에:\n\n1. 전체 EDS의 약 25%만 있으면 전체 데이터를 복구할 수 있습니다.\n2. 충분한 수의 노드가 샘플링을 수행하면, 네트워크 전체적으로 데이터 복구가 가능한 수준의 샘플이 존재합니다.\n\n```go\n// store/file/square.go에서\nfunc (s square) computeAxisHalf(axisType rsmt2d.Axis, axisIdx int) (eds.AxisHalf, error) {\n    // Reed-Solomon 인코딩을 사용하여 누락된 데이터 복구\n}\n```\n\n## 4. 저장 최적화\n\nCelestia는 모든 노드가 모든 데이터를 저장할 필요가 없도록 설계되었습니다:\n\n1. **선택적 저장**: 풀 노드는 블록 데이터의 ODS 부분만 저장합니다.\n2. **시간 기반 전략**: 가용성 윈도우 내의 최근 블록은 ODSQ4 형태(ODS+Q4)로 저장하고, 오래된 블록은 ODS 형태로만 저장합니다.\n\n```go\n// core/eds.go에서\nfunc storeEDS(ctx context.Context, eh *header.ExtendedHeader, eds *rsmt2d.ExtendedDataSquare, store *store.Store, window time.Duration, archival bool) error {\n    if availability.IsWithinWindow(eh.Time(), window) {\n        // 가용성 윈도우 내의 블록은 ODS와 Q4 모두 저장\n        err = store.PutODSQ4(ctx, eh.DAH, eh.Height(), eds)\n    } else {\n        // 오래된 블록은 ODS만 저장\n        err = store.PutODS(ctx, eh.DAH, eh.Height(), eds)\n    }\n}\n```\n\n## 5. 장점 및 의의\n\n1. **확장성 향상**: 경량 노드는 전체 블록을 다운로드하지 않고도 데이터 가용성을 검증할 수 있습니다.\n2. **보안 유지**: 충분한 샘플링을 통해 높은 확률로 데이터 가용성을 보장합니다.\n3. **모듈식 설계**: 데이터 가용성 레이어를 실행 레이어(execution layer)와 분리하여 모듈식 블록체인 설계를 가능하게 합니다.\n4. **롤업 확장**: Celestia의 데이터 가용성 레이어는 다양한 롤업(rollup)의 기반 레이어로 활용될 수 있습니다.\n\nCelestia의 데이터 가용성 증명 메커니즘은 블록체인의 \"데이터 가용성 문제\"를 효율적으로 해결하여, 확장성을 크게 향상시키면서도 보안을 유지하는 혁신적인 접근 방식입니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 3,
    "wordCount": 592,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "celestia의-eds-extended-data-square",
    "slug": "celestiayi-eds-extended-data-square",
    "path": "blockchain/celestia",
    "fullPath": "blockchain/celestia/celestiayi-eds-extended-data-square",
    "title": "Celestia의 EDS(Extended Data Square)",
    "excerpt": "EDS(Extended Data Square)란? EDS는 Celestia의 데이터 가용성(Data Availability) 보장 메커니즘의 핵심 구조입니다. EDS는 원본 데이터를 2D 사각형으로 구성한 후, Reed-Solomon 오류 정정 코딩을 적용하여...",
    "content": "## EDS(Extended Data Square)란?\n\nEDS는 Celestia의 데이터 가용성(Data Availability) 보장 메커니즘의 핵심 구조입니다. EDS는 원본 데이터를 2D 사각형으로 구성한 후, Reed-Solomon 오류 정정 코딩을 적용하여 확장된 2차원 데이터 구조를 말합니다.\n\n```mermaid\ngraph LR\n    Q1[\"🟦 Q1: ODS<br/>원본 데이터\"] --- Q2[\"🟩 Q2: Row Parity<br/>행 패리티\"] --- Q3[\"🟨 Q3: Col Parity<br/>열 패리티\"] --- Q4[\"🟪 Q4: Row+Col Parity<br/>행+열 패리티\"]\n```\n\n> **Extended Data Square (EDS)**: 원본 데이터(Q1)를 Reed-Solomon 인코딩하여 행/열/대각선 패리티(Q2, Q3, Q4)를 생성한 2D 구조\n\n## EDS의 구조와 특징\n\n1. **사분면 구조**:\n   - **Q1 (좌상단)**: 원본 데이터 사각형(ODS - Original Data Square)\n   - **Q2 (우상단)**: 행 패리티 데이터(Row Parity) - 행 단위 복구 가능\n   - **Q3 (좌하단)**: 열 패리티 데이터(Column Parity) - 열 단위 복구 가능\n   - **Q4 (우하단)**: 행과 열 패리티 데이터(Row+Column Parity) - 특정 복구 시나리오에서 필요\n\n2. **2D Reed-Solomon 인코딩**:\n   - 행과 열 모두에 대해 Reed-Solomon 인코딩 적용\n   - 25% 이상의 데이터가 사용 가능하면 전체 데이터 복구 가능\n\n3. **데이터 단위**:\n   - **Share**: 기본 데이터 단위. 고정 크기의 바이트 배열\n   - **Square**: n×n 크기의 Share 배열\n\n## EDS 관련 주요 기능\n\n첨부된 코드 스니펫에서 볼 수 있는 주요 기능들:\n\n### 1. EDS 생성\n\n```go\nfunc extendBlock(data *types.Data, appVersion uint64, options ...nmt.Option) (*rsmt2d.ExtendedDataSquare, error)\n```\n\n- 블록 데이터를 EDS로 확장합니다.\n- 트랜잭션 데이터를 2D 사각형으로 구성한 후 Reed-Solomon 인코딩을 적용합니다.\n\n```go\nfunc extendShares(s [][]byte, options ...nmt.Option) (*rsmt2d.ExtendedDataSquare, error)\n```\n\n- Share의 배열을 EDS로 확장합니다.\n\n### 2. EDS 저장\n\n```go\nfunc storeEDS(\n    ctx context.Context,\n    eh *header.ExtendedHeader,\n    eds *rsmt2d.ExtendedDataSquare,\n    store *store.Store,\n    window time.Duration,\n    archival bool,\n) error\n```\n\n- EDS를 저장합니다.\n- 가용성 윈도우 내에 있으면 ODS와 Q4 모두 저장(ODSQ4)\n- 가용성 윈도우 밖에 있으면 ODS만 저장\n\n## file 패키지와 EDS의 관계\n\n앞서 설명한 file 패키지는 EDS의 저장 및 접근 메커니즘을 제공합니다:\n\n1. **ODS**: EDS의 Q1 사분면(원본 데이터)만 저장하는 방식\n2. **ODSQ4**: ODS와 Q4 사분면을 함께 저장하는 방식\n   - 일부 쿼리 및 데이터 복구에 더 효율적\n   - 저장 공간을 더 필요로 함\n\n## EDS의 Celestia에서의 역할\n\n1. **데이터 가용성 검증**:\n   - 노드들은 EDS의 임의 샘플을 요청하여 데이터 가용성 검증\n   - 충분한 샘플이 확인되면 전체 블록이 가용하다고 판단\n\n2. **데이터 복구**:\n   - 일부 데이터만으로 전체 데이터 복구 가능\n   - 네트워크 효율성 향상: 전체 블록이 아닌 일부만 다운로드해도 됨\n\n3. **저장 최적화**:\n   - 모든 노드가 전체 EDS를 저장할 필요 없음\n   - 일반 노드는 ODS만 저장해도 충분\n   - 가용성 보장이 필요한 최근 블록만 ODSQ4 형태로 저장\n\n## 실제 구현에서의 고려사항\n\n1. **가용성 윈도우**:\n\n   ```go\n   if availability.IsWithinWindow(eh.Time(), availability.StorageWindow) {\n       err = store.PutODSQ4(ctx, eh.DAH, eh.Height(), eds)\n   } else {\n       err = store.PutODS(ctx, eh.DAH, eh.Height(), eds)\n   }\n   ```\n\n   - 최근 블록(가용성 윈도우 내)에 대해서만 ODSQ4 방식으로 저장\n   - 오래된 블록은 ODS 방식으로만 저장하여 디스크 공간 절약\n\n2. **성능 최적화**:\n   - 캐싱 및 버퍼링을 통한 I/O 최적화\n   - Q4 지연 로딩(필요할 때만 로드)\n   - Reed-Solomon 인코더 캐싱\n\nEDS는 Celestia의 데이터 가용성 레이어의 핵심 구성 요소로, 블록체인의 데이터 확장성과 가용성을 동시에 해결하기 위한 중요한 구조입니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 3,
    "wordCount": 465,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "celestia가-트랜잭션-배열을-ods로-변환하는-방법",
    "slug": "celestiaga-teuraenjaegsyeon-baeyeoleul-odsro-byeonhwanhaneun-bangbeob",
    "path": "blockchain/celestia",
    "fullPath": "blockchain/celestia/celestiaga-teuraenjaegsyeon-baeyeoleul-odsro-byeonhwanhaneun-bangbeob",
    "title": "Celestia가 트랜잭션 배열을 ODS로 변환하는 방법",
    "excerpt": "핵심 개념 Share (공간단위) Celestia의 기본 데이터 단위(512바이트) 네임스페이스 ID를 포함한 원시 데이터 저장 각 Share는 특정 네임스페이스에 속하며, 정보 바이트와 버전을 포함 Square (사각형) 데...",
    "content": "## 1. 핵심 개념\n\n### Share (공간단위)\n- Celestia의 기본 데이터 단위(512바이트)\n- 네임스페이스 ID를 포함한 원시 데이터 저장\n- 각 Share는 특정 네임스페이스에 속하며, 정보 바이트와 버전을 포함\n\n### Square (사각형)\n- 데이터의 2D 정사각형 배열로, 항상 변의 길이가 2의 제곱수\n- Share들의 집합으로 구성\n- 최종적인 데이터 가용성 계층의 구조\n\n### 트랜잭션 유형\n- 일반 트랜잭션: 기본 트랜잭션\n- PFB(Pay-for-Blob) 트랜잭션: 블롭 데이터를 포함하거나 참조하는 특수 트랜잭션\n\n## 2. 변환 프로세스\n\n### 초기화 (Builder 생성)\n```go\nbuilder, err := NewBuilder(maxSquareSize, subtreeRootThreshold)\n```\n- `maxSquareSize`: 최대 사각형 크기(2의 제곱수)\n- `subtreeRootThreshold`: 서브트리 루트 임계값 설정\n\n### 트랜잭션 처리 순서\n1. **트랜잭션 분류**: 입력된 트랜잭션을 일반 트랜잭션과 blob 트랜잭션으로 분류\n2. **트랜잭션 배치**: 일반 트랜잭션을 먼저 배치한 후 PFB 트랜잭션 배치\n\n### Share 분할 프로세스\n1. **Compact Share 사용**: 일반 트랜잭션과 PFB 트랜잭션을 Compact Share로 변환\n   ```go\n   txWriter := share.NewCompactShareSplitter(share.TxNamespace, share.ShareVersionZero)\n   pfbWriter := share.NewCompactShareSplitter(share.PayForBlobNamespace, share.ShareVersionZero)\n   ```\n\n2. **Sparse Share 사용**: Blob 데이터는 Sparse Share로 변환\n   ```go\n   blobWriter := share.NewSparseShareSplitter()\n   ```\n\n3. **Blob 정렬 및 배치**:\n   - 네임스페이스 기준으로 Blob 정렬\n   - Share commitment 규칙에 맞게 패딩 추가\n   - 첫 Blob의 시작 위치가 nonReservedStart 결정\n\n4. **패딩 추가**:\n   - 네임스페이스 패딩: 트랜잭션과 PFB 사이\n   - 테일 패딩: 사각형 크기를 맞추기 위해 추가\n\n### 사각형 생성\n```go\nsquare, err := WriteSquare(txWriter, pfbWriter, blobWriter, nonReservedStart, squareSize)\n```\n\n1. **사각형 크기 결정**:\n   - 필요한 최소 크기 계산 (`inclusion.BlobMinSquareSize`)\n   - 트랜잭션, PFB, 블롭 데이터를 모두 수용할 수 있는 2의 제곱수로 크기 설정\n\n2. **데이터 배치**:\n   - 일반 트랜잭션 → PFB 트랜잭션 → 패딩 → Blob 데이터 → 테일 패딩 순으로 배치\n   - 네임스페이스별로 데이터 구분 (TxNamespace, PayForBlobNamespace 등)\n\n## 3. 주요 최적화 및 특징\n\n### 메모리 효율성\n- Share Counter를 사용하여 정확한 크기 계산\n- 필요한 만큼만 패딩 추가로 공간 최적화\n\n### 네임스페이스 구분\n- 각 데이터 유형에 맞는 네임스페이스 할당\n- 이를 통해 데이터 유형별 검색 및 접근 용이\n\n### 머클 트리 최적화\n- 서브트리 임계값 설정으로 머클 트리 구조 최적화\n- 블롭 데이터 위치 조정으로 효율적인 증명 생성\n\n### Share commitment 규칙 \n- 각 Blob의 시작 위치는 Share commitment 규칙에 따라 결정\n- 이는 데이터 가용성 검증을 위한 효율적인 증명을 가능하게 함\n\n## 세부 스펙에 대한 Note\n\n## 1. maxSquareSize와 원본/패리티 share 관계\n\n- **ODS(Original Data Square)**: 모든 share가 원본 데이터입니다. 여기서는 트랜잭션, PFB, 블롭 데이터, 그리고 필요한 패딩만 포함됩니다. 이 단계에서는 패리티 데이터가 없습니다.\n\n- **EDS(Extended Data Square)**: ODS를 2D 리드-솔로몬 인코딩으로 확장한 것으로, 이 때 패리티 데이터가 추가됩니다. 이는 코드베이스의 다른 부분에서 처리됩니다.\n\nODS의 크기가 2^n x 2^n인 이유는:\n1. 머클 트리 구성의 효율성 \n2. 데이터 가용성 샘플링(DAS)의 효율성\n3. 2D 리드-솔로몬 인코딩의 요구사항\n\n## 2. share 크기와 square 크기 제한\n\n- **share 크기**: 각 share는 512바이트로 고정되어 있습니다. 이는 코드에서 `ShareSize` 상수로 정의됩니다.\n\n- **square 크기 제한**: 이론적으로는 2의 제곱수로 무한히 커질 수 있지만, 실제로는 제한이 있습니다. 코드를 보면:\n\n  ```go\n  // worstCaseShareIndexes 함수에서\n  squareSizeUpperBound := 128\n  worstCaseShareIndex := squareSizeUpperBound * squareSizeUpperBound\n  ```\n\n  이 부분에서 최대 square 크기를 128x128(16,384 shares)로 제한하고 있음을 알 수 있습니다. 이는 Celestia-app v1.x와의 호환성을 위한 것입니다.\n\n  또한 각 노드의 메모리 제한, 네트워크 처리량, 블록 시간 등 실용적인 제약 요소들도 최대 square 크기를 제한합니다. 128x128 square는 약 **8MB**(512바이트 * 16,384)의 데이터를 담을 수 있으며, 이는 현재 구현의 실용적인 상한선입니다.\n\n결론적으로, share 크기는 고정되어 있고 square 크기는 이론적으로는 2의 제곱수로 확장 가능하지만 실제 구현에서는 제한이 있습니다.\n\nRef: https://github.com/celestiaorg/go-square",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 3,
    "wordCount": 541,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "celestia-데이터-가용성-샘플링-das-분석",
    "slug": "celestia-deiteo-gayongseong-saempeulring-das-bunseog",
    "path": "blockchain/celestia",
    "fullPath": "blockchain/celestia/celestia-deiteo-gayongseong-saempeulring-das-bunseog",
    "title": "Celestia 데이터 가용성 샘플링(DAS) 분석",
    "excerpt": "데이터 가용성 샘플링(DAS)에서 샘플 수량 결정 방식 라이트 노드의 샘플링 설정 share/availability/light/options.go 파일에서, 라이트 노드의 기본 샘플 수량이 16개로 정의되어 있습니다. ``` // D...",
    "content": "**데이터 가용성 샘플링(DAS)에서 샘플 수량 결정 방식**\n\n1. **라이트 노드의 샘플링 설정**\n\n- share/availability/light/options.go 파일에서, 라이트 노드의 기본 샘플 수량이 **16개**로 정의되어 있습니다.\n\n```\n// DefaultSampleAmount는 라이트 노드가 블록이 사용 가능하다고 선언하기 전에 수행해야 하는 최소 샘플 수를 지정합니다.\nvar (\n    DefaultSampleAmount uint = 16\n)\n```\n\n1. **DAS 관련 주요 매개변수**\n\n- das/options.go 파일의 DefaultParameters() 함수에서 DAS의 기본 설정을 확인할 수 있습니다.\n\n```\n// DefaultParameters는 daser(샘플링 모듈)의 기본 설정값을 반환합니다.\nfunc DefaultParameters() Parameters {\n    concurrencyLimit := 16\n    return Parameters{\n        SamplingRange: 100,\n        ConcurrencyLimit: concurrencyLimit,\n        BackgroundStoreInterval: 10 * time.Minute,\n        SampleFrom: 1,\n        SampleTimeout: 15 * time.Second * time.Duration(concurrencyLimit),\n    }\n}\n```\n\n여기서 SamplingRange: 100은 한 번의 샘플링 작업에서 **최대 100개의 헤더를 처리할 수 있음을 의미**하지만, 블록당 샘플 수량을 직접적으로 정의하는 것은 아닙니다.\n\n1. **무작위 샘플링 구현 방식**\n\n- share/availability/light/sample.go 파일의 selectRandomSamples 함수는 데이터 정사각형(squares)에서 무작위로 샘플을 선택하는 방식을 보여줍니다.\n\n```\n// selectRandomSamples는 주어진 크기의 정사각형에서 무작위로 고유한 좌표를 선택합니다.\nfunc selectRandomSamples(squareSize, sampleCount int) []shwap.SampleCoords {\n    total := squareSize * squareSize\n    if sampleCount > total {\n        sampleCount = total\n    }\n    \n    samples := make(map[shwap.SampleCoords]struct{}, sampleCount)\n    for len(samples) < sampleCount {\n        s := shwap.SampleCoords{\n            Row: randInt(squareSize),\n            Col: randInt(squareSize),\n        }\n        samples[s] = struct{}{}\n    }\n    return slices.Collect(maps.Keys(samples))\n}\n```\n\n위 코드에서 **샘플링 개수는 블록 데이터의 정사각형 크기에 따라 다르며**, 주어진 개수만큼 무작위로 선택됩니다.\n\n1. **라이트 노드의 데이터 가용성 확인 과정**\n\n- share/availability/light/availability.go 파일의 SharesAvailable 메서드를 살펴보면, 특정 블록 헤더에 대한 기존 샘플링 결과가 없을 경우 새로운 샘플링을 수행하는 것을 확인할 수 있습니다.\n\n```\nsamples = NewSamplingResult(len(dah.RowRoots), int(la.params.SampleAmount))\n```\n\n여기서 dah.RowRoots의 길이(즉, 데이터 정사각형의 크기)와 **설정된 샘플 수량(기본값: 16개)** 을 기반으로 샘플링이 이루어집니다.\n\n---\n\n**16KB 블록의 샘플 수량 분석**\n\nCelestia에서 **16KB 블록의 샘플링 방식**은 다음과 같습니다.\n\n1. **라이트 노드의 기본 샘플 수량**\n- 기본적으로 라이트 노드는 **블록 크기에 상관없이 16개의 샘플을 사용**합니다.\n\n1. **16KB 블록의 경우 샘플링 과정**\n\n- 16KB 블록은 주어진 블록 크기에 따라 정사각형 형태로 변환됩니다.\n- 보통 **4×4(16개)의 공유 데이터(share)로 나뉘어 저장**됩니다.\n- 라이트 노드는 이 **16개의 공유 데이터 중 16개를 무작위로 선택하여 샘플링**합니다.\n- 이렇게 선택된 샘플을 통해 블록이 네트워크에서 제대로 전파되었는지를 확인합니다.\n\n1. **풀 노드(Full Node) vs. 라이트 노드(Light Node)**\n\n- share/doc.go 파일에 따르면, 라이트 노드는 **16개의 샘플만 사용하여 가용성을 확인**하지만, 풀 노드는 전체 데이터를 다운로드하여 가용성을 검증합니다.\n\n```\n// Light Availability 구현은 블록 데이터의 16개 샘플을 확인하여 가용성을 검증합니다.\n// Full Availability 구현은 데이터를 완전히 복구할 수 있을 만큼의 샘플을 다운로드합니다.\n```\n\n---\n\n**결론: 샘플 수량 분석 요약**\n\n1. **라이트 노드의 기본 샘플 수량은 16개**\n\n- share/availability/light/options.go에서 기본값으로 16개 설정\n- 블록 크기와 상관없이 동일한 수량으로 샘플링 진행\n\n1. **16KB 블록에서는 전체 데이터 공유 개수가 16개이므로, 전체를 샘플링**\n\n- 블록이 4×4 정사각형으로 변환되며, 16개 중 16개를 샘플링\n- 16개만 샘플링해도 충분한 확률로 가용성을 검증할 수 있음\n\n👉 **결론적으로, Celestia의 라이트 노드는 기본적으로 블록당 16개의 샘플을 추출하여 데이터 가용성을 검증하도록 설계되어 있습니다.** 🚀\n\n### 데이터 가용성 샘플링의 확률적 보장\n\nCelestia의 데이터 가용성 샘플링(DAS)에서 16개의 샘플은 다음과 같은 확률적 보장을 제공합니다:\n\n#### 이론적 배경\n\n데이터 가용성 샘플링은 정보 이론과 확률론에 기반합니다. 특히 \"샘플링 게임\" 이론에 따르면:\n\n- 블록 생성자가 데이터의 일부(예: 50%)를 숨기면, 무작위로 선택된 각 샘플이 그 숨겨진 부분을 발견할 확률은 50%입니다.\n    \n- 16개의 독립적인 샘플을 선택할 경우, 숨겨진 데이터를 하나도 발견하지 못할 확률은 $(0.5)^{16} = 0.0000152587890625$, 즉 약 0.0015%입니다.\n    \n- 이는 반대로 말하면, 데이터의 50%가 누락된 경우 16개의 샘플로 99.9985%의 확률로 최소 하나 이상의 문제를 발견할 수 있다는 뜻입니다.\n    \n\n#### 샘플 수와 보안성 사이의 관계\n\n실제 코드에서 DefaultSampleAmount가 16으로 설정된 이유는 다음과 같습니다:\n\n1. **공격자의 데이터 은닉 비율에 따른 탐지 확률**:\n    \n    - 25% 데이터 은닉: 16개 샘플로 약 99.9999% 탐지 확률\n        \n    - 10% 데이터 은닉: 16개 샘플로 약 82% 탐지 확률\n        \n2. **효율성과 보안성의 균형**:  \n    샘플 수가 증가할수록 보안성은 향상되지만, 네트워크 부하와 처리 시간도 증가합니다. 16개의 샘플은 다음을 고려한 균형점입니다:\n    \n    - 네트워크 부하 최소화\n        \n    - 충분한 보안 레벨 제공\n        \n    - 경량 노드에 적합한 계산 부담\n        \n3. **네트워크 전체의 집단적 검증**:  \n    개별 노드는 16개 샘플만 검사하지만, 수천 개의 노드가 각각 다른 무작위 샘플을 검사함으로써 네트워크 전체적으로는 모든 데이터가 검증됩니다.\n    \n\n#### 실제 보안성\n\n실제 Celestia 네트워크에서는 공격자가 데이터의 작은 부분만 숨기더라도, 충분한 수의 노드가 샘플링을 수행하면 높은 확률로 탐지됩니다. 여러 노드에서 각각 16개의 샘플을 취하면, 네트워크 전체적으로는 훨씬 더 높은 보안성을 달성합니다.\n\n따라서 16개의 샘플은 단일 라이트 노드에서 리소스 효율성과 적절한 보안성을 균형 있게 제공하는 수치이며, 네트워크 전체적으로는 매우 높은 수준의 데이터 가용성 보장을 제공합니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 4,
    "wordCount": 692,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "celestia-node-file-패키지-분석",
    "slug": "celestia-node-file-paekiji-bunseog",
    "path": "blockchain/celestia",
    "fullPath": "blockchain/celestia/celestia-node-file-paekiji-bunseog",
    "title": "celestia-node 'file' 패키지 분석",
    "excerpt": "celestia-node 'file' 패키지 분석 Celestia-node repository의 패키지는 Exten Data Square(EDS)라는 데이터 구조를 파일 시스템에 효율적으로 저장하고 접근하기 위한 구현을 제공합니다. 이 패키...",
    "content": "# celestia-node 'file' 패키지 분석\n\nCelestia-node repository의 `store/file` 패키지는 Exten Data Square(EDS)라는 데이터 구조를 파일 시스템에 효율적으로 저장하고 접근하기 위한 구현을 제공합니다. 이 패키지는 데이터의 무결성과 복구 가능성을 보장하면서도 디스크 공간을 최적화하는 방식으로 설계되었습니다.\n\n## 핵심 개념\n\n1. **Original Data Square (ODS)**: 블록체인의 트랜잭션 데이터를 정사각형 형태로 배열한 것으로, EDS의 첫 번째 사분면(Q1)을 구성합니다.\n2. **Extended Data Square (EDS)**: ODS에 Reed-Solomon 인코딩을 적용하여 확장된 2D 데이터 구조입니다. 총 4개의 사분면으로 구성됩니다.\n3. **Q4**: EDS의 네 번째 사분면으로, 행과 열 모두에 패리티가 적용된 데이터를 저장합니다.\n4. **Share**: 데이터의 기본 단위로, 고정 크기의 바이트 배열입니다.\n\n## 저장 전략과 공간 효율성\n\nCelestia는 저장 공간을 효율적으로 사용하기 위해 두 가지 저장 전략을 사용합니다:\n\n1. **ODS만 저장**: 트랜잭션 데이터(ODS)만 저장하는 방식으로, EDS 전체 크기의 약 1/4에 해당하는 저장 공간을 사용합니다. 오래된 블록이나 아카이브 목적의 저장에 주로 사용됩니다.\n2. **ODSQ4 저장**: ODS와 Q4 사분면을 함께 저장하는 방식으로, EDS 전체 크기의 약 1/2에 해당하는 저장 공간을 사용합니다. 가용성 윈도우(availability window) 내의 최근 블록에 사용하여 특정 데이터 접근 패턴에서 계산 효율성을 향상시킵니다.\n\n가용성 윈도우는 데이터 가용성 검증이 더 중요한 최근 블록들을 구분하는 시간적 경계로, 이 기간 내의 블록은 ODSQ4 방식으로, 그 외의 블록은 ODS 방식으로 저장됩니다.\n\n## 핵심 구성요소와 기능\n\n다음은 패키지의 주요 구조체와 그 관계를 mermaid 다이어그램으로 정리한 것입니다:\n\n```mermaid\nclassDiagram\n    class ODS {\n        -headerV0 hdr\n        -os.File fl\n        -sync.RWMutex lock\n        -square ods\n        -bool disableCache\n        +Size(context.Context) int\n        +DataHash(context.Context) (share.DataHash, error)\n        +AxisRoots(context.Context) (*share.AxisRoots, error)\n        +Close() error\n        +Sample(context.Context, shwap.SampleCoords) (shwap.Sample, error)\n        +AxisHalf(context.Context, rsmt2d.Axis, int) (eds.AxisHalf, error)\n        +RowNamespaceData(context.Context, libshare.Namespace, int) (shwap.RowNamespaceData, error)\n        +Shares(context.Context) ([]libshare.Share, error)\n        +Reader() (io.Reader, error)\n    }\n\n    class q4 {\n        -headerV0 hdr\n        -os.File file\n        +close() error\n        +axisHalf(rsmt2d.Axis, int) (eds.AxisHalf, error)\n    }\n\n    class ODSQ4 {\n        -ODS ods\n        -string pathQ4\n        -sync.Mutex q4Mu\n        -atomic.Bool q4OpenAttempted\n        -q4 q4\n        +Size(context.Context) int\n        +DataHash(context.Context) (share.DataHash, error)\n        +AxisRoots(context.Context) (*share.AxisRoots, error)\n        +Sample(context.Context, shwap.SampleCoords) (shwap.Sample, error)\n        +AxisHalf(context.Context, rsmt2d.Axis, int) (eds.AxisHalf, error)\n        +RowNamespaceData(context.Context, libshare.Namespace, int) (shwap.RowNamespaceData, error)\n        +Shares(context.Context) ([]libshare.Share, error)\n        +Reader() (io.Reader, error)\n        +Close() error\n    }\n\n    class square {\n        +reader() (io.Reader, error)\n        +size() int\n        +shares() ([]libshare.Share, error)\n        +axisHalf(rsmt2d.Axis, int) (eds.AxisHalf, error)\n        +computeAxisHalf(rsmt2d.Axis, int) (eds.AxisHalf, error)\n    }\n\n    class headerV0 {\n        -fileVersion fileVersion\n        -uint16 shareSize\n        -uint16 squareSize\n        -share.DataHash datahash\n        +SquareSize() int\n        +ShareSize() int\n        +Size() int\n        +RootsSize() int\n        +OffsetWithRoots() int\n        +WriteTo(io.Writer) (int64, error)\n        +ReadFrom(io.Reader) (int64, error)\n    }\n\n    class Codec {\n        <<interface>>\n        +Encoder(int) (reedsolomon.Encoder, error)\n    }\n\n    class codecCache {\n        -sync.Map cache\n        +Encoder(int) (reedsolomon.Encoder, error)\n    }\n\n    ODS --* headerV0 : contains\n    ODS --* square : caches\n    q4 --* headerV0 : contains\n    ODSQ4 --* ODS : contains\n    ODSQ4 --* q4 : contains\n    codecCache ..|> Codec : implements\n```\n\n## 주요 컴포넌트 상세 설명\n\n### 1. headerV0 (header.go)\n- 파일의 메타데이터를 저장하는 구조체입니다.\n- 파일 버전, share 크기, square 크기, 데이터 해시 등을 포함합니다.\n- 파일 읽기/쓰기 작업에 필요한 메타데이터를 제공하며, 파일 형식의 버전 관리를 지원합니다.\n\n### 2. ODS (ods.go)\n- Original Data Square(ODS)를 파일 시스템에 저장하고 접근하는 기능을 제공합니다.\n- EDS의 첫 번째 사분면(Q1)을 저장하며, 파일 헤더에 메타데이터를 함께 저장합니다.\n- 성능 최적화를 위한 메모리 캐싱 기능을 제공하여 반복적인 파일 I/O를 줄입니다.\n- `eds.AccessorStreamer` 인터페이스를 구현하여 표준화된 데이터 접근 방식을 제공합니다.\n\n### 3. q4 (q4.go)\n- EDS의 네 번째 사분면(Q4)을 파일 시스템에 저장하고 접근하는 기능을 제공합니다.\n- Q4는 데이터 복구나 특정 유형의 쿼리(특히 Q2, Q4 사분면 샘플링)에 효율적으로 활용됩니다.\n- 파일의 크기 검증 및 오류 처리 기능을 포함합니다.\n\n### 4. ODSQ4 (ods_q4.go)\n- ODS와 Q4를 결합하여 효율적인 데이터 접근을 제공합니다.\n- 첫 번째 요청 시 Q4 파일을 지연 로딩(lazy loading)하여 초기 로딩 시간과 메모리 사용량을 최적화합니다.\n- 샘플링 작업이나 특정 행/열 접근 시 계산 효율성을 높여줍니다.\n- `eds.AccessorStreamer` 인터페이스를 구현하여 ODS와 동일한 인터페이스로 접근 가능합니다.\n\n### 5. square (square.go)\n- 데이터 square를 표현하는 2차원 배열 구조체입니다.\n- share의 행과 열에 쉽게 접근할 수 있는 메소드를 제공합니다.\n- 필요한 데이터를 계산하거나 복구하는 기능을 구현합니다.\n- 병렬 처리를 통해 데이터 복구 성능을 최적화합니다.\n\n### 6. Codec/codecCache (codec.go)\n- Reed-Solomon 인코딩을 위한 인터페이스와 구현을 제공합니다.\n- `reedsolomon.New(ln/2, ln/2, reedsolomon.WithLeopardGF(true))` 형태로 인코더를 생성하여 데이터의 약 25%만으로도 전체 복구가 가능하게 합니다.\n- 인코더를 캐싱하여 반복적인 생성 비용을 줄이고 성능을 최적화합니다.\n\n## 핵심 기능\n\n1. **데이터 저장**: EDS의 일부(ODS와 선택적으로 Q4)를 파일 시스템에 효율적으로 저장합니다.\n2. **데이터 접근**: 저장된 데이터에 다양한 방식(행, 열, 샘플 등)으로 접근할 수 있는 API를 제공합니다.\n3. **데이터 복구**: Reed-Solomon 인코딩을 사용하여 필요한 경우 누락된 데이터를 복구할 수 있으며, EDS 전체의 약 25%만으로도 복구가 가능합니다.\n4. **최적화된 I/O**: 버퍼링, 캐싱, 지연 로딩 등을 통해 파일 I/O 작업을 최적화합니다.\n5. **무결성 검증**: 데이터 해시와 크기 검증을 통해 파일의 무결성을 보장합니다.\n\n## 실제 사용 예시\n\nCelestia 네트워크에서 이 패키지는 다음과 같은 상황에서 활용됩니다:\n\n1. **블록 데이터 저장**: 새로운 블록이 검증되면, 노드는 블록 데이터를 EDS로 확장한 후 저장 전략에 따라 ODS 또는 ODSQ4 형태로 저장합니다.\n\n   ```go\n   // 가용성 윈도우 내의 블록은 ODS와 Q4 모두 저장\n   if availability.IsWithinWindow(eh.Time(), availability.StorageWindow) {\n       err = store.PutODSQ4(ctx, eh.DAH, eh.Height(), eds)\n   } else {\n       // 그 외 블록은 ODS만 저장하여 공간 절약\n       err = store.PutODS(ctx, eh.DAH, eh.Height(), eds)\n   }\n   ```\n\n2. **데이터 가용성 샘플링(DAS)**: 다른 노드로부터 블록 데이터의 특정 샘플을 요청받으면, 저장된 ODS 또는 ODSQ4를 사용하여 요청된 샘플을 효율적으로 제공합니다.\n\n3. **데이터 복구**: 누락된 블록 데이터가 있을 경우, 네트워크의 다른 노드로부터 충분한 샘플을 수집하여 Reed-Solomon 인코딩을 통해 전체 EDS를 복구할 수 있습니다.\n\n이 패키지는 Celestia의 데이터 가용성 레이어의 핵심 구성 요소로, 블록체인의 데이터 확장성 문제를 해결하면서도 데이터의 가용성과 무결성을 보장하는 중요한 역할을 합니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 5,
    "wordCount": 847,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "비트코인-nft와-brc-20-ft",
    "slug": "biteukoin-nftwa-brc-20-ft",
    "path": "blockchain/bitcoin",
    "fullPath": "blockchain/bitcoin/biteukoin-nftwa-brc-20-ft",
    "title": "비트코인 NFT와 BRC-20(FT)",
    "excerpt": "비트코인 NFT와 BRC-20(FT) 연초에 비트코인에서 발행이 가능해졌다는 뉴스가 나왔다. 최근에는 트랜잭션 급증으로 비트코인 네트워크가 혼잡해지고 있다. 본 글에서는 단순했던 비트코인 네트워크에서 어떻게 이더리움같은 , `NF...",
    "content": "# 비트코인 NFT와 BRC-20(FT)\n\n연초에 비트코인에서 `NFT` 발행이 가능해졌다는 뉴스가 나왔다. 최근에는 `brc-20` 트랜잭션 급증으로 비트코인 네트워크가 혼잡해지고 있다.\n본 글에서는 단순했던 비트코인 네트워크에서 어떻게 이더리움같은 `FT`, `NFT`를 발행할 수 있었는지 정리한다.\n\n## 비트코인에서의 Ordinals Protocal (서수체계) 도입과 비트코인 NFT의 출현\n\n[Ordinal Numbers](https://github.com/casey/ord/blob/master/bip.mediawiki)의 제안 동기는 비트코인 애플리케이션에서 사용될 수도 있는 안정적인 식별자를 제공하기 위함이라고 하는데, 이는 비트코인 주소 체계 상 안정적으로 사용할 만한 공개 신원 정보가 없기 때문입니다.\n\n서수체계 도입을 위해 모든 사토시를 채굴된 순서로 일련번호를 지정합니다. 이 숫자를 서수, `ordinal number`로 부릅니다. 구체적인 알고리즘은 다음과 같습니다. 이 코드는 블록체인에서 새 블록의 채굴 보상을 계산하고, 해당 블록에 속한 트랜잭션의 출력값에 일련번호(ordinal)를 부여하는 기능을 수행합니다.\n\n```python\n# subsidy 함수는 블록의 높이(height)를 입력으로 받아 그 높이에 해당하는 블록의 채굴 보상을 계산합니다. \n# 비트코인의 경우, 채굴 보상은 50 BTC로 시작하여 210,000 블록마다 절반으로 줄어들기 때문에, 이 함수는 높이에 따른 보상을 계산하기 위해 이러한 수식을 사용합니다.\ndef subsidy(height):\n  return 50 * 100_000_000 >> height // 210_000\n\n# first_ordinal 함수는 블록의 높이를 입력으로 받아 해당 높이의 첫 번째 트랜잭션 출력값에 할당될 일련번호를 계산합니다. \n# 이 함수는 이전 블록의 모든 출력값에 대한 일련번호를 더하고 블록의 채굴 보상을 더하여 구합니다.\ndef first_ordinal(height):\n  start = 0\n  for height in range(height):\n    start += subsidy(height)\n  return start\n\n# assign_ordinals 함수는 블록을 입력으로 받아, 각 트랜잭션 출력값에 일련번호를 부여합니다. \n# 이 함수는 먼저 블록 채굴 보상에 대한 일련번호를 계산하고, 이어서 블록 내의 모든 트랜잭션에 대해 다음을 수행합니다. \n# 각 트랜잭션의 입력값에서 일련번호를 가져와 출력값에 할당하고, 출력값에 일련번호를 부여합니다. \n# 마지막으로, 채굴 보상 출력값에 일련번호를 할당합니다. \n# 이러한 과정을 통해 블록 내의 모든 출력값에 일련번호가 부여됩니다.\ndef assign_ordinals(block):\n  first = first_ordinal(block.height)\n  last = first + subsidy(block.height)\n  coinbase_ordinals = list(range(first, last))\n\n  for transaction in block.transactions[1:]:\n    ordinals = []\n    for input in transaction.inputs:\n      ordinals.extend(input.ordinals)\n\n    for output in transaction.outputs:\n      output.ordinals = ordinals[:output.value]\n      del ordinals[:output.value]\n\n    coinbase_ordinals.extend(ordinals)\n\n  for output in block.transaction[0].outputs:\n    output.ordinals = coinbase_ordinals[:output.value]\n    del coinbase_ordinals[:output.value]\n```\n\n<br/>\n\n여기에 더해 inscription이 적용되면서 ordinal inscription은 NFT와 유사한 디지털 자산으로 볼 수 있게 되었습니다. 기존의 NFT는 스마트체인 또는 사이드체인의 컨트랙트를 통해 호스팅 되었지만, 비트코인 NFT는 사토시에 바인딩 되어 있기 때문에 사이드 체인이나 별도의 토큰이 필요하지 않습니다.\n\nOrdinals는 단순히 가치 이전만 제공하던 비트코인 네트워크의 새로운 사용 사례를 만들었습니다. 최근 트랜잭션이 늘어나면서 네트워크 비용이 증가하고 기존 비트코인의 단순성을 훼손하는 것이 아니냐는 지적이 있습니다. 그러나 Ordinals의 지지자들은 미래에 블록 보상이 감소하더라도 네트워크 수수료가 비트코인에 대한 해시 파워를 약속하는 주요 인센티브가 될 수 있다고 주장합니다.\n\n## BRC-20의 등장\n\n앞서 설명한 서수의 등장과 탭루트 업그레이드를 통해서 비트코인 블록체인에서 NFT 발행이 가능해졌고, 최근 이를 이용한 BRC-20이 등장하게 되었습니다. BRC-20을 제안한 `domo`가 밝혔듯이, BRC-20은 inscriptions를 활용한 실험이며 아직 진지하게 받아들일 만한 공식 표준이 아닙니다. BRC-20의 기본적인 목적은 서수 이론을 통해 비트코인에 fungibility를 도입할 수 있는지 확인하는 것입니다. 자세한 내용은 [다음 문서](https://domo-2.gitbook.io/brc-20-experiment/)에서 확인할 수 있습니다.\n\n## 참고\n\n1. [비트코인 서수와 NFT - 바이낸스 아카데미](https://academy.binance.com/en/articles/what-are-ordinals-an-overview-of-bitcoin-nfts)\n2. [BRC-20 - domo](https://domo-2.gitbook.io/brc-20-experiment/)\n3. [BRC-20 토큰 - 바이낸스 아카데미](https://academy.binance.com/cs/glossary/brc-20-tokens)\n4. [Ordinal Numbers bip.memiawiki](https://github.com/casey/ord/blob/master/bip.mediawiki)\n5. [Ordinal Theory document](https://docs.ordinals.com/overview.html)\n6. [Bitcoin Taproot - 바이낸스 아카데미](https://academy.binance.com/en/articles/what-is-taproot-and-how-it-will-benefit-bitcoin)",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 3,
    "wordCount": 472,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "spv-simplified-payment-verification",
    "slug": "spv-simplified-payment-verification",
    "path": "blockchain/bitcoin",
    "fullPath": "blockchain/bitcoin/spv-simplified-payment-verification",
    "title": "SPV (Simplified Payment Verification)",
    "excerpt": "SPV (Simplified Payment Verification) SPV란? 거래에 대한 모든 블록체인을 저장하지 않고도 트랜잭션을 검증하는 방법입니다. 라이트 웨이트 노드 또는 경량노드라고도 불립니다. 특징 블록체인의 사본을 보관하지 않...",
    "content": "# SPV (Simplified Payment Verification)\n\n## SPV란?\n\n거래에 대한 모든 블록체인을 저장하지 않고도 트랜잭션을 검증하는 방법입니다. 라이트 웨이트 노드 또는 경량노드라고도 불립니다.\n\n## 특징\n\n-   블록체인의 사본을 보관하지 않고 트랜잭션 검증과정에도 참여하지 않으므로 네트워크 보안에 기여하지 않는다\n-   그러므로 다른 풀노드 정보에 의존하여 거래를 진행한다\n-   블록 헤더 구성\n    -   버전: 4바이트\n    -   이전 블록해시 : 32바이트\n    -   머클루트 해시 : 32바이트\n    -   블록 시간 : 4바이트\n    -   비츠 : 4바이트\n    -   논스값 : 4바이트로 구성되어있으며, 총 80바이트로, 1년 동안 발생하는 52,560개의 블록 헤더 용량이 4MB 정도이니 현재 150GB를 넘긴 풀 노드에 비해 매우 가볍다고 할 수 있다.\n\n## 원리\n\n![merkle-root](https://miro.medium.com/v2/resize:fit:720/format:webp/0*ZLrIO_B67108JStC.jpg)\n\n거래3가 블록에 실렸는지 확인하고 싶다면, 블록 생성 시마다 해당 블록의 머클루트 획득에 필요한 해시들만 가져오면 된다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 118,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "bitcoin-segwit",
    "slug": "bitcoin-segwit",
    "path": "blockchain/bitcoin",
    "fullPath": "blockchain/bitcoin/bitcoin-segwit",
    "title": "Bitcoin Segwit",
    "excerpt": "Bitcoin Segwit 비트코인에서, 거래는 입력(inputs)과 출력(outputs)을 포함합니다. 트랜잭션이 네트워크로 전송될 때 노드에서 트랜잭션의 유효성을 검사하여 트랜잭션이 합법적이고 입력이 이중으로 사용되지 않는지 확인해야 합니다. 원래 비트코인 프...",
    "content": "# Bitcoin Segwit\n\n비트코인에서, 거래는 입력(inputs)과 출력(outputs)을 포함합니다. 트랜잭션이 네트워크로 전송될 때 노드에서 트랜잭션의 유효성을 검사하여 트랜잭션이 합법적이고 입력이 이중으로 사용되지 않는지 확인해야 합니다. 원래 비트코인 프로토콜에서는 디지털 서명(증인 데이터)이 트랜잭션 입력에 포함되어 트랜잭션이 커지고 네트워크 처리량이 감소했습니다. 이를 해결하기 위해 2017년에 분리 증인(SegWit)이라는 새로운 거래 형식이 도입되었습니다. SegWit는 거래의 입력에서 증인 데이터를 분리하여 증인이라는 거래의 별도 섹션에 배치합니다. SegWit 주소는 SegWit 트랜잭션 형식과 호환되는 비트코인 주소입니다. SegWit 주소로 자금을 보낼 때 자금의 소유권을 증명하는 증인을 거래에 포함시킬 수 있습니다. 감시자와 트랜잭션을 만들려면 SegWit 주소를 트랜잭션의 출력 주소로 사용해야 하며, 트랜잭션에 서명할 때 감시자 데이터를 포함해야 합니다. SegWit 트랜잭션의 script_pubkey에는 자금을 사용할 수 있는 조건을 지정하는 감시 프로그램이 포함되어 있으며, SegWit 주소를 만드는 데 사용됩니다.\n\n```rust\nuse bitcoin::{\n    blockdata::transaction::{Transaction, TxIn, TxOut},\n    network::constants::Network,\n    util::bip143::{SigHashCache, SigHashType},\n    PublicKey,\n    Script,\n    TxBuilder,\n    TxInWitness,\n};\n\nfn create_transaction() -> Transaction {\n    // Create inputs\n    let txin = TxIn {\n        previous_output: bitcoin::OutPoint::new(\n            bitcoin::hash::Sha256dHash::default(),\n            0,\n        ),\n        script_sig: Script::new(),\n        sequence: 0xFFFFFFFF,\n        witness: TxInWitness::default(),\n    };\n\n    // Create outputs\n    let txout = TxOut {\n        value: 1000000, // Satoshis\n        script_pubkey: Script::new(),\n    };\n\n    // Create transaction\n    let mut tx_builder = TxBuilder::new();\n    let tx = tx_builder\n        .add_input(txin)\n        .add_output(txout)\n        .build()\n        .unwrap();\n\n    // Sign transaction\n    let key = bitcoin::PrivateKey::from_wif(\"cTJtmP6oZmnBp9jWsnJzBvTuwT54qfN3rq8WxjZgCCzU6DDHMC6N\").unwrap();\n    let public_key = PublicKey::from_private_key(&key, true).unwrap();\n    let sig_hash = SigHashCache::new(&tx).signature_hash(0, &Script::new(), 1000000, SigHashType::All);\n    let signature = key.sign(&sig_hash);\n    let mut witness = TxInWitness::default();\n    witness.push(signature.serialize_der().to_vec());\n    witness.push(public_key.to_bytes());\n    tx_builder.set_witness(0, witness);\n\n    tx\n}\n\nfn main() {\n    let tx = create_transaction();\n    println!(\"{}\", tx);\n}\n```\n\n```toml\n[dependencies]\nbitcoin = \"0.28.1\"\nsecp256k1 = \"0.17.0\"\nhex = \"0.4.2\"\n```\n\n이 예에서는 먼저 하나의 입력과 하나의 출력으로 트랜잭션을 만듭니다. 그런 다음 개인 키를 사용하여 트랜잭션에 서명하고 디지털 서명과 공개 키를 포함하는 증인을 생성합니다. 마지막으로 TxBuilder의 set_witness 메서드를 사용하여 트랜잭션에 대한 감시를 설정하고 트랜잭션을 콘솔에 인쇄합니다.\n\n이 예에서는 트랜잭션에 더미 입력 및 출력을 사용하고 서명에 임의로 생성된 개인 키를 사용했습니다. 실제 응용 프로그램에서는 이 값을 사용 사례의 실제 값으로 대체해야 합니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 2,
    "wordCount": 303,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "bitcoin-script",
    "slug": "bitcoin-script",
    "path": "blockchain/bitcoin",
    "fullPath": "blockchain/bitcoin/bitcoin-script",
    "title": "Bitcoin Script",
    "excerpt": "Bitcoin Script 비트코인은 트랜잭션에 스크립팅 시스템을 사용합니다. 스크립트는 단순하고, 스택 기반이며, 좌에서 우로 진행합니다. 이것은 의도적으로 튜링완전하지 않으며, 루프가 허용되지 않습니다. 스크립트는 본질적으로 각 트랜잭션에 기록된 지시어들의...",
    "content": "# Bitcoin Script\n\n비트코인은 트랜잭션에 스크립팅 시스템을 사용합니다. 스크립트는 단순하고, 스택 기반이며, 좌에서 우로 진행합니다. 이것은 의도적으로 튜링완전하지 않으며, 루프가 허용되지 않습니다.\n\n스크립트는 본질적으로 각 트랜잭션에 기록된 지시어들의 배열이고, 지시어들은 전송되는 비트코인을 사용하려는 다음 사람이 접근 할 수 있는 지를 설명합니다.\n\n일반적으로 비트코인을 수신자 주소로 전송하는 스크립트는 두가지이고 사용자가 제공해야 합니다. 첫번째로 트랜잭션이 해시될 때 스크립트에 포함된 수신자 주소를 생성하는 Public Key, 두번째로 첫번째로 제공한 Public Key에 대응하는 Private Key 소유권을 증명하는 서명입니다.\n\n스크립팅은 전송된 비트코인을 사용하는데 필요한 매개변수를 변경할 수 있는 유연성을 제공합니다. 예를 들어, 스크립팅 시스템을 사용하여 두 개의 개인 키를 요구하거나 여러개의 키를 조합하거나 아예 키를 사용하지 않을 수 있습니다.\n\n트랜잭션은 스크립트 조합에서 에러를 발생하지 않고, 최상위 스택 항목이 True(non-zero)인 경우에 유효합니다.\n\n## 예시\n\n### p2pkh(pay-to-pubkey-hash)\n\n```\nscriptPubKey: OP_DUP OP_HASH160 <pubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nscriptSig: <sig> <pubKey>\n```\n\n| Stack                                             | Script                                                                         | Description                              |\n| ------------------------------------------------- | ------------------------------------------------------------------------------ | ---------------------------------------- |\n| Empty                                             | `<sig>` `<pubKey>` OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG | scriptSig와 scriptPubKey가 결합된다      |\n| `<sig>` `<pubKey>`                                | OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                    | 상수를 스택에 추가한다                   |\n| `<sig>` `<pubKey>` `<pubKey>`                     | OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                           | 최상위 스택 아이템이 복사되었다          |\n| `<sig>` `<pubKey>` `<pubKeyHashA>`                | `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                                      | 최상위 스택 아이템이 해싱되었다          |\n| `<sig>` `<pubKey>` `<pubKeyHashA>` `<pubkeyHash>` | OP_EQUALVERIFY OP_CHECKSIG                                                     | 상수를 스택에 추가한다                   |\n| `<sig>` `<pubKey>`                                | OP_CHECKSIG                                                                    | 최상위 두개 아이템이 동일함을 확인하였다 |\n| true                                              | Empty                                                                          | 최상위 두개 아이템의 서명이 확인되었다   |\n\n### p2wpkh(pay-to-witness-pubkey-hash)\n\n```\nscriptPubKey: OP_0 <pubkey.hash:20>\nscriptSig: Empty.\nwitness: <sig> <pubkey>\n```\n\n| Stack                                             | Script                                                                         | Description                                                                        |\n| ------------------------------------------------- | ------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------- |\n| Empty                                             | OP_0 <pubkey.hash:20>                                                          | scriptSig와 scriptPubKey가 결합된다                                                |\n| Empty                                             | `<sig>` `<pubKey>` OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG | p2wpkh패턴, witness정보의 `<sig>` `<pubkey>`을 통해 `<pubkey.hash:20>`을 치환한다. |\n| `<sig>` `<pubKey>`                                | OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                    | 상수를 스택에 추가한다                                                             |\n| `<sig>` `<pubKey>` `<pubKey>`                     | OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                           | 최상위 스택 아이템이 복사되었다                                                    |\n| `<sig>` `<pubKey>` `<pubKeyHashA>`                | `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                                      | 최상위 스택 아이템이 해싱되었다                                                    |\n| `<sig>` `<pubKey>` `<pubKeyHashA>` `<pubkeyHash>` | OP_EQUALVERIFY OP_CHECKSIG                                                     | 상수를 스택에 추가한다                                                             |\n| `<sig>` `<pubKey>`                                | OP_CHECKSIG                                                                    | 최상위 두개 아이템이 동일함을 확인하였다                                           |\n| true                                              | Empty                                                                          | 최상위 두개 아이템의 서명이 확인되었다                                             |\n\n### p2sh-p2wpkh\n\n```\nscriptPubKey: <OP_HASH160> <script-hash> <OP_EQUAL>\nscriptSig(redeemScript): hash160(<OP_2> <pubkey-a> <pubkey-b> <pubkey-c> <OP_3> <OP_CHECKMULTISIG>)\nwitness: <sig> <pubkey>\n```\n\n| Stack                                             | Script                                                                         | Description                                                                        |\n| ------------------------------------------------- | ------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------- |\n| Empty                                             | `<redeem_script>` OP_HASH160 `<script-hash>` `OP_EQUAL`                        | scriptSig와 scriptPubKey가 결합된다                                                |\n| Empty                                             | `<sig>` `<pubKey>` OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG | p2wpkh패턴, witness정보의 `<sig>` `<pubkey>`을 통해 `<pubkey.hash:20>`을 치환한다. |\n| `<sig>` `<pubKey>`                                | OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                    | 상수를 스택에 추가한다                                                             |\n| `<sig>` `<pubKey>` `<pubKey>`                     | OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                           | 최상위 스택 아이템이 복사되었다                                                    |\n| `<sig>` `<pubKey>` `<pubKeyHashA>`                | `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                                      | 최상위 스택 아이템이 해싱되었다                                                    |\n| `<sig>` `<pubKey>` `<pubKeyHashA>` `<pubkeyHash>` | OP_EQUALVERIFY OP_CHECKSIG                                                     | 상수를 스택에 추가한다                                                             |\n| `<sig>` `<pubKey>`                                | OP_CHECKSIG                                                                    | 최상위 두개 아이템이 동일함을 확인하였다                                           |\n| true                                              | Empty                                                                          | 최상위 두개 아이템의 서명이 확인되었다                                             |\n\n### 미래 특정 시점까지 자금을 동결하고 싶은 경우\n\n```\nscriptPubKey: <expiry-time> OP_CHECKLOCKTIMEVERIFY OP_DROP OP_DUP OP_HASH160 <pubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nscriptSig: <sig> <pubKey>\n```\n\n| Stack                                             | Script                                                                                                                | Description                                                   |\n| ------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- |\n| Empty                                             | `<sig>` `<pubKey>` `<expiry-time>` OP_CHECKLOCKTIMEVERIFY OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG | scriptSig와 scriptPubKey가 결합된다                           |\n| `<sig>` `<pubKey>` `<expiry-time>`                | OP_CHECKLOCKTIMEVERIFY OP_DROP OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                            | 상수를 스택에 추가한다                                        |\n| `<sig>` `<pubKey>` `<expiry-time>`                | OP_DROP OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                                                   | 최상위 스택 아이템를 현재 시간 또는 블록 높이와 비교 확인한다 |\n| `<sig>` `<pubKey>`                                | OP_DUP OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                                                           | 최상위 스택 아이템을 제거한다                                 |\n| `<sig>` `<pubKey>` `<pubKey>`                     | OP_HASH160 `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                                                                  | 최상위 스택 아이템이 복사되었다                               |\n| `<sig>` `<pubKey>` `<pubKeyHashA>`                | `<pubkeyHash>` OP_EQUALVERIFY OP_CHECKSIG                                                                             | 최상위 스택 아이템이 해싱되었다                               |\n| `<sig>` `<pubKey>` `<pubKeyHashA>` `<pubkeyHash>` | OP_EQUALVERIFY OP_CHECKSIG                                                                                            | 상수를 스택에 추가한다                                        |\n| `<sig>` `<pubKey>`                                | OP_CHECKSIG                                                                                                           | 최상위 두개 아이템이 동일함을 확인하였다                      |\n| true                                              | Empty                                                                                                                 | 최상위 두개 아이템의 서명이 확인되었다                        |\n\n### pay-to-multi-signature (2-out-of-3)\n\n```\nscriptPubKey: <OP_2> <pubkey-a> <pubkey-b> <pubkey-c> <OP_3> <OP_CHECKMULTISIG>\nscriptSig: <OP_0> <sig> <sig> <OP_2>\n```\n\n### pay-to-script\n\n```\nscriptPubKey: <OP_HASH160> <script-hash> <OP_EQUAL>\nscriptSig(redeemScript): hash160(<OP_2> <pubkey-a> <pubkey-b> <pubkey-c> <OP_3> <OP_CHECKMULTISIG>)\n```\n\n![](https://learnmeabitcoin.com/technical/images/address/encode-p2sh.png)\n\n위 그림을 보면 중간에 hash160(script)가 있는데 이게 `redeem-script`의 해시값이라고 볼 수 있다. 이것을 base58로 변환했을때 a로 시작하는 P2SH주소 형태로 상대방에게 전달할 수 있습니다.\n\n## Ref\n\n- https://learnmeabitcoin.com/technical/p2sh\n- https://medium.com/programming-bitcoin/chapter-13-세그윗-865a0c3f6414\n- https://dev-notes.eu/2020/11/Bitcoin-Pay-To-Script-Hash/\n- https://bitcoin.design/guide/glossary/address/\n- https://developer.bitcoin.org/reference/rpc/\n- https://en.bitcoin.it/wiki/Category:Technical",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 4,
    "wordCount": 758,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "address",
    "slug": "address",
    "path": "blockchain/bitcoin",
    "fullPath": "blockchain/bitcoin/address",
    "title": "Address",
    "excerpt": "Address 비트코인 주소는 비트코인을 받는 데 사용되는 26-35개의 영숫자 식별자입니다. 서로 다른 사양을 기반으로 하는 여러 주소 형식이 있습니다. 사용자가 주소를 입력할 때 이러한 형식에는 특정 접두사가 있으므로 사용 중인 형식을 확인할 수 있습니다....",
    "content": "# Address\n\n비트코인 주소는 비트코인을 받는 데 사용되는 26-35개의 영숫자 식별자입니다. 서로 다른 사양을 기반으로 하는 여러 주소 형식이 있습니다.\n\n사용자가 주소를 입력할 때 이러한 형식에는 특정 접두사가 있으므로 사용 중인 형식을 확인할 수 있습니다.\n\n다음은 오늘날 사용되는 일반적인 주소 형식입니다:\n\n## Taproot address - P2TR\n\nTaproot 또는 Bech32m 주소라고도 하는 P2TR(Pay-to-Taproot)은 가장 최신의 고급 비트코인 주소 형식입니다. Taproot는 비트코인에 더욱 향상된 보안, 개인 정보 보호, 유연성 및 확장 기능을 제공합니다. SegWit와 마찬가지로 Taproot 주소는 옵트인이며 현재 널리 지원되지 않습니다.\n\nTaproot의 장점은 슈노르 서명(Schnorr Signatures)를 사용할 수 있는 기능, 더 나은 보안, 더 낮은 수수료, 더 유연한 다중 키 트랜잭션을 제공하는 것입니다. P2TR을 사용하는 다중 키 주소는 단일 키 주소와 동일하게 보여 다중 키 사용자에게 향상된 개인 정보를 제공합니다. Taproot는 또한 더 고급 스크립팅을 가능하게 하여 비트코인을 기반으로 더 복잡한 스마트 계약을 구축할 수 있게 합니다.\n\nTaproot 주소는 bc1p로 시작하며 대소문자를 구분하지 않습니다.\n\nExample: bc1pmzfrwwndsqmk5yh69yjr5lfgfg4ev8c0tsc06e\n\n## SegWit address - P2WPKH\n\n네이티브 SegWit 또는 Bech32 주소로도 알려진 P2WPKH(pay-to-witness-public-key-hash)는 현대적이고 보다 효율적인 주소 형식입니다. SegWit 주소는 옵트인이므로 모든 애플리케이션이 이를 지원하는 것은 아니지만 오늘날 대부분이 지원하고 지원해야 합니다. SegWit 채택 여부는 여기에서 확인할 수 있습니다.\n\nSegWit 주소의 이점은 대소문자를 구분하지 않고 오류 수정 코드를 사용하기 때문에 입력 오류에 대한 저항성이 향상되고 트랜잭션 비용이 절감된다는 것입니다. 수수료 절감은 거래 유형에 따라 다르겠지만 일반적인 자금 이체의 경우 30-40%가 될 수 있습니다.\n\nSegWit 주소는 bc1q로 시작하며 대소문자를 구분하지 않습니다.\n\nExample: bc1qar0srrr7xfkvy5l643lydnw9re59gtzzwf5mdq\n\n## Script address - P2SH\n\nP2SH(Pay-to-Script-Hash) 또는 스크립트 주소는 주소에 추가 규칙 및 기능을 첨부할 수 있습니다. 스크립트 주소는 일반적으로 트랜잭션을 인증하는 데 여러 키의 서명이 필요함을 지정할 수 있는 다중 서명 주소에 사용됩니다.\n\n스크립트 주소는 숫자 3으로 시작하고 대문자와 소문자를 포함할 수 있으며 대소문자를 구분합니다.\n\nExample: 3J98t1WpEZ73CNmQviecrnyiWrnqRhWNLy\n\n## Legacy address - P2PKH\n\nP2PKH(pay-to-pubkey-hash) 또는 레거시 주소는 가장 오래되고 원래의 비트코인 주소 형식입니다. 이 주소 형식은 이 형식을 사용하면 트랜잭션 비용이 더 높기 때문에 오늘날 널리 사용되지 않습니다. 그러나 여전히 일부 새로운 주소체계를 적용하지 않은 레거시 애플리케이션이 존재하므로, 이들과의 호환성을 지키는 것이 권장됩니다.\n\nLegacy address는 숫자 1로 시작하고 대문자와 소문자를 포함할 수 있으며 대소문자를 구분합니다.\n\nExample: 1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2\n\n## Address 호환성\n\n레거시 주소가 여전히 사용되고 있기 때문에, 일부 오래된 애플리케이션은 여전히 업그레이드가 필요합니다. 스크립트 주소를 사용하면 송신자의 애플리케이션이 수신자에 의해 제공받은 세그윗 주소를 유효하게 인식하지 못하는 호환성 문제를 해결할 수 있습니다.\n\n그러므로 수신자는 기본적으로 세그윗 주소를 사용한다고 하더라도 송신자의 호환성을 맞춰주기 위해서 스크립트 또는 탭루트 주소로 전환할 수 있어야 합니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 2,
    "wordCount": 386,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "upgrade-move-code",
    "slug": "upgrade-move-code",
    "path": "blockchain/aptos",
    "fullPath": "blockchain/aptos/upgrade-move-code",
    "title": "Upgrade Move code",
    "excerpt": "Upgrade Move code Move code (e.g., Move modules) on the Aptos blockchain can be upgraded. This allows code owners and module developers to update a...",
    "content": "# Upgrade Move code\n\nMove code (e.g., Move modules) on the Aptos blockchain can be upgraded. This\nallows code owners and module developers to update and evolve their contracts\nunder a single, stable, well-known account address that doesn't change. If a\nmodule upgrade happens, all consumers of that module will automatically receive\nthe latest version of the code (e.g., the next time they interact with it).\n\nThe Aptos blockchain natively supports different _upgrade policies_, which allow\nmove developers to explicitly define the constraints around how their move code\ncan be upgraded. The default policy is _(backwards) compatible_. This means that\ncode upgrades are accepted only if they guarantee that no existing resource storage\nor public APIs are broken by the upgrade (including public functions).\nThis compatibility checking is possible because of Move's strongly typed bytecode\nsemantics.\n\nWe note, however, that even compatible upgrades can have hazardous effects on\napplications and dependent Move code (for example, if the semantics of the underlying\nmodule are modified). As a result, developers should be careful when depending on\nthird-party Move code that can be upgraded on-chain. See\n[Security considerations for dependencies](#security-considerations-for-dependencies)\nfor more details.\n\n## How it works\n\nMove code upgrades on the Aptos blockchain happen at the [Move package](https://move-language.github.io/move/packages.html)\ngranularity. A package specifies an upgrade policy in the `Move.toml` manifest:\n\n```toml\n[package]\nname = \"MyApp\"\nversion = \"0.0.1\"\nupgrade_policy = \"compatible\"\n...\n```\n\n:::tip Compatibility check\nAptos checks compatibility at the time a [Move package](https://move-language.github.io/move/packages.html) is published via an Aptos transaction. This transaction will abort if deemed incompatible.\n:::\n\n## How to upgrade\n\nTo upgrade already published Move code, simply attempt to republish the code at\nthe same address that it was previously published. This can be done by following the\ninstructions for code compilation and publishing using the\n[Aptos CLI](../../cli-tools/aptos-cli-tool/use-aptos-cli.md). For an example,\nsee the [Your First Move Module](../../tutorials/first-move-module.md) tutorial.\n\n## Upgrade policies\n\nThere are two different upgrade policies currently supported by Aptos:\n\n- `compatible`: these upgrades must be backwards compatible, specifically:\n  - For storage, all old struct declarations must be the same in\n    the new code. This ensures that the existing state of storage is\n    correctly interpreted by the new code. However, new struct declarations\n    can be added.\n  - For APIs, all existing public functions must have the same signature as\n    before. New functions, including public and entry functions, can be added.\n- `immutable`: the code is not upgradeable and is guaranteed to stay the same\n  forever.\n\nThose policies are ordered regarding strength such that `compatible < immutable`,\ni.e., compatible is weaker than immutable. The policy of a package on-chain can\nonly get stronger, not weaker. Moreover, the policy of all dependencies of a\npackage must be stronger or equal to the policy of the given package. For example,\nan `immutable` package cannot refer directly or indirectly to a `compatible` package.\nThis gives users the guarantee that no unexpected updates can happen under the hood.\n\nNote that there is one exception to the above rule: framework packages\ninstalled at addresses `0x1` to `0xa` are exempted from the dependency check.\nThis is necessary so one can define an `immutable` package based on the standard\nlibraries, which have the `compatible` policy to allow critical upgrades and fixes.\n\n## Compatibility rules\n\nWhen using `compatible` upgrade policy, a module package can be upgraded. However, updates to existing modules already\npublished previously need to be compatible and follow the rules below:\n\n- All existing structs' fields cannot be updated. This means no new fields can be added and existing fields cannot be\n  modified. Struct abilities also cannot be changed (no new ones added or existing removed).\n- All public and entry functions cannot change their signature (argument types, type argument, return types). However,\n  argument names can change.\n- Public(friend) functions are treated as private and thus their signature can arbitrarily change. This is safe as\n  only modules in the same package can call friend functions anyway and they need to be updated if the signature changes.\n\nWhen updating your modules, if you see an incompatible error, make sure to check the above rules and fix any violations.\n\n## Security considerations for dependencies\n\nAs mentioned above, even compatible upgrades can have disastrous effects for\napplications that depend on the upgraded code. These effects can come from bugs,\nbut they can also be the result of malicious upgrades. For example,\nan upgraded dependency can suddenly make all functions abort, breaking the\noperation of your Move code. Alternatively, an upgraded dependency can make\nall functions suddenly cost much more gas to execute then before the upgrade.\nAs result, dependencies to upgradeable packages need to be handled with care:\n\n- The safest dependency is, of course, an `immutable` package. This guarantees\n  that the dependency will never change, including its transitive dependencies.\n  In order to update an immutable package, the owner would have to introduce a\n  new major version, which is practically like deploying a new, separate\n  and independent package. This is because major versioning can be expressed\n  only by name (e.g. `module feature_v1` and `module feature_v2`). However,\n  not all package owners like to publish their code as `immutable`, because this\n  takes away the ability to fix bugs and update the code in place.\n- If you have a dependency to a `compatible` package, it is highly\n  recommended you know and understand the entity publishing the package.\n  The highest level of assurance is when the package is governed by a\n  Decentralized Autonomous Organization (DAO) where no single user can initiate\n  an upgrade; a vote or similar has to be taken. This is the case for the Aptos\n  framework.\n\n## Programmatic upgrade\n\nIn general, Aptos offers, via the Move module `aptos_framework::code`,\nways to publish code from anywhere in your smart contracts. However,\nnotice that code published in the current transaction can be executed\nonly after that transaction ends.\n\nThe Aptos framework itself, including all the on-chain administration logic, is\nan example for programmatic upgrade. The framework is marked as `compatible`.\nUpgrades happen via specific generated governance scripts. For more details,\nsee [Aptos Governance](../../concepts/governance.md).",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 6,
    "wordCount": 1002,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "move-on-aptos",
    "slug": "move-on-aptos",
    "path": "blockchain/aptos",
    "fullPath": "blockchain/aptos/move-on-aptos",
    "title": "Move on Aptos",
    "excerpt": "Move on Aptos 앱토스 블록체인은 합의 프로토콜을 실행하는 밸리데이터 노드들로 구성됩니다. 합의 프로토콜은 Move Virtual Machine()에서 실행될 때 트랜잭션들의 순서와 출력()에 동의합니다. 각 밸리데이터 노드는...",
    "content": "# Move on Aptos\n\n앱토스 블록체인은 합의 프로토콜을 실행하는 밸리데이터 노드들로 구성됩니다. 합의 프로토콜은 Move Virtual Machine(`MoveVM`)에서 실행될 때 트랜잭션들의 순서와 출력(`output`)에 동의합니다. 각 밸리데이터 노드는 현재 블록체인 원장 상태와 함께 트랜잭션을 VM에 대한 입력으로 변환합니다. `MoveVM은` 이 입력을 처리하여 변변경사항(`changeset`) 또는 스토리지 델타를 출력으로 생성합니다. 합의 프로토콜이 동의하고 출력이 커밋되면 이는 공개적으로 보이는 상태가 됩니다.\n\n## What is Move?\n\n`Move`는 희소성과 접근 제어를 강조하는, Web3를 위한 안전하고 보안이 뛰어난 프로그래밍 언어입니다. `Move`의 모든 자산은 리소스로 또는 리소스에 저장되어 표현될 수 있습니다. 희소성은 구조체(`struct`)를 복제할 수 없기 때문에 기본적으로 강제됩니다. 오직 바이트코드 계층에서 명시적으로 복사본(`copy`)으로 정의된 경우에만 복제할 수 있습니다.\n\n접근제어(`Access Control`)는 모듈(`module`) 접근 권한과 계정(`accounts`)의 개념에서 비롯됩니다. `Move`의 모듈은 자산을 생성(`create`), 저장(`store`), 전송(`transfer`)하는 라이브러리 또는 프로그램일 수 있습니다. `Move`는 오직 공개(`public`)모듈 기능(`functions`)들만 다른 모듈에서 접근할 수 있음을 보증합니다. 구조체가 `public`  생성자(`constructor`)를 가진 것이 아니라면, 오직 해당 구조체를 정의하고 있는 모듈에서만 생성될 수 있습니다. 마찬가지로, 구조체 내의 필드는 해당 모듈 내에서 또는 `public` `getter`또는 `setter`를 통해서만 액세스하고 변경할 수 있습니다.\n\n`Move`에서 트랜잭션의 전송자는 특정 `account`의 확인된 소유자인 `signer`로 표현합니다.  `signer`는 `Move`에서 가장 높은 권한 레벨을 가지고 있고 `account`에 `resources`를 추가할 수 있는 유일한 엔티티입니다. 게다가, 모듈 개발자는 `resource`에 접근하거나 계정에 저장된 자산을 수정하기 위해  `signer`가 있어야한다고 요구할 수 있습니다.\n\n## Comparison to other VMs\n\n| | Aptos/Move | Solana/SeaLevel | EVM |\n|--|------|------|------|\n| Data Storage | 소유자의 계정에 저장됨 Stored within the owner's account | 프로그램과 관련된 소유자 계정 내에 저장 Stored within the owner's account associated with a program | 컨트랙트와 관련된 계정내에 저장 Stored within the account associated with a smart contract |\n| Parallelization | 앱토스 내에서 런타임에 병렬화를 추론할 수 있음 Capable of inferring parallelization at runtime within Aptos | 트랜잭션 내에서 액세스하는 모든 계정 및 프로그램을 지정해야 함 Requires specifying within the transaction all accounts and programs accessed | 현재로선 직렬화 하지 않음 Currently serial nothing in production |\n| Transaction safety | Sequence number | 트랜잭션 고유성 + 트랜잭션 기억 Transaction uniqueness + remembering transactions | nonces, similar to sequence numbers |\n| Type safety | Module structs and generics| Program structs | Contract types |\n| Function calling | 제네릭이 아닌 정적 디스패치 Static dispatch not on generics | 정적 디스패치 Static dispatch | 동적 디스패치 Dynamic dispatch |\n\n## Aptos Move features\n\n`MoveVM`의 각 배포는 어댑터 레이어를 통해 코어 `MoveVM`을 추가 기능으로 확장할 수 있는 기능이 있습니다. 또한 `MoveVM`에는 컴퓨터가 `OS`를 가진 것 처럼 표준작업을 지원하는 프레임워크가 있습니다.\n\n`Aptos Move Adapter`에는 아래 기능들이 있습니다.\n- 계정에 저장된 데이터 양을 분리하여 계정과 관련된 트랜잭션의 가스 요금에 영향을 미치는 세분화된 스토리지 (`Fine grained storage`) \n- 크기에 맞게 계정 내에 키, 값 데이터를 저장할 수 있는 `Tables`\n- 사용자의 입력 없이 트랜잭션을 동시에 실행할 수 있는 `Block-STM`을 통한 병렬성\n\n`Aptos framework`는 여러 유용한 라이브러리를 포함합니다.\n- 스마트 계약을 게시하지 않고도 NFT 및 기타 풍부한 토큰을 생성할 수 있는 `Token standard`\n- 가벼운 모듈을 게시하여 안전한 유형의 코인 생성을 가능하게 하는 `Coin standard`\n- 스테이킹 및 위임 프레임워크\n- 주어진 유형의 주소, 모듈 및 구조체 이름을 런타임에 식별하는 `type_of` 서비스\n- 여러 `signer` 엔터티를 허용하는 `Multi-Signer` 프레임워크\n- 실제 현재 유닉스타임에 매핑되는 단조롭게 증가하는 시계를 제공하는 `timestamp` 서비스\n\n## Key Concepts in Aptos Move\n\n- 데이터는 모듈을 게시한 계정이 아닌 데이터를 소유한 계정 내에 저장되어야 합니다.\n- 데이터 흐름에는 생태계 유용성에 중점을 둔 최소한의 제약이 있어야 합니다.\n- 제네릭을 통한 런타임 안전보다 정적 유형 안전을 선호합니다.\n- 명시적으로 명확하지 않은 경우 `signer`는 자산을 계정에 추가하거나 제거할 수 있는 액세스를 제한해야 합니다.\n\n### Data ownership\n\n데이터는 모듈을 게시한 계정이 아니라 데이터를 소유한 계정에 저장해야 합니다.  \n\n`Solidity`에서 데이터는 계약을 생성한 계정의 네임스페이스 내에 저장됩니다. 일반적으로 이것은 값에 대한 주소의 맵 또는 소유자의 주소에 대한 인스턴스 ID의 맵으로 표시됩니다.  \n\n`Solana`에서 데이터는 계약과 관련된 별개의 계정에 저장됩니다.  \n\n`Move`에서 데이터는 모듈 소유자의 계정에 저장될 수 있지만, 이는 소유권 모호성 문제를 야기하며 다음 두 가지 문제를 암시한다:  \n1. 자산에 소유자와 연결된 리소스가 없기 때문에 소유권이 모호해집니다  \n2. 모듈 작성자는 임대, 회수 등과 같은 리소스의 수명에 대한 책임을 집니다  \n\n첫 번째로, 자산을 계정 내의 신뢰할 수 있는 리소스에 배치함으로써 소유자는 악의적으로 프로그래밍된 모듈조차도 해당 자산을 수정할 수 없도록 할 수 있습니다. `Move`에서는 표준 주문서 구조와 인터페이스를 프로그래밍하여 상단에 구축된 애플리케이션이 계정이나 주문서 항목에 백도어 액세스를 할 수 없도록 할 수 있습니다.  \n  \n다음 두 가지 `Coin` 보관 전략을 비교해 보십시오:  \n  \n다음은 인덱스로 표시된 소유권을 가진 단일 `Account`로 코인을 배치합니다.\n\n```move\nstruct CoinStore has key {\n\tcoins: table<address, Coin>,\n}\n```\n\n대신에  `Account` 에 `Coin`을 저장하는 접근법에서는 소유권을 명시적으로 할 수 있습니다.\n\n```move\nstruct CoinStore has key {\n    coin: Coin,\n}\n```\n\n### Data flow\n\n데이터 흐름은 생태계 유용성에 중점을 두고 최소한의 제약 조건을 가져야 합니다.\n\nMove에서 어떤 인터페이스도 해당 구조체(`struct`)를 값 형태로 나타내지 않도록 하고, 대신 모듈내에 정의된 데이터를 조작하기 위한 기능만을 제공하도록 할 수 있습니다(캡슐화, `encapsulation`). 이를 통해 자산이 오직 모듈 내에서만 접근 할 수 있도록 프로그래밍 할 수 있습니다. 이것은 직접적인 읽기와 쓰기 접근을 제한하여 다른 모듈과의 상호운용성이 차단됩니다. \n\n`Coin<T>`를 `input`으로 하고 `Ticket`을 `return`하는 컨트랙트가 있다고 가정해보겠습니다. 만약 `Coin<T>`를 모듈 내에서만 정의했고 외부로 내보낼 수 없는 경우, 해당 `Coin<T>`에 대한 요청들은 모듈이 정의한 항목으로만 제한됩니다.\n  \n입금 및 인출을 사용하여 코인 전송을 구현하는 다음의 두 가지 기능을 비교해 보십시오:\n\n```move\npublic fun transfer<T>(sender: &signer, recipient: address, amount: u64) {\n    let coin = withdraw(&sender, amount);\n    deposit(recipient, coin);\n}\n```\n\n모듈 외부에서 코인을 사용할 수 있는 범위는 다음과 같습니다.\n\n```move\nfun withdraw<T>(account: &signer, amount: u64): Coin<T>\nfun deposit<T>(account: address, coin: Coin<T>)\n```\n\n인출 및 입금에 `public accessors`를 추가하면 코인을 모듈 외부로 가져와 다른 모듈에서 사용하고 모듈로 반환할 수 있습니다.\n\n```move\npublic fun withdraw<T>(account: &signer, amount: u64): Coin<T>\npublic fun deposit<T>(account: address, coin: Coin<T>)\n```\n\n### Type-safety\n\n`Move`에서 `A`라고 하는 특정 구조체가 주어지면 서로 다른 인스턴스를 두 가지 방식으로 구분할 수 있습니다.\n\n- GUID와 같은 내부 식별자\n- `T`가 또 다른 구조체인 `A<T>`와 같은 제네릭\n\n내부 식별자는 단순하고 프로그래밍이 용이하기 때문에 편리할 수 있습니다. 그러나 제네릭은 명시적 컴파일 또는 유효성 검사 시간을 포함한 훨씬 더 높은 보장을 제공하지만 일부 비용이 발생합니다.\n\n제네릭은 이러한 유형을 예상하는 완전히 다른 유형과 리소스 및 인터페이스를 허용합니다. 예를 들어, 주문서에는 모든 주문에 대해 두 개의 통화가 예상되지만 그 중 하나는 수정되어야 한다고 명시할 수 있습니다. 예를 들어, `buy<T>(Coin: Coin<APT>): Coin<T>`. 이것은 사용자가 어떠한 `Coin<T>`도 구매할 수 있지만 `Coin<APT>`로 결제해야 한다는 것을 명시합니다.\n\n제네릭의 복잡성은 데이터를 `T`에 저장하는 것이 바람직할 때 발생합니다. `Move`는 제네릭에서 정적 디스패치를 지원하지 않으므로, `create<T>(...) : Coin<T>`와 같은 함수에서 T는 팬텀 유형이어야 합니다. 즉, Coin에서 유형 매개 변수로만 사용되거나 생성할 입력으로 지정되어야 합니다. 모든 `T`가 해당 함수를 구현하더라도 `T:: function`과 같이 사용될 수 없습니다.\n\n대량으로 생성될 수 있는 구조체의 경우 제네릭은 데이터 추적 및 이벤트 방출과 관련된 많은 새 저장소 및 리소스를 생성하는 결과를 낳습니다.\n\n이 때문에, 우리는 두 가지 \"토큰\" 표준을 만드는 어려운 선택을 했습니다. 하나는 `Coin`이라는 통화와 관련된 토큰에 대한 것이고, 다른 하나는 자산과 또는 NFT로 불리는 `Token`에 대한 것입니다. `Coin`은 제네릭을 통해 정적 유형의 안전성을 활용하지만 훨씬 단순한 계약입니다. `Token`은 자체 범용 식별자를 통해 동적 유형 안전을 활용하고 사용의 인체공학에 영향을 미치는 복잡성 때문에 일반론을 회피합니다\n\n### Data access\n\n- `signer`는 명시적으로 명확하지 않은 한 계정에 자산을 추가하거나 제거하는 액세스를 제한해야 합니다.\n\n`Move`에서 모듈은 계정 소유자 서명자의 존재에 관계없이 리소스에 액세스하는 방법과 리소스 내용을 수정하는 방법을 정의할 수 있습니다. 즉, 프로그래머가 실수로 다른 사용자의 계정에서 임의로 자산을 생성하거나 제거할 수 있는 리소스를 만들 수 있습니다.\n\nAptos Core Framework를 개발하면서 접근 권한을 허용 또는 방지한 위치에 대한 몇 가지 예가 있습니다:\n\n- A유저가 이미  `U Token`을 보유한 것이 아니라면, `U Token`은 A유저의 `account`에 직접 생성할 수 없습니다.\n- 접근 제어 목록을 효과적으로 사용해서  `TokenTransfers`가 유저가 명시적으로 다른 유저의 리소스의 토큰을 요구할 수 있도록 한다.\n- A유저가 `Coin<T>`을 저장할 `CoinStore<Coin<T>>`리소스를 가지고 있는 한, 어떤 유저든 A유저에게 `Coin<T>`을 직접 전송할 수 있습니다.\n\n`Token`에 대한 엄격한 노력이 부족하면 사용자가 다른 사용자 계정으로 직접 `Token`을 에어드롭할 수 있으며, 이는 사용자 계정에 추가 스토리지를 추가하고 처음 승인하지 않은 콘텐츠의 소유자가 됩니다.\n\n구체적인 예로, 인출 기능이 있는 이전 `Coin` 케이스로 돌아가십시오. 대신 `withdraw` 함수가 다음과 같이 정의된 경우(`signer` 인수가 없음에 유의하십시오):\n\n```move\npublic fun withdraw<T>(account: address, amount: u64): Coin<T>\n```\n\n누구나 계정에서 코인을 제거할 수 있습니다.\n\n### Resource accounts\n\n`Move` 모델은 종종 트랜잭션의 `signer`를 알아야 하기 때문에, Aptos는 `signer` 기능을 할당하기 위한 리소스 계정을 제공합니다. 리소스 계정을 생성하면 `signer` 기능에 액세스하여 자동으로 사용할 수 있습니다. `signer` 기능은 리소스 계정의 `signer`가 리소스 계정을 생성하거나 모듈의 로컬 저장소에 배치된 원본 계정의 주소와 함께 검색할 수 있습니다. `create_nft_with_resource_account.move`에서 `resource_signer_cap` 참조를 참조하십시오.\n\n리소스 계정을 생성할 때 해당 계정에 `signer` 기능도 부여합니다. `signer` 기능 내의 유일한 필드는 `signer`의 주소입니다. `signer` 기능에서 `signer`를 생성하는 방법을 보려면 `create_nft_with_resource_account.move`의 `let resource_signer` 함수를 검토하십시오.  \n  \n보안 침해를 방지하기 위해 모듈과 리소스 계정만 서명자 기능을 호출할 수 있습니다. 서명자 기능에서 서명자를 역으로 생성할 수 없으며, 대신 새 리소스 계정을 생성해야 합니다. 예를 들어 개인 키에서 서명자 기능을 생성할 수 없습니다.\n\n`signer` 취약성을 추가로 방지하려면 지갑 이벤트를 모니터링하고 다음 사항을 확인하십시오:  \n  \n- 공제되는 금액이 맞습니다.  \n- NFT 생성 이벤트가 있습니다.  \n- NFT 인출 이벤트가 없습니다.\n\nSee [resource accounts](https://aptos.dev/guides/resource-accounts) to learn more.\n\n### Coins\n\nAPT(Aptos Token)는 임의의 주소로 전송할 수 있으므로 존재하지 않는 주소에 대한 계정을 만들 수 있습니다. 예를 들어, USDC를 구입했으며 이를 APT로 변환하려고 합니다. 사용자를 보호하려면 해당 토큰을 수락해야 합니다.\n\n### Wrapping\n\n`Coin` 대신 밸런스를 직접 보관하는 이유는 무엇입니까? 우리는 당신이 `wrapper` 기능을 추가할 수 있도록 간접적으로 추가합니다.\n\n예를 들어, `Coin`에서 출금 및 입금 이벤트를 전송할 수 있습니다.\n\n하지만 에스크로의 경우 `Coin`을 보유하기 위한 이벤트도 방출할 수 있습니다.\n\n모듈 내에서 다른 구조체들을(`structure`)를 `destructure` 하여 간접적으로 잔액 대신 직접 `Coin`에서 동작시킬 수 있습니다.\n\n그것은 개별 구현에 달려 있습니다. 동일한 모듈에서 `Coin`과 밸런스를 모두 정의하는 경우 `destructure`를 통해 내부의 `Coin`에 대한 참조를 얻을 수 있으며 구조 자체에 대한 변경 가능한 참조를 얻을 수 있습니다. 대신 `Coin` 모듈에 의존하는 경우, 사용자에게 입금하기 위해 `Balance` 메서드를 사용하거나 `BalanceWithdraw` 메서드를 사용하여 실제 `Coin`을 얻어야 합니다. 함께 추가하려면 `CoinMerge를` 사용하십시오.\n\n### Generics\n\n사용자 지정 토큰과 Aptos 토큰 모두에 제네릭을 사용할 수 있습니다. Aptos가 제공하는 유일한 마법은 Aptos가 애그리게이터를 사용한다는 것입니다. 다른 코인 유형에는 아직 사용할 수 없습니다.\n\n### Visibility\n\n`Functions`는 `private`이 기본 값이므로 같은 파일에서만 호출될 수 있습니다. [`public`, `public(entry)`, etc.] 를 사용해서 파일 바깥에서 호출 하도록 할 수 있습니다.\n\n-   `entry` - 함수 호출을 실제 entry 함수로 만들어 분리합니다. 재중복성을 방지합니다(컴파일러 오류 발생)\n-   `public` - 누구나 어디서나 함수를 호출할 수 있습니다\n-   `public(entry)` - 관련 트랜잭션에 정의된 메서드만 함수를 호출할 수 있습니다\n-   `public(friend)` - 현재 모듈이 신뢰하는 모듈을 선언하는 데 사용됩니다.\n-   `public(script)` - Aptos 네트워크에서 임의 이동 코드를 제출, 컴파일 및 실행할 수 있습니다\n\n가능한 `public(entry)`이 아닌 `entry`를 사용하는 것을 권장하는데, 코드가 추가 개체(`object`)로 감싸이지 않도록 해주기 때문입니다.\n\n`Move`는 두 가지 방법으로 재진입을 방지합니다\n\n1.  동적 디스패치가 없는 경우 모듈 내의 다른 모듈을 호출하려면 해당 모듈에 명시적으로 의존해야 합니다. 따라서 다른 모듈은 사용자에게 의존해야 합니다.\n2.  순환 종속성은 허용되지 않습니다. 따라서 A가 B를 호출하고 B가 A에 상호 의존하면 모듈 B를 배포할 수 없습니다.\n\nFind out more about the Move programming language among the [Move Guides](https://aptos.dev/).",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 9,
    "wordCount": 1763,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "interact-with-the-move-vm",
    "slug": "interact-with-the-move-vm",
    "path": "blockchain/aptos",
    "fullPath": "blockchain/aptos/interact-with-the-move-vm",
    "title": "Interact with the Move VM",
    "excerpt": "Interact with the Move VM The Aptos blockchain uses the Move virtual machine (VM) for executing operations...",
    "content": "# Interact with the Move VM\n\nThe Aptos blockchain uses the [Move](https://github.com/move-language/move) virtual machine (VM) for executing operations. While many blockchains implement a set of\nnative operations, Aptos delegates all operations to Move, including: account creation, fund transfer and publishing Move modules.\nTo support these operations, blockchains built on top of Move must provide a framework (akin to\nan operating system for a computer or a minimal viable set of functions) for interacting with the blockchain. In this section, we discuss\nthese functions, exposed via the Aptos Framework's `script` functions.\n\nThis guide (in concert with the [Move module tutorial](../tutorials/first-move-module.md) ) will unlock the minimal amount of information required to start building rich applications on top of the Aptos blockchain. Note: the Aptos Framework is under heavy development and this document may not\nbe up to date. The most recent framework can be found in the [source code](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework).\n\nThe core functions provided to users within the Aptos Framework include:\n\n- Sending and receiving the network coin `Coin<AptosCoin>`\n- Creating a new account\n- Publishing a new Move module\n\nNote: this document assumes readers are already familiar with submitting transactions, as described in the [Your first transaction tutorial](../tutorials/first-transaction.md).\n\n## Sending and Receiving the network coin `Coin<AptosCoin>`\n\n`Coin<AptosCoin>` is required for paying gas fees when submitting and executing transactions. `Coin<AptosCoin>` can be obtained by calling the Devnet Faucet. See the [Your first transaction](../tutorials/first-transaction.md) tutorial for an example.\n\nThe payload for instructing the blockchain to perform a transfer is:\n\n```\n{\n  \"type\": \"entry_function_payload\",\n  \"function\": \"0x1::coin::transfer\",\n  \"type_arguments\": [\"0x1::aptos_coin::AptosCoin\"],\n  \"arguments\": [\n    \"0x737b36c96926043794ed3a0b3eaaceaf\",\n    \"1000\",\n  ]\n}\n```\n\nThis instructs the VM to execute the `script` `0x1::coin::transfer` with a type argument of 0x1::aptos_coin::AptosCoin. Type is required here as Coin is our standard module that can be used to create many types of Coins. See the [Your first coin tutorial](../tutorials/first-coin.md) for an example of creating a custom Coin. The first argument is the recipient address, `0x737b36c96926043794ed3a0b3eaaceaf`, and the second is the amount to transfer, `1000`. The sender address is the account\naddress that sent the transaction querying this `script`.\n\n## Creating a new account\n\nThe payload for instructing the blockchain to create a new account is:\n\n```\n{\n  \"type\": \"entry_function_payload\",\n  \"function\": \"0x1::aptos_account::create_account\",\n  \"type_arguments\": [],\n  \"arguments\": [\n    \"0x0c7e09cd9185a27104fa218a0b26ea88\",\n    \"0xaacf87ae9d8a5e523c7f1107c668cb28dec005933c4a3bf0465ffd8a9800a2d900\",\n  ]\n}\n```\n\nThis instructs the Move virtual machine to execute the `script` `0x1::aptos_account::create_account`. The first argument is the address of the account to create and the second is the authentication key pre-image (which is mentioned in [Accounts](../concepts/accounts.md). For single signer authentication, this is the public key concatenated with the `0` byte (or `pubkey_A | 0x00`). This is required to prevent account address land grabbing. The execution of this instruction verifies that the 32-bytes of the authentication key are the same as the 32-byte account address. We are actively working on improving this API to support taking in a 32-byte account address that would eliminate concerns around land grabbing or account manipulation.\n\n## Publishing a new Move module\n\nThe payload for publishing a new module is:\n\n```\n\"type\": \"module_bundle_payload\",\n\"modules\": [\n    {\"bytecode\": \"0x...\"},\n],\n```\n\nThis instructs the VM to publish the module bytecode under the sender's account. For a full-length tutorial, see [Your first move module](../tutorials/first-move-module.md).\n\nIt is important to note that the Move bytecode must specify the same address as the sender's account, otherwise the transaction will be rejected. For example, assuming account address `0xe110`, the Move module would need to be updated as such `module 0xe110::Message`, `module 0xbar::Message` would be rejected. Alternatively an aliased address could be used, such as `module HelloBlockchain::Message` but the `HelloBlockchain` alias would need to updated to `0xe110` in the `Move.toml` file. We are working with the Move team and planning on incorporating a compiler into our REST interface to mitigate this issue.\n\n[accounts]: /concepts/accounts\n[your-first-coin]: /tutorials/your-first-coin\n[your-first-move-module]: /tutorials/first-move-module\n[your-first-transaction]: /tutorials/your-first-transaction\n[move_url]: https://diem.github.io/move/\n[aptos_framework]: https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework/aptos-framework/sources",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 4,
    "wordCount": 632,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "aptos-whitepaper",
    "slug": "aptos-whitepaper",
    "path": "blockchain/aptos",
    "fullPath": "blockchain/aptos/aptos-whitepaper",
    "title": "Aptos Whitepaper",
    "excerpt": "Aptos Whitepaper https://aptos.dev/aptos-white-paper/aptos-white-paper-in-korean...",
    "content": "# Aptos Whitepaper\n\nhttps://aptos.dev/aptos-white-paper/aptos-white-paper-in-korean",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 5,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "aptos-move-structure",
    "slug": "aptos-move-structure",
    "path": "blockchain/aptos",
    "fullPath": "blockchain/aptos/aptos-move-structure",
    "title": "Aptos Move Structure",
    "excerpt": "Aptos Move Structure 여러분의 Move 코드를 어떻게 구성하는게 좋은지 이해하는 시간을 가져봅시다 Move의 구조체는 함수 클래스 역할을 하는 Rust와 같은 다른 프로그래밍 언어의 구조체와 비슷합니다. 원하는 만큼 구조체에 많은 필드를 가질 수...",
    "content": "# Aptos Move Structure\n\n여러분의 Move 코드를 어떻게 구성하는게 좋은지 이해하는 시간을 가져봅시다\n\nMove의 구조체는 함수 클래스 역할을 하는 Rust와 같은 다른 프로그래밍 언어의 구조체와 비슷합니다. 원하는 만큼 구조체에 많은 필드를 가질 수 있지만 개체 지향 프로그래밍에서와 같이 구조체에 메서드를 가질 수는 없습니다. 마찬가지로 Move에는 상속이 없습니다. 대신 구조체를 다시 생성하려면 구조체를 복제해야 합니다.\n\n일단 게시되면 Move의 구조체 정의는 변경할 수 없습니다. 구조체 자체는 업그레이드할 수 없지만 해당 필드의 값은 변경될 수 있습니다. Move의 보안을 위해 구조체가 정의된 모듈만 구조체를 분해하거나 해당 속성에 액세스할 수 있습니다.\n\n## Abilities\n\nMove의 구조체(Structures)에는 해당 유형으로 수행할 수 있는 작업을 설명하는 다양한 기능이 부여될 수 있습니다. 다음과 같은 네 가지 기능이 있습니다.\n\n- copy: 복사할 수 있는 기능. 지리적 ID가 좋은 활용 사례가 될 것입니다. NFT는 이 기능을 가지고 있어서는 안 됩니다.  values of types with this ability to be copied. A geographic ID would be a good use case. NFTs should not have this ability.\n- drop: 팝/드롭할 수 있는 기능.\n- store: 글로벌 스토리지의 구조체 내부에 저장 또는 저장할 수 있는 기능.\n- key: 글로벌 스토리지 작업의 키 역할을 하는 유형입니다. 이 기능을 사용하면 값을 계정 내 최상위 항목으로 저장할 수 있습니다.\n\n## Global storage\n\nMove에서 각 계정은 주어진 유형의 리소스를 하나만 가질 수 있습니다. `Coin`예를 들어 Move의 계정은 하나의 유형 만 존재하는 해시맵과 유사하기 때문입니다 . 해시맵은 리소스 유형 또는 모듈 이름을 리소스 값에 매핑한 것입니다. 이것이 Aptos가 여러 코인과 토큰을 보유하기 위한 추상화를 제공하기 위해 `CoinStore`및 의 홀더 패턴을 제공하는 이유입니다. `TokenStore`이러한 홀더는 테이블을 포함하거나 저장을 위해 제네릭을 사용합니다.\n\nAptos 는 효율적인 상태 동기화 및 인증된 스토리지 읽기를 위해 [Merkle 트리 를 사용합니다.](https://aptos.dev/reference/glossary/#merkle-trees)\n\n## Signers\n\nAptos에서 서명자는 엄청나게 강력합니다. 구조체는 서명자 주소로 게시됩니다. 서명자는 트랜잭션에 서명하고 제출할 때 생성됩니다. 트랜잭션을 제출할 때 서명자는 기본적으로 첫 번째 매개변수입니다. 서명자는 자신의 구조체를 체인에 포함하는 데 동의했습니다. 서명자에게는 저장 또는 키 기능이 없고 복사 기능만 있습니다.\n\n## key\n\n다른 사용자가 서명자를 사용할 수 있도록 하기 위해 서명자는 리소스에 저장됩니다. `key` 기능을 통해 `type`은 `store` 기능이 있는 `Coin`과 같은 글로벌 스토리지 작업의 `key` 역할을 할 수 있습니다. `Balance`에는 `key`기능이 있으므로 계정 내 최상위 항목으로 `store`할 수 있습니다.\n\nAptos는 서명자를 저장하지 않고 서명자 기능을 저장합니다. 제한된 `native` 기능만 서명자 기능을 만들 수 있습니다. NFT를 `minting`하려면 컬렉션을 생성한 서명자에 대한 액세스 권한이 필요합니다. 이것이 동적 발행을 수행할 때 많은 사람들이 NFT를 미리 발행(`pre-mint`)하는 이유입니다. Aptos는 트랜잭션에 자율적으로 서명할 수 있는 리소스 계정을 제공합니다.\n\n## acquires\n\n유저가 구조체와 같은 글로벌 리소스를 사용할때마다 항상 먼저 이것을 획득(`acquire`)해야합니다. 예를 들어,  NFT 입출금시 `TokenStore`를 획득해야 합니다. 리소스를 획득하는 모듈 내부의 함수를 호출하는 다른 모듈의 함수가 있는 경우, 첫 번째 함수에 `acquires()`로 레이블을 지정할 필요가 없습니다.\n\n리소스가 계정 내부에 저장되므로 소유권이 명확해집니다. 계정은 리소스를 생성할 수 있는지 여부를 결정할 수 있습니다. 해당 리소스를 정의하는 모듈은 해당 구조체를 읽고 수정하는 권한을 가집니다. 따라서 해당 모듈 내부의 코드는 해당 구조체를 명시적으로 획득해야 합니다.\n\n그래도 Move에서 빌리거나 이동하는 모든 위치에서 자동으로 리소스를 획득하게 됩니다. 명확성을 위해 명시적 포함을 위해 취득을 사용하십시오. 마찬가지로 `exists()` 함수에는 `acquires()` 함수가 필요하지 않습니다.\n\n참고: 자신의 모듈에 정의된 구조체에서 모든 계정의 모듈 내 전역(`global`)을 빌릴 수 있습니다. 모듈 외부에서 전역을 빌릴 수 없습니다.\n\n## move_to\n\n그런 다음 `move_to` 함수를 서명자 및 계정에 대한 참조와 함께 사용하여 구조체를 계정으로 이동할 수 있습니다. 그 과정에서 우리는 가치가 있는 코인의 새로운 인스턴스를 생성합니다.\nYou may then use the `move_to` function along with a reference to signer and account to move the struct into an account. In the process, we create a new instance of coin with value.\n\n## Initialization\n\n`init_module`은 모듈이 배포될 때 자동으로 호출되고 실행됩니다.\nThe `init_module` automatically gets called and run when the module is published:\n\n```shell\n    fun init_module(resource_account: &signer) {\n        let resource_signer_cap = resource_account::retrieve_resource_account_cap(resource_account, @source_addr);\n        let resource_signer = account::create_signer_with_capability(&resource_signer_cap);\n```\n\n`mint_nft_ticket()` 함수는 콜렉션을 가져오고 토큰을 생성합니다.\nThe `mint_nft_ticket()` function gets a collection and creates a token.\n\nTokenData ID의 결과로, 함수는 모듈의 리소스 서명자를 사용하여 토큰을 NFT 수신자에 `mint`합니다.\n\nFor example:\n\n```shell\n    public entry fun mint_nft(receiver: &signer) acquires ModuleData {\n        let receiver_addr = signer::address_of(receiver);\n```\n\n## Signing\n\n모든 `entry fun`은 `&signer` 유형을 첫 번째 매개변수로 사용합니다. Move와 Aptos 모두 트랜잭션을 제출할 때마다 트랜잭션에 서명하는 개인 키가 자동으로 연결된 계정을 서명자의 첫 번째 매개변수로 만듭니다.\n\n서명자에서 주소로 이동할 수 있지만 일반적으로 그 반대는 아닙니다. 따라서 NFT를 청구할 때 아래 지침과 같이 생성자와 수신자의 개인 키가 모두 필요합니다.\n\n`init_module`에서 서명자는 항상 계약을 업로드하는 계정입니다. 이것은 다음과 결합됩니다.\n\n```move\n        token::create_collection(&resource_signer, collection, description, collection_uri, maximum_supply, mutate_setting);\n\n```\n\nThen:\n\n```move\n        signer_cap: account::SignerCapability,\n```\n\n서명자 기능을 사용하면 모듈이 자율적으로 서명할 수 있습니다. 자원 계정은 누구도 개인 키를 가져오지 못하도록 하며 전적으로 계약에 의해 제어됩니다.\n\n## Module data\n\n그런 다음 'ModuleData'가 초기화되고 서명자 기능이 있는 리소스 계정으로 `_moved_`됩니다.\n\n```shell\n        move_to(resource_account, ModuleData {\n```\n\n`mint_nft_ticket()` 함수에서 첫 번째 단계는 `ModuleData` 구조체를 차용하는 것입니다.\n\n```shell\n        let module_data = borrow_global_mut<ModuleData>(@mint_nft);\n```\n\n그런 다음 `ModuleData` 구조체의 서명자 기능에 대한 참조를 사용하여 `resource_signer`를 만듭니다.\n\n```shell\n        let resource_signer = account::create_signer_with_capability(&module_data.signer_cap);\n```\n\n이러한 방식으로 모듈에 이미 저장된 서명자 기능을 나중에 사용할 수 있습니다. 모듈과 해당 구조를 계정으로 이동하면 해당 계정과 연결된 Aptos Explorer에 표시됩니다.\n\n## Accounts\n\n예를 들어 NFT를 발행할 때 NFT는 계정 주소에 저장됩니다. 트랜잭션을 제출하면 트랜잭션에 서명합니다. `aptos init`를 실행하는 위치(아래)와 관련된 `.aptos/config.yaml`에서 계정 구성 정보를 찾으십시오.\n\n리소스 계정을 사용하면 트랜잭션 서명을 위임할 수 있습니다. 리소스 계정을 생성하여 동일한 계정의 새 리소스에 저장할 수 있고 자율적으로 트랜잭션에 서명할 수 있는 서명자 기능을 부여합니다. 아무도 자원 계정의 개인 키에 액세스할 수 없으므로 서명자 기능이 보호됩니다.",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 5,
    "wordCount": 872,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "aptos-integration-guide",
    "slug": "aptos-integration-guide",
    "path": "blockchain/aptos",
    "fullPath": "blockchain/aptos/aptos-integration-guide",
    "title": "Aptos Integration Guide",
    "excerpt": "Aptos Integration Guide https://aptos.dev/guides/system-integrators-guide...",
    "content": "# Aptos Integration Guide\n\nhttps://aptos.dev/guides/system-integrators-guide",
    "docType": "original",
    "category": "Blockchain",
    "tags": [],
    "readingTime": 1,
    "wordCount": 6,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "데코레이터-decorator",
    "slug": "dekoreiteo-decorator",
    "path": "backend/patterns",
    "fullPath": "backend/patterns/dekoreiteo-decorator",
    "title": "데코레이터 (Decorator)",
    "excerpt": "데코레이터 (Decorator) 정의 데코레이터는 클래스 선언, 메서드, 접근자, 프로퍼티, 또는 매개변수에 첨부할 수 있는 특수한 종류의 선언입니다. 사용 형식은 과 같으며, 여기서 은 데코레이팅 된 선언...",
    "content": "# 데코레이터 (Decorator)\n\n## 정의\n\n데코레이터는 클래스 선언, 메서드, 접근자, 프로퍼티, 또는 매개변수에 첨부할 수 있는 특수한 종류의 선언입니다.  사용 형식은 `@expression`과 같으며, 여기서 `@expression`은 데코레이팅 된 선언에 대한 정보와 함께 런타임에 호출되는 함수여야 합니다. 데코레이터는 클래스와 클래스 멤버에 어노테이션과 메타-프로그래밍 구문을 추가할 수 있는 방법을 제공합니다.\n\n## 데코레이터 팩토리 (Decorator Factories)\n\n```typescript\nfunction color(value: string) { // 데코레이터 팩토리\n\treturn function (target) { // 데코레이터\n\t\t// 'target'과 'value' 변수를 가지고 무언가를 수행합니다\n\t\t...\n\t}\n}\n\n# Reference\n- https://www.typescriptlang.org/docs/handbook/decorators.html#handbook-content\n```\n\n## 데코레이터 합성 (Decorator Composition)\n\nTypeScript에서 단일 선언에서 여러 데코레이터를 사용할 때 다음 단계가 수행됩니다.\n\n1.  각 데코레이터의 표현은 위에서 아래로 평가됩니다.\n2.  그런 다음 결과는 아래에서 위로 함수로 호출됩니다.\n\n여러 데코레이터가 단일 선언에 적용되는 경우 예시를 보여드리겠습니다.\n\n```typescript\nfunction first() {  \n  console.log('first(): factory evaluated');  \n  return (target: any, propertyKey: string, descriptor: PropertyDescriptor) => {  \n    console.log('first(): called');  \n  };  \n}  \n  \nfunction second() {  \n  console.log('second(): factory evaluated');  \n  return (target: any, propertyKey: string, descriptor: PropertyDescriptor) => {  \n    console.log('second(): called');  \n  };  \n}  \n  \nclass ExampleClass {  \n  @first()  \n  @second()  \n  method() {}  \n}\n\n# Reference\n- https://www.typescriptlang.org/docs/handbook/decorators.html#handbook-content\n```\n위 `ExampleClass`의  `method` 를 호출하면 아래 결과를 출력하게 됩니다\n```\nfirst(): factory evaluated\nsecond(): factory evaluated\nsecond(): called\nfirst(): called\n```\n\n## 데코레이터 평가 (Decorator Evaluation)\n\n클래스에서 다양한 선언에 데코레이터를 적용하는 방법은 다음과 같이 잘 정의되어 있습니다.\n1. _Parameter Decorators_, followed by _Method_, _Accessor_, or _Property Decorators_ are applied for each instance member.\n2.  _Parameter Decorators_, followed by _Method_, _Accessor_, or _Property Decorators_ are applied for each static member.\n3.  _Parameter Decorators_ are applied for the constructor.\n4.  _Class Decorators_ are applied for the class.\n\n## 클래스 데코레이터 (Class Decorators)\n\n클래스 데코레이터는 클래스 선언 직전에 선언되며, 해당 클래스의 생성자에 적용됩니다.\n```typescript\n@sealed\nclass BugReport {\n  type = \"report\";\n  title: string;\n  \n  constructor(t: string) {\n    this.title = t;\n  }\n}\n\nfunction sealed(constructor: Function) {\n  Object.seal(constructor);\n  Object.seal(constructor.prototype);\n}\n```\n\n```typescript\nfunction reportableClassDecorator<T extends { new (...args: any[]): {} }>(  \n  constructor: T,  \n) {  \n  return class extends constructor {  \n    reportingURL = 'http://www...';  \n  };  \n}  \n  \n@reportableClassDecorator  \nclass BugReport {  \n  type = 'report';  \n  title: string;  \n  \n  constructor(t: string) {  \n    this.title = t;  \n  }  \n}  \n  \nconst bug = new BugReport('Needs dark mode');  \nconsole.log(bug.title); // Prints \"Needs dark mode\"  \nconsole.log(bug.type); // Prints \"report\"  \n  \n// Note that the decorator *does not* change the TypeScript type  \n// and so the new property `reportingURL` is not known  \n// to the type system:  \nbug.reportingURL;\n\nProperty 'reportingURL' does not exist on type 'BugReport'.\n```\n\n## 메소드 데코레이터 (Method Decorators)\n\n메서드 데코레이터는 메서드 선언 직전에 선언됩니다. 데코레이터는 메서드의 프로퍼티 설명자(Property Descriptor) 에 적용되며 메서드 정의를 관찰, 수정 또는 대체하는 데 사용할 수 있습니다. 메서드 데코레이터는 선언 파일, 오버로드 또는 기타 주변 컨텍스트(예: `선언` 클래스)에서 사용할 수 없습니다.\n\n메서드 데코레이터의 표현식은 런타임에 다음 세 개의 인수와 함께 함수로 호출됩니다:\n\n1.  정적 멤버에 대한 클래스의 생성자 함수 또는 인스턴스 멤버에 대한 클래스의 프로토타입입니다.\n2.  멤버의 이름\n3.  멤버의 _프로퍼티 설명자_\n\n> 참고  스크립트 대상이 ‘ES5’보다 낮은 경우 _프로퍼티 설명자_ 는 ‘undefined’이 됩니다.\n\n메서드 데코레이터가 값을 반환하면, 메서드의 _프로퍼티 설명자_ 로 사용됩니다.\n\n> 참고  스크립트 대상이 ‘ES5’보다 낮은 경우 반환 값은 무시됩니다.\n\n```typescript\nfunction printClassName(enabled: boolean) {  \n  return function (  \n    target: any,  \n    propertyKey: string,  \n    descriptor: PropertyDescriptor,  \n  ) {  \n    if (enabled) {  \n      console.log(target.constructor.name);  \n    }  \n  };  \n}  \n  \nclass Person {  \n  msg: string;  \n  constructor(msg: string) {  \n    this.msg = msg;  \n  }  \n  @printClassName(true)  \n  sayMessage() {  \n    return this.msg;  \n  }  \n}\n```\n\n## 접근자 데코레이터 (Accessor Decorators)\n\n접근자 데코레이터는 접근자 선언 바로 전에 선언됩니다. 접근자 데코레이터는 접근자의 _프로퍼티 설명자_에 적용되며 접근자의 정의를 관찰, 수정 또는 교체하는 데 사용할 수 있습니다. 접근자 데코레이터는 선언 파일이나 다른 주변 컨텍스트(예: `선언` 클래스)에서 사용할 수 없습니다.\n\n> 참고  TypeScript는 단일 멤버에 대해 `get` 및 `set` 접근자를 데코레이팅 할 수 없습니다. 대신 멤버의 모든 데코레이터를 문서 순서대로 지정된 첫 번째 접근자에 적용해야 합니다. 왜냐하면, 데코레이터는 각각의 선언이 아닌 `get`과 `set` 접근자를 결합한 프로퍼티 설명자에 적용되기 때문입니다.\n\n접근자 데코레이터의 표현 식은 런타임에 다음 세 가지 인수와 함께 함수로 호출됩니다:\n\n1.  정적 멤버에 대한 클래스의 생성자 함수 또는 인스턴스 멤버에 대한 클래스의 프로토타입\n2.  멤버의 이름\n3.  멤버의 _프로퍼티 설명자_\n\n> 참고  스크립트 대상이 ‘ES5’보다 낮은 경우 프로퍼티 설명자는 `undefined`가 됩니다.\n\n접근자 데코레이터가 값을 반환하면 멤버의 프로퍼티 설명자로 사용됩니다.\n\n> 참고  스크립트 대상이 ‘ES5’보다 낮은 경우 반환 값은 무시됩니다.\n\n## 프로퍼티 데코레이터 (Property Decorators)\n\n프로퍼티 데코레이터는 프로퍼티 선언 바로 전에 선언됩니다. 프로퍼티 데코레이터는 선언 파일이나 다른 주변 컨텍스트(예: `선언` 클래스)에서 사용할 수 없습니다.\n\n프로퍼티 데코레이터의 표현 식은 런타임에 다음 두 개의 인수와 함께 함수로 호출됩니다:\n\n1.  정적 멤버에 대한 클래스의 생성자 함수 또는 인스턴스 멤버에 대한 클래스의 프로토타입\n2.  멤버의 이름\n\n> 참고  TypeScript에서 `프로퍼티 데코레이터`가 초기화되는 방식으로 인해 프로퍼티 설명자가 프로퍼티 데코레이터에 대한 인수로 제공되지 않습니다. 현재 프로토타입의 멤버를 정의할 때 인스턴스 프로퍼티를 설명하는 메커니즘이 없고 프로퍼티의 이니셜라이저를 관찰하거나 수정할 수 있는 방법이 없기 때문입니다. 반환 값도 무시됩니다. 따라서 프로퍼티 데코레이터는 특정 이름의 프로퍼티가 클래스에 선언되었음을 관찰하는 데만 사용할 수 있습니다.\n\n이 정보를 사용하여 다음 예와 같이 프로퍼티에 대한 메타데이터를 기록할 수 있습니다:\n\n```typescript\nclass Greeter {  \n  @format(\"Hello, %s\")  \n  greeting: string;  \n  \n  constructor(message: string) {  \n    this.greeting = message;  \n  }  \n  \n  greet() {  \n    let formatString = getFormat(this, \"greeting\");  \n    return formatString.replace(\"%s\", this.greeting);  \n  }  \n}\n```\n\n다음 함수 선언을 사용하여 `@format` 데코레이터와 `getFormat` 함수를 정의 할 수 있습니다:\n\n```typescript\nimport \"reflect-metadata\";  \n\nconst formatMetadataKey = Symbol(\"format\");  \n\nfunction format(formatString: string) {  \n  return Reflect.metadata(formatMetadataKey, formatString);  \n}  \n\nfunction getFormat(target: any, propertyKey: string) {  \n  return Reflect.getMetadata(formatMetadataKey, target, propertyKey);  \n}\n```\n\n`@format(\"Hello, %s\")` 데코레이터는 [데코레이터 팩토리](https://www.typescriptlang.org/ko/docs/handbook/decorators.html#%EB%8D%B0%EC%BD%94%EB%A0%88%EC%9D%B4%ED%84%B0-%ED%8C%A9%ED%86%A0%EB%A6%AC-Decorator-Factories)입니다. `@format(\"Hello, %s\")`가 호출되면 `reflect-metadata` 라이브러리의 `Reflect.metadata` 함수를 사용하여 프로퍼티에 대한 메타데이터 항목을 추가합니다. `getFormat`이 호출되면 형식의 메타데이터 값을 읽습니다.\n\n> 참고  이 예제에는 `reflect-metadata` 라이브러리가 필요합니다. `reflect-metadata` 라이브러리에 대한 자세한 내용은 [메타데이터](https://www.typescriptlang.org/ko/docs/handbook/decorators.html#%EB%A9%94%ED%83%80%EB%8D%B0%EC%9D%B4%ED%84%B0-metadata)를 참조하십시오.\n\n\n## 메타데이터 (Metadata)\n\n일부 예제는 [실험적 메타데이터 API](https://github.com/rbuckton/ReflectDecorators)에 대한 폴리필(polyfill)을 추가하는 `reflect-metadata` 라이브러리를 사용합니다. 이 라이브러리는 아직 ECMAScript (JavaScript) 표준의 일부가 아닙니다. 그러나 데코레이터가 공식적으로 ECMAScript 표준의 일부로 채택되면 이러한 확장을 채택하게 될 것입니다.\n\nnpm을 통해 설치할 수 있습니다.\n\n`   npm i reflect-metadata --save   `\n\nTypeScript에는 데코레이터가 있는 선언에 대해 특정 타입의 메타 데이터를 내보내는 실험적인 지원을 포함합니다. 이 실험적인 지원을 가능하게 하려면, 명령행 또는`tsconfig.json`에서 `emitDecoratorMetadata` 컴파일러 옵션을 설정해야 합니다.\n\n**명령줄**:\n\n`tsc --target ES5 --experimentalDecorators --emitDecoratorMetadata`\n\n**tsconfig.json**:\n\n```typescript\n{  \n  \"compilerOptions\": {  \n    \"target\": \"ES5\",  \n    \"experimentalDecorators\": true,  \n    \"emitDecoratorMetadata\": true  \n  }  \n}\n```\n\n활성화되면 `reflect-metadata`라이브러리를 가져오기만 하면 추가 디자인-타임 타입 정보가 런타임에 사용 가능합니다.\n\n다음 예제에서 이를 확인할 수 있습니다.\n\n```typescript\nimport 'reflect-metadata';  \n  \nclass Point {  \n  constructor(public x: number, public y: number) {}  \n}  \n  \nclass Line {  \n  private _start: Point;  \n  private _end: Point;  \n  \n  @validate  \n  set start(value: Point) {  \n    this._start = value;  \n  }  \n  \n  get start() {  \n    return this._start;  \n  }  \n  \n  @validate  \n  set end(value: Point) {  \n    this._end = value;  \n  }  \n  \n  get end() {  \n    return this._end;  \n  }  \n}  \n  \nfunction validate<T>(  \n  target: any,  \n  propertyKey: string,  \n  descriptor: TypedPropertyDescriptor<T>,  \n) {  \n  let set = descriptor.set!;  \n  \n  descriptor.set = function (value: T) {  \n    let type = Reflect.getMetadata('design:type', target, propertyKey);  \n  \n    if (!(value instanceof type)) {  \n      throw new TypeError(  \n        `Invalid type, got ${typeof value} not ${type.name}.`,  \n      );  \n    }  \n  \n    set.call(this, value);  \n  };  \n}  \n  \nconst line = new Line();  \nline.start = new Point(0, 0);  \n  \n// @ts-ignore  \n// line.end = {}  \n  \n// Fails at runtime with:  \n// > Invalid type, got object not Point\n```\n\nTypeScript 컴파일러는 `@Reflect.metadata` 데코레이터를 사용하여 디자인-타임 타입 정보를 주입합니다. 다음 TypeScript와 동일하다고 생각할 수 있습니다.\n\n```typescript\nclass Line {  \n  private _start: Point;  \n  private _end: Point;  \n  @validate  \n  @Reflect.metadata('design:type', Point)  \n  set start(value: Point) {  \n    this._start = value;  \n  }  \n  get start() {  \n    return this._start;  \n  }  \n  @validate  \n  @Reflect.metadata('design:type', Point)  \n  set end(value: Point) {  \n    this._end = value;  \n  }  \n  get end() {  \n    return this._end;  \n  }  \n}\n```",
    "docType": "original",
    "category": "Research",
    "tags": [],
    "readingTime": 6,
    "wordCount": 1199,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "개체-지향-프로그래밍-object-oriented-programming",
    "slug": "gaece-jihyang-peurogeuraeming-object-oriented-programming",
    "path": "backend/patterns",
    "fullPath": "backend/patterns/gaece-jihyang-peurogeuraeming-object-oriented-programming",
    "title": "개체 지향 프로그래밍 (Object Oriented Programming)",
    "excerpt": "개체 지향 프로그래밍 (Object Oriented Programming) 개체 지향 프로그래밍 언어의 네가지 기본 원칙 추상화 - 관련 특성 및 엔터티의 상호 작용을 클래스로 모델링하여 시스템의 추상적 표현을 정의합니다. 캡슐화 - 개체의 내부...",
    "content": "# 개체 지향 프로그래밍 (Object Oriented Programming)\n\n## 개체 지향 프로그래밍 언어의 네가지 기본 원칙\n\n1. 추상화 - 관련 특성 및 엔터티의 상호 작용을 클래스로 모델링하여 시스템의 추상적 표현을 정의합니다.\n2. 캡슐화 - 개체의 내부 상태와 기능을 숨기고 public 함수 세트를 통해서만 개체에 엑세스할 수 있습니다.\n3. 상속 - 기존 추상화를 기반으로 새 추상화를 만들 수 있습니다.\n4. 다형성 - 여러 추상화 에서 다양한 방법으로 상속된 속성 또는 메서드를 구현할 수 있습니다.\n\n## C#의 클래스, 구조체 및 레코드 개요\n\n### 캡슐화\n\n캡슐화는 경우에 따라 개체 지향 프로그래밍의 첫 번째 원래로 인식됩니다. 클래스 또는 구조체는 그것의 외부의 코드에 각 멤버가 엑세스하는 방법을 지정할 수 있습니다. 클래스 또는 어셈블리 외부에서 사용하지 않으려는 메서드 및 변수를 숨겨 코딩 오류 또는 악의적인 악용 가능성을 제한할 수 있습니다.\n\n### 멤버\n\n멤버는 모든 메서드, 필드, 상수, 속성, 이벤트를 포함합니다. 다른 언어에는 있지만 C#에는 전역 변수 또는 메서드가 없습니다. 프로그램의 진입점인 `Main`메서드까지도 클래스나 구조체 내에 선언되어야 합니다.\n\n## 은행 계좌 예제를 통한 개체지향 프로그래밍 살펴보기\n\n### 은행 계좌의 기능\n\n1. 은행계좌를 고유하게 식별하는 10자리 숫자가 있습니다.\n2. 소유자의 이름을 저장하는 문자열이 있습니다.\n3. 잔액을 검사할 수 있습니다.\n4. 예금을 허용합니다.\n5. 인출을 허용합니다.\n6. 초기 잔액은 양수여야 합니다.\n7. 인출은 마이너스 잔액을 초래할 수 없습니다.\n\n### 은행 계좌 형식 정리\n\n```cs\nnamespace Classes;\n\npublic class BankAccount {\n  public string Number { get; }\n  public string Owner { get; set; }\n  public decimal Balance { get; }\n\n  public void MakeDeposit(decimal amount, DateTime date, string note)\n  {\n  }\n\n  public vode MakeWithdraw(decimal amount, DateTime date, string note)\n  {\n  }\n}\n```\n\n`BankAccount` 클래스는 다섯 개의 멤버를 가집니다. 앞의 세가지는 속성인데, 속성은 데이터 요소이며 유효성 검사 또는 기타 규칙을 적용하는 코드가 있을 수 있습니다. 나머지 두 가지는 메서드입니다. 메서드는 단일 함수를 수행하는 코드 블록입니다. 클래스의 각 멤버는 그것의 이름을 읽으면 타인이 해당 클래스가 수행하는 작업을 이해하기에 충분한 정보를 제공해야 합니다.\n\n### 새 계좌 개설 (생성자)\n\n`BankAccount` 형식의 새 개체를 만드는 것은 해당 값을 할당하는 생성자를 정의함을 의미합니다. C#에서 생성자는 클래스와 이름이 같은 멤버입니다.\n\n```cs\nnamespace Classes;\n\npublic class BankAccount {\n  private static int accountNumberSeed = 1234567890;\n  public string Number { get; }\n  public string Owner { get; set; }\n  public decimal Balance { get; }\n\n  public BankAccount(string, name, decimal initialBalance)\n  {\n    // C#는 this 한정자가 선택사항이며 일반적으로 생략할 수 있습니다.\n    // this.Owner = name;\n    // this.Balance = initialBalance;\n    Owner = name;\n    Balance = initialBalance;\n    // 계좌 번호\n    Number = accountNumberSeed.ToString();\n    accountNumberSeed++;\n  }\n\n  public void MakeDeposit(decimal amount, DateTime date, string note)\n  {\n  }\n\n  public vode MakeWithdraw(decimal amount, DateTime date, string note)\n  {\n  }\n}\n```\n\n생성자는 new를 사용하여 개체를 만들 때 호출됩니다.\n\n```cs\nusing Classes;\n\nvar account = new BankAccount(\"<name>\", 1000);\nConsole.WriteLine($\"Account {account.Number} was created for {account.Owner} with {account.Balance} initial balance.\");\n```\n\n### 예금 및 인출 만들기\n\n은행 계좌 클래스의 예금과 인출을 구현해보도록 하겠습니다. 먼저 트랜잭션을 나타내는 새 클래스를 생성합니다.\n그리고 Transaction 개체의 `List<T>`를 `BankAccount`클래스에 추가하고 Balance 속성을 업데이트 합니다.\n다음으로 `MakeDeposit`, `MakeWithdrawal`메서드를 구현합니다.\n그 뒤에는 생성자에서 최초 입금 건을 추가해줄 수 있도록 `MakeDeposit`을 호출하게 해보겠습니다.\n\n```cs\nnamespace Classses\n\npublic class Transaction\n{\n  public decimal Amount { get; }\n  public DateTime Date { get; }\n  public string Notes { get; }\n\n  public Transaction(decimal amount, DateTime date, string note)\n  {\n    Amount = amount;\n    Date = date;\n    Notes = note;\n  }\n}\n\npublic class BankAccount {\n  private static int accountNumberSeed = 1234567890;\n  private List<Transaction> allTransactions = new List<Transaction>();\n\n  public string Number { get; }\n  public string Owner { get; set; }\n  public decimal Balance\n  {\n     get\n     {\n        decimal balance = 0;\n        foreach (var item in allTransactions)\n        {\n          balanace += item.Amount;\n        }\n        return balance;\n     }\n  }\n\n  public BankAccount(string, name, decimal initialBalance)\n  {\n    // C#는 this 한정자가 선택사항이며 일반적으로 생략할 수 있습니다.\n    // this.Owner = name;\n    // this.Balance = initialBalance;\n    Owner = name;\n    MakeDeposit(initialBalance, DateTime.Now, \"Initial balance\");\n    // 계좌 번호\n    Number = accountNumberSeed.ToString();\n    accountNumberSeed++;\n  }\n\n  public void MakeDeposit(decimal amount, DateTime date, string note)\n  {\n    if (amount <= 0)\n    {\n      throw new ArgumentOutOfRangeException(nameof(amount), \"Amount of deposit must be positive\");\n    }\n    var deposit = new Transaction(amount, date, note);\n    allTransactions.add(deposit);\n  }\n\n  public vode MakeWithdraw(decimal amount, DateTime date, string note)\n  {\n    if (amount <= 0)\n    {\n      throw new ArgumentOutOfRangeException(nameof(amount), \"Amount of withdrawal must be positive\");\n    }\n    if (Balance - amount < 0)\n    {\n      throw new InvalidOperationException(\"Not sufficient funds for this withdrawal\");\n    }\n    var deposit = new Transaction(-amount, date, note);\n    allTransactions.add(deposit);\n  }\n}\n```\n\n## Ref\n\n- [클래스 및 개체를 사용한 개체 지향 프로그래밍 살펴보기](https://learn.microsoft.com/ko-kr/dotnet/csharp/fundamentals/tutorials/classes)\n- [개체 지향 프로그래밍(C#)](https://learn.microsoft.com/ko-kr/dotnet/csharp/fundamentals/tutorials/oop)\n- [C#의 클래스, 구조체 및 레코드 개요](https://learn.microsoft.com/ko-kr/dotnet/csharp/fundamentals/object-oriented/)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 4,
    "wordCount": 726,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "개체-vs-객체",
    "slug": "gaece-vs-gaegce",
    "path": "backend/patterns",
    "fullPath": "backend/patterns/gaece-vs-gaegce",
    "title": "개체 vs 객체",
    "excerpt": "개체 vs 객체 또는 라는 용어는 개발자, 특히 백엔드 개발자 사이에서 빼놓을 수 없다. 매체에 따라서 개체 또는 객체라고 표현하는 는 무엇일까? 객체 철학 의사나 행위가 미치는 대상. 언어 문장 내에서 동사의 행...",
    "content": "# 개체 vs 객체\n\n`개체` 또는 `객체`라는 용어는 개발자, 특히 백엔드 개발자 사이에서 빼놓을 수 없다. 매체에 따라서 개체 또는 객체라고 표현하는 `Object`는 무엇일까?\n\n## 객체\n\n1. 철학 의사나 행위가 미치는 대상.\n2. 언어 문장 내에서 동사의 행위가 미치는 대상.\n3. 철학 작용의 대상이 되는 쪽.\n\n## 개체\n\n1. 전체나 집단에 상대하여 하나하나의 낱개를 이르는 말.\n2. 생명 하나의 독립된 생물체. 살아가는 데에 필요한 독립적인 기능을 갖고 있다.\n3. 철학 단일하고 독립적인 통일적 존재. 철학 사상의 발전 과정에서 이 통일성은 물질적ㆍ양적 측면, 또는 정신적ㆍ질적 측면 따위의 여러 관점에서 고찰되었다.\n\n## 나만의 정리\n\n개체가 맞는 것 같다. 객체는 개체보다 수동적인 개념으로 이해할 수 있는데, 실제 클래스들은 서로 다른 클래스들과 상호작용을 하기 때문에 영향을 받는 것 뿐만 아니라 영향을 주기도 하기 때문이다.\n\n## Ref\n\n- [개체지향프로그래밍(C#)](https://learn.microsoft.com/ko-kr/dotnet/csharp/fundamentals/tutorials/oop)\n- [객체 정의](https://ko.dict.naver.com/#/entry/koko/9ef345f0a0884eca89d5c3155653fe94)\n- [개체 정의](https://ko.dict.naver.com/#/entry/koko/1f8d5f43afa2434f8d56f9ced1231c60)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 1,
    "wordCount": 131,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "solid-원칙",
    "slug": "solid-weoncig",
    "path": "backend/patterns",
    "fullPath": "backend/patterns/solid-weoncig",
    "title": "SOLID 원칙",
    "excerpt": "SOLID 원칙 Ref https://ko.wikipedia.org/wiki/SOLID_(%EA%B0%9D%EC%B2%B4_%EC%A7%80%ED%96%A5_%EC%84%A4%EA%B3%84)...",
    "content": "# SOLID 원칙\n\n## Ref\n\nhttps://ko.wikipedia.org/wiki/SOLID_(%EA%B0%9D%EC%B2%B4_%EC%A7%80%ED%96%A5_%EC%84%A4%EA%B3%84)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 1,
    "wordCount": 7,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "데코레이터를-이용한-nest-js에서의-aop-적용",
    "slug": "dekoreiteoreul-iyonghan-nest-jseseoyi-aop-jeogyong",
    "path": "backend/nestjs",
    "fullPath": "backend/nestjs/dekoreiteoreul-iyonghan-nest-jseseoyi-aop-jeogyong",
    "title": "데코레이터를 이용한 Nest.js에서의 AOP 적용",
    "excerpt": "데코레이터를 이용한 Nest.js에서의 AOP 적용 데코레이터? [데코레이터](<obsidian://open?vault=seogyugim.coinone&file=Typescript%2F%EB%8D%B0%EC%BD%94%EB%A0%88%EC%9D%B4%ED%...",
    "content": "# 데코레이터를 이용한 Nest.js에서의 AOP 적용\n\n## 데코레이터?\n\n[데코레이터](<obsidian://open?vault=seogyugim.coinone&file=Typescript%2F%EB%8D%B0%EC%BD%94%EB%A0%88%EC%9D%B4%ED%84%B0%20(Decorator)>) 문서를 참조해주세요!",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 1,
    "wordCount": 12,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "nestjs-dynamic-module-주의점",
    "slug": "nestjs-dynamic-module-juyijeom",
    "path": "backend/nestjs",
    "fullPath": "backend/nestjs/nestjs-dynamic-module-juyijeom",
    "title": "NestJS Dynamic Module 주의점",
    "excerpt": "NestJS Dynamic Module 주의점 ```typescript export const databaseProviders = [ { provide: MysqlDatasourceKey, inject: [ConfigService, MysqlConfigS...",
    "content": "# NestJS Dynamic Module 주의점\n\n```typescript\nexport const databaseProviders = [\n\t{\n\t\tprovide: MysqlDatasourceKey,\n\t\tinject: [ConfigService, MysqlConfigService],\n\t\tuseFactory: async (\n\t\t\tconfigService: ConfigService,\n\t\t\tdatabaseConfigService: MysqlConfigService,\n\t\t) => {\n\t\t\tconst dataSource = new DataSource(\n\t\t\t\tdatabaseConfigService.getTypeormConfig(),\n\t\t\t)\n\t\t\treturn dataSource.initialize()\n\t\t},\n\t},\n]\n```\n\n> 위와 같은 상황에서 useFactory에 인자에는 무조건 **`inject`배열의 순서**대로 인스턴스가 들어온다\n\n- 참고\n  - `MySqlConfigService` 는 `ConfigService`에 의존성이 있다.",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 1,
    "wordCount": 60,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "nestjs-cache-manager-v5-사용시-문제-해결법",
    "slug": "nestjs-cache-manager-v5-sayongsi-munje-haegyeolbeob",
    "path": "backend/nestjs",
    "fullPath": "backend/nestjs/nestjs-cache-manager-v5-sayongsi-munje-haegyeolbeob",
    "title": "NestJS, Cache-Manager v5 사용시 문제 해결법",
    "excerpt": "NestJS, Cache-Manager v5 사용시 문제 해결법 문제 공식문서에 나온대로 하면 발생 원인 가 로 올라가면서 사용법이 아예...",
    "content": "# NestJS, Cache-Manager v5 사용시 문제 해결법\n\n## 문제\n\n공식문서에 나온대로 하면 `this.cacheManager.get is not a function` 발생\n\n## 원인\n\n`cache-manager` 가 `v5`로 올라가면서 사용법이 아예 바뀜..\n\n## 해결\n\n```typescript\nimport { registerAs } from '@nestjs/config'\nimport { CACHE_CONFIG_KEY } from '../constants/index.js'\nimport { redisStore } from 'cache-manager-redis-store'\nimport { CacheConfigSchema } from './config.zod.js'\n\nexport const cacheConfig = registerAs(CACHE_CONFIG_KEY, async () =>\n\tCacheConfigSchema.parseAsync({\n\t\thost: process.env.CACHE_HOST,\n\t\tport: Number(process.env.CACHE_PORT),\n\t\tttl: Number(process.env.CACHE_TTL),\n\t\tstore: redisStore,\n\t}),\n)\n\n@Module({\n  providers: [\n    {\n      provide: CACHE_MANAGER,\n      inject: [cacheConfig.KEY],\n      useFactory: ({ store, ...config }: ConfigType<typeof cacheConfig>) =>\n        caching(store, config),\n    },\n  ],\n})\nexport class AppCacheModule\n```",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 1,
    "wordCount": 99,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "http-쿠키-보안-설정",
    "slug": "http-kuki-boan-seoljeong",
    "path": "backend/http",
    "fullPath": "backend/http/http-kuki-boan-seoljeong",
    "title": "HTTP 쿠키 보안 설정",
    "excerpt": "HTTP 쿠키 보안 설정 [세션 하이재킹과 XSS](https://developer.mozilla.org/ko/docs/Web/HTTP/Cookies%EC%84%B8%EC%85%98_%ED%95%98%EC%9D%B4%EC%9E%AC%ED%82%B9%EA%B...",
    "content": "# HTTP 쿠키 보안 설정\n\n1. [세션 하이재킹과 XSS](https://developer.mozilla.org/ko/docs/Web/HTTP/Cookies#%EC%84%B8%EC%85%98_%ED%95%98%EC%9D%B4%EC%9E%AC%ED%82%B9%EA%B3%BC_xss)\n2. [CSRF](https://developer.mozilla.org/ko/docs/Web/HTTP/Cookies#cross-site_%EC%9A%94%EC%B2%AD_%EC%9C%84%EC%A1%B0_csrf)\n3. [SameSite](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie/SameSite)\n\n\n## 참고 문서\n\n- [HTTP cookies 보안](https://developer.mozilla.org/ko/docs/Web/HTTP/Cookies#%EB%B3%B4%EC%95%88)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 1,
    "wordCount": 21,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "http-요청-최소화-기법",
    "slug": "http-yoceong-coesohwa-gibeob",
    "path": "backend/http",
    "fullPath": "backend/http/http-yoceong-coesohwa-gibeob",
    "title": "Http 요청 최소화 기법",
    "excerpt": "Http 요청 최소화 기법 뭐가 있을까? 다른 공급자에 대해 HTTP 요구를 수행하는 것은 많은 크롤 프로그램이나 배치 프로그램에서 필요할 수 있지만, 요청 수를 최소화하여 성능을 향상시키고 오류나 타임아웃 위험을 줄이는 것이 중요합니다. HTTP 요청을...",
    "content": "# Http 요청 최소화 기법\n\n## 뭐가 있을까?\n\n다른 공급자에 대해 HTTP 요구를 수행하는 것은 많은 크롤 프로그램이나 배치 프로그램에서 필요할 수 있지만, 요청 수를 최소화하여 성능을 향상시키고 오류나 타임아웃 위험을 줄이는 것이 중요합니다. HTTP 요청을 최소화하기 위한 일반적인 모범 사례는 다음과 같습니다.\n\n- 데이터 로컬 캐시하기: 동일한 데이터에 대해 반복적으로 요구하는 경우 불필요한 HTTP 요청을 수행하지 않도록 데이터 로컬 캐시를 검토하십시오. Redis나 Memcached 등의 도구를 사용하여 자주 액세스되는 데이터를 메모리에 저장하거나 로컬 파일 캐시를 사용하여 데이터를 디스크에 저장할 수 있습니다.\n- 배치 요청: 데이터마다 개별 요청을 작성하는 대신 요청을 배치 처리하여 HTTP 요청 수를 줄이는 것을 검토하십시오. 예를 들어, 하나의 API 호출을 사용하여 한 번에 여러 레코드를 페치하거나 여러 요청을 하나의 배치 요청에 결합할 수 있습니다.\n- 페이지네이션 사용: 대량의 데이터를 요구하는 경우 페이지네이션을 사용하여 한 번에 작은 배치의 데이터를 페치하는 것을 검토하십시오. 이를 통해 요청의 전체 수를 줄이고 성능을 향상시킬 수 있습니다.\n- HTTP 캐시 사용: 요구하는 데이터가 자주 변경될 가능성이 낮은 경우 HTTP 캐시를 사용하여 클라이언트 캐시에 응답을 저장하는 것을 검토하십시오. 이를 통해 서버에 대한 요청 수를 줄이고 성능을 향상시킬 수 있습니다.\n- 요청에 우선 순위를 매김: 여러 리소스에 대해 요청을 할 경우 가장 중요한 데이터가 먼저 페치되도록 요청에 우선 순위를 매기는 것을 검토하십시오. 이를 통해 요청의 전체 수를 줄이고 성능을 향상시킬 수 있습니다.\n\n이러한 모범 사례를 따름으로써 크롤 프로그램 또는 배치 프로그램에 의해 수행되는 HTTP 요청의 수를 최소화하여 성능을 향상시키고 오류 및 타임아웃 위험을 줄일 수 있습니다.",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 2,
    "wordCount": 232,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "http-transfer-크기를-줄이는-법",
    "slug": "http-transfer-keugireul-julineun-beob",
    "path": "backend/http",
    "fullPath": "backend/http/http-transfer-keugireul-julineun-beob",
    "title": "HTTP Transfer 크기를 줄이는 법",
    "excerpt": "HTTP Transfer 크기를 줄이는 법 종단 간 압축 !종단 간 압축 Accept-...",
    "content": "# HTTP Transfer 크기를 줄이는 법\n\n1. 종단 간 압축\n   ![종단 간 압축](https://developer.mozilla.org/en-US/docs/Web/HTTP/Compression/httpcompression1.png)\n    1. Accept-Encoding, Content-Encoding 클라이언트와 서버에서 헤더를 통해 정보를 주고 받는다\n    2. 이미지, 오디오나 비디오 등의 미디어 파일은 이미 압축되어 있을 확률이 높다.\n    3. CPU가 상대적으로 많이 든다.\n    4. gzip이 가장 보편적이며, 구글에서 개발한 br이 후발주자로 떠오른다.\n2. Hop-By-Hop 압축\n   ![Hop-By-Hop 압축](https://developer.mozilla.org/en-US/docs/Web/HTTP/Compression/httpcomp2.png)\n    1. 클라이언트와 서버 사이의 경로에 있는 노드들에서 압축이 발생한다.\n    2. Transfer-Encoding 헤더를 통해서 압축 방법을 주고 받는다.\n    3. 보통 프록시 계층에서 적용된다\n    4. `Transfer-Encoding: chunked`\n       헤더가 사용될 때는 요청이 완전히 처리되기 전까지 응답의 전체 크기를 알 수 없다. 데이터베이스 쿼리의 결과가 될 큰 HTML 테이블을 생성하는 경우나, 큰 이미지를 전송하는 경우가 예시가 된다.\n\n## 참고 문서\n\n- [Web HTTP Compression](https://developer.mozilla.org/ko/docs/Web/HTTP/Compression)\n- [HTTP Headers Transfer-Encoding](https://developer.mozilla.org/ko/docs/Web/HTTP/Headers/Transfer-Encoding)\n- [ExpressJS Compression Middleware Library](https://github.com/expressjs/compression)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 1,
    "wordCount": 124,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "eaddrnotavail",
    "slug": "eaddrnotavail",
    "path": "backend/http",
    "fullPath": "backend/http/eaddrnotavail",
    "title": "EADDRNOTAVAIL",
    "excerpt": "EADDRNOTAVAIL 문제 상황 node.js 서버 애플리케이션을 리눅스 환경에서 사용중이다. 아래와 같은 에러가 발생했다 ```json { \"message\": \"request to aa failed, reason: connect EAD...",
    "content": "# EADDRNOTAVAIL\n\n## 문제 상황\n\n1. node.js 서버 애플리케이션을 리눅스 환경에서 사용중이다.\n2. 아래와 같은 에러가 발생했다\n\n```json\n{\n  \"message\": \"request to aa failed, reason: connect EADDRNOTAVAIL aa:30000 - Local (aa:0)\",\n  \"type\": \"system\",\n  \"errno\": \"EADDRNOTAVAIL\",\n  \"code\": \"EADDRNOTAVAIL\",\n  \"isFetchError\": true,\n  \"url\": \"aa\"\n}\n```\n\n## 해결 방법 조사\n\n`etc/sysctl.conf`의 `net.ipv4.tcp_tw_recycle`를 활성화 하는 것은 좋은 생각이 아니다.\n\n위 옵션 변경으로 튜닝 하라는 가이드 문서가 많이 보이지만, tcp(7) 매뉴얼 페이지에 의하면 NAT를 가지고 동작할 때 문제가 발생할 수 있어서 권장하지 않는다고 한다.\n\nTIME_WAIT 상태의 접속은 접속 테이블에서 1분동안 유지된다. 즉 같은 네 쌍둥이(소스주소, 소스포트, 목적지주소, 목적지포트)에 다른 연결은 존재할 수 없다는 것을 뜻한다.\n웹 서버로 예를 들면 목적지 주소와 목적지 포트는 상수일 것이다. 웹 서버가 L7 로드밸런서 뒤에 있다면 소스 주소 도한 상수일 수 있다. 리눅스에서 클라이언트 포트는 기본적으로 30,000개의 포트 범위에서 할당\n된다(`net.ipv4.ip_local_port_range`를 튜닝하여 변경가능). 즉, 웹서버와 로드밸런서 사이에 연결이 매 분당 총 30,000개이며 매초 평균 500개의 연결이 맺어질 수 있다는 것을\n의미하겠다.\n이것을 초과하면 EADDRNOTAVAIL을 리턴한다. 해결방법은 네 쌍둥이를 더 많이 가질 수 있게 하는 것 밖에 없다.\n난이도가 어려운 순서대로 나열하면 다음과 같다.\n\n- `net.ipv4.ip_local_port_range`를 좀 더 넓게 세팅해서 더 많은 클라이언트 포트를 사용한다\n- 리스닝하는 웹서버에 추가적인 포트(81,82,83,...)를 할당함으로써 좀 더 많은 서버 포트를 사용한다\n- 로드 밸런서에 아이피를 추가하거나 라운드 로빈 기능을 적용해서 좀 더 많은 클라이언트 아이피를 사용한다.\n- 웹 서버에 아이피를 추가하여 좀 더 많은 아이피를 사용한다.\n\nNodeJS에서의 우회적인 방법으로는 다음과 같은 방법이 있다.\n\n```js\nvar http = require( \"http\"),\n    agent = new http.Agent( {maxSockets: 1} );\n\n\nfunction httpRequest( callback ) {\n    var options = {\n            host: 'localhost',\n            port: 80,\n            path: '',\n\n            agent: agent\n        },\n...\n```\n\n```js\nvar http = require(\"http\");\n\nfunction httpRequest(callback) {\n    var options = {\n        ...,\n        agent: false\n    };\n...\n```\n\n또한 아래를 `/etc/sysctl.conf`에 추가해주었다.\n\n`net.ipv4.ip_local_port_range = 1024 65535`\n\n## 참고 문서\n\n- [리눅스 man-pages](https://man7.org/linux/man-pages/index.html)\n- [[번역] 바쁜 리눅스 서버에서 TCP TIME-WAIT 상태 대처하기](https://linux.systemv.pe.kr/%EB%B2%88%EC%97%AD-%EB%B0%94%EC%81%9C-%EB%A6%AC%EB%88%85%EC%8A%A4-%EC%84%9C%EB%B2%84%EC%97%90%EC%84%9C-tcp-time-wait-%EC%83%81%ED%83%9C-%EB%8C%80%EC%B2%98%ED%95%98%EA%B8%B0/)\n- [2014년도 구글 그룹에서의 한 문답..](https://groups.google.com/g/nodejs/c/68SYd6_ksns?pli=1)\n- [[Linux] 커널 파라미터 수정 - TCP 성능향상](https://bangu4.tistory.com/135)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 2,
    "wordCount": 317,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  },
  {
    "id": "trunk-based-development",
    "slug": "trunk-based-development",
    "path": "backend/devops",
    "fullPath": "backend/devops/trunk-based-development",
    "title": "Trunk-Based Development",
    "excerpt": "Trunk-Based Development 트렁크 기반 개발은 개발자들이 라고 부르는 단일 브랜치에서 공동 작업을 수행하는 소스 제어 브랜칭 모델이며, 수명이 긴 다른 개발 브랜치를 생성하지 않기 위한 방법입니다. 그러므로 이 방법을 사용하면 병합지옥...",
    "content": "# Trunk-Based Development\n\n트렁크 기반 개발은 개발자들이 `trunk`라고 부르는 단일 브랜치에서 공동 작업을 수행하는 소스 제어 브랜칭 모델이며, 수명이 긴 다른 개발 브랜치를 생성하지 않기 위한 방법입니다. 그러므로 이 방법을 사용하면 병합지옥을 피하고 빌드를 깨지 않을 수 있습니다.\n\n## 트렁크 기반 개발의 Good or Bad Practice\n\n### Shared branches off mainline/main/trunk are bad at any release cadence\n\n![trunk-1a](https://trunkbaseddevelopment.com/trunk1a.png)\n\n### Trunk-Based Development For Smaller Teams\n\n![trunk-1b](https://trunkbaseddevelopment.com/trunk1b.png)\n\n### Scaled Trunk-Based Development\n\n![trunk-1c](https://trunkbaseddevelopment.com/trunk1c.png)\n\n## 정리\n\n개발자들은 피쳐브랜치에서 작업한 뒤 Trunk (or main) 브랜치로 병합하고, 릴리즈가 진행될떄 릴리즈 버전을 명시한 브랜치를 분기한다. 이때 분기된 브랜치에는 추가적인 커밋을 하지 않으며, 변경사항은 다음 릴리즈에 반영한다. 이런 작업 방식에서 서로 다른 버전에서 반영되어야할 사항이 main 브랜치에 공존하는 상황이 있을 수 있는데, 이를 통제하기 위해 기능 별 플래그처리를 사용하는 것이 좋다. 이 내용을 공식 사이트에서는 다음과 같이 소개하고 있다. [링크](https://trunkbaseddevelopment.com/feature-flags/)\n\n## NodeJS에서 플래그 처리를 어떻게 하는게 좋을까?\n\npackage.json의 버전을 적극적으로 사용하는게 어떨까 싶다. semver를 사용하고 있다면, release 버전을 부버전까지는 고정시켜 놓고 수버전을 올리면서 패치를 하게 될텐데, 한 릴리즈에서의 모든 기능을 보장한다면 플래그 처리를 부버전까지를 검사하는 것으로 할 수 있다.\n\n아래는 v2.5.x 릴리즈를 하는 경우의 예시이다\n\n```ts\nconst version = process.env.npm_package_version || '100'\n\nif (version.startsWith('2.5')) {\n   someCode();\n}\n\nif (Number(version) > 2.5) {\n   runAnotherCode();\n}\n...\n\n```\n\n## NodeJS에서 버전을 가져오는 방법\n\n1. package.json의 version을 가져오는 것\n   다만 참조한 스택오버플로우 답변에도 적혀있듯이, 브라우저에서 사용할 시엔 package.json의 내용을 클라이언트에서 참조할 수 있으므로 NodeJS를 활용한 서버에서만 활용하는게 좋을 듯 하다.\n\n   ```ts\n   // You need to set resolveJsonModule true in tsconfig.json\n   import { version } from './package.json'\n   console.log(`version = ${version}`)\n   console.log(`Is flag enabled? ${version.startsWith('2.5')}`)\n   // version = 1.0.0\n   // Is flag enabled? false\n   ```\n\n2. process 환경변수에서 가져오는 것\n   만약 NodeJS 애플리케이션이 npm 등의 패키지 매니저로 시작되었다면 아래와 같이 가져올 수 있다.\n\n   ```ts\n   // run npm start\n   const version = process.env.npm_package_version\n   console.log(`version = ${version}`)\n   console.log(\n   \t`Is flag enabled? ${version?.startsWith('2.5') ?? 'version is undefined'}`,\n   )\n   // version = 1.0.0\n   // Is flag enabled? false\n   ```\n\n물론 버전을 통한 플래그 처리를 하기 위해서는 철저한 package.json 관리가 필요하다.\n\n## Ref\n\n- [트렁크기반개발](https://trunkbaseddevelopment.com/)\n- [semver](https://semver.org/lang/ko/)\n- [is-there-a-way-to-get-version-from-package-json-in-nodejs-code](https://stackoverflow.com/questions/9153571/is-there-a-way-to-get-version-from-package-json-in-nodejs-code)",
    "docType": "original",
    "category": "Backend_DevOps",
    "tags": [],
    "readingTime": 2,
    "wordCount": 332,
    "isFeatured": false,
    "isPublic": true,
    "date": "2025-12-27"
  }
]